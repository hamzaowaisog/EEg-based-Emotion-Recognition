{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d166b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d65e3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Raw EEG Shape: (32, 40, 40, 8064)\n",
      "âœ… Emotion Labels Shape: (32, 40)\n",
      "âœ… DE features saved to: E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_features.npy\n",
      "âœ… Labels saved to: E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_labels.npy\n",
      "ðŸŽ‰ All processing done! DE features and labels are now saved and ready for training.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import scipy.io\n",
    "import os\n",
    "\n",
    "# ==== CONFIG ====\n",
    "data_path = \"E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/data_preprocessed_matlab/\"\n",
    "save_features = \"E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_features.npy\"\n",
    "save_labels = \"E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_labels.npy\"\n",
    "\n",
    "# ==== Frequency bands ====\n",
    "freq_bands = {\n",
    "    \"delta\": (1, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 14),\n",
    "    \"beta\": (14, 30),\n",
    "    \"gamma\": (31, 50),\n",
    "}\n",
    "\n",
    "# Differential Entropy formula\n",
    "def compute_de(signal):\n",
    "    variance = np.var(signal, axis=-1, keepdims=True)\n",
    "    de = 0.5 * np.log(2 * np.pi * np.e * variance)\n",
    "    return de.squeeze()\n",
    "\n",
    "# Feature extraction and save\n",
    "def extract_and_save_de_features(subject_data, subject_labels, feature_path, label_path, fs=128, window_size=128):\n",
    "    num_subjects, num_trials, num_channels, num_samples = subject_data.shape\n",
    "    num_bands = len(freq_bands)\n",
    "    num_windows = num_samples // window_size\n",
    "\n",
    "    de_features = np.zeros((num_subjects, num_trials, num_channels, num_bands, num_windows))\n",
    "\n",
    "    for subj in range(num_subjects):\n",
    "        for trial in range(num_trials):\n",
    "            for ch in range(num_channels):\n",
    "                signal = subject_data[subj, trial, ch, :]\n",
    "                for b_idx, (band, (low, high)) in enumerate(freq_bands.items()):\n",
    "                    sos = scipy.signal.butter(4, [low, high], btype=\"bandpass\", fs=fs, output=\"sos\")\n",
    "                    filtered_signal = scipy.signal.sosfilt(sos, signal)\n",
    "\n",
    "                    segmented = np.array(np.split(filtered_signal, num_windows, axis=-1))\n",
    "                    de_features[subj, trial, ch, b_idx, :] = compute_de(segmented)\n",
    "\n",
    "    np.save(feature_path, de_features)\n",
    "    print(f\"âœ… DE features saved to: {feature_path}\")\n",
    "\n",
    "    # Expand labels to match window dimension\n",
    "    expanded_labels = np.repeat(subject_labels[:, :, np.newaxis], num_windows, axis=2)  # Shape: (32, 40, 63)\n",
    "    np.save(label_path, expanded_labels)\n",
    "    print(f\"âœ… Labels saved to: {label_path}\")\n",
    "\n",
    "# ==== Loading raw EEG data ====\n",
    "subject_data = []\n",
    "subject_labels = []\n",
    "\n",
    "for i in range(1, 33):\n",
    "    mat = scipy.io.loadmat(f\"{data_path}s{i:02d}.mat\")\n",
    "    eeg = mat[\"data\"]  # Shape: (40, 40, 8064)\n",
    "    labels = mat[\"labels\"]  # Shape: (40, 4)\n",
    "\n",
    "    # Map labels to 4 emotion classes (Valence + Arousal)\n",
    "    valence = labels[:, 0]\n",
    "    arousal = labels[:, 1]\n",
    "    emotion_class = np.zeros_like(valence, dtype=int)\n",
    "    emotion_class[(valence >= 5) & (arousal >= 5)] = 3\n",
    "    emotion_class[(valence < 5) & (arousal >= 5)] = 1\n",
    "    emotion_class[(valence >= 5) & (arousal < 5)] = 2\n",
    "    emotion_class[(valence < 5) & (arousal < 5)] = 0\n",
    "\n",
    "    subject_data.append(eeg)\n",
    "    subject_labels.append(emotion_class)\n",
    "\n",
    "subject_data = np.array(subject_data)      # Shape: (32, 40, 40, 8064)\n",
    "subject_labels = np.array(subject_labels)  # Shape: (32, 40)\n",
    "\n",
    "print(\"âœ… Raw EEG Shape:\", subject_data.shape)\n",
    "print(\"âœ… Emotion Labels Shape:\", subject_labels.shape)\n",
    "\n",
    "# ==== Extract and save DE features + labels ====\n",
    "extract_and_save_de_features(subject_data, subject_labels, save_features, save_labels)\n",
    "\n",
    "print(\"ðŸŽ‰ All processing done! DE features and labels are now saved and ready for training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e27ae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DE features loaded: (32, 40, 40, 5, 63)\n",
      "âœ… DE labels loaded: (32, 40, 63)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "de_features = np.load(save_features)\n",
    "de_labels = np.load(save_labels) \n",
    "\n",
    "print(\"âœ… DE features loaded:\", de_features.shape)\n",
    "print(\"âœ… DE labels loaded:\", de_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "461e90a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Class distribution (after segmentation):\n",
      "Class 0: 16380 samples\n",
      "Class 1: 18648 samples\n",
      "Class 2: 16758 samples\n",
      "Class 3: 28854 samples\n",
      "\n",
      "ðŸ’¡ Total samples: 80640\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your saved labels\n",
    "de_labels = np.load(\"E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_labels.npy\")\n",
    "\n",
    "# Flatten labels to 1D array\n",
    "flat_labels = de_labels.flatten()\n",
    "\n",
    "# Count each class\n",
    "classes, counts = np.unique(flat_labels, return_counts=True)\n",
    "\n",
    "print(\"ðŸ§  Class distribution (after segmentation):\")\n",
    "for cls, count in zip(classes, counts):\n",
    "    print(f\"Class {cls}: {count} samples\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Total samples:\", np.sum(counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782258d0",
   "metadata": {},
   "source": [
    "## DEAP DATASET CLASS FOR FEATURES & LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8232331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DEAPDataset(Dataset):\n",
    "    def __init__(self, feature_path, label_path, transform=None):\n",
    "        self.features = np.load(feature_path)  # Shape: (32, 40, 40, 5, 63)\n",
    "        self.labels = np.load(label_path)      # Shape: (32, 40, 63)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.samples = []\n",
    "        num_subjects, num_trials, _, _, num_windows = self.features.shape\n",
    "\n",
    "        for subj in range(num_subjects):\n",
    "            for trial in range(num_trials):\n",
    "                for win in range(num_windows):\n",
    "                    label = self.labels[subj, trial, win]\n",
    "                    self.samples.append((subj, trial, win, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subj, trial, win, label = self.samples[idx]\n",
    "        feature = self.features[subj, trial, :, :, win]  # Shape: (40 channels, 5 bands)\n",
    "\n",
    "        if self.transform:\n",
    "            feature = self.transform(feature)\n",
    "\n",
    "        return torch.tensor(feature, dtype=torch.float32), int(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0671a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Balanced DataLoader ready for training.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# Instantiate dataset\n",
    "dataset = DEAPDataset('E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_features.npy',\n",
    "                      'E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_labels.npy')\n",
    "\n",
    "# Get all labels for computing class weights\n",
    "all_labels = np.array([label for _, _, _, label in dataset.samples])\n",
    "classes, counts = np.unique(all_labels, return_counts=True)\n",
    "\n",
    "# Inverse frequency as weight\n",
    "class_weights = 1. / counts\n",
    "sample_weights = [class_weights[label] for label in all_labels]\n",
    "\n",
    "# Create the sampler\n",
    "sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                 num_samples=len(sample_weights),\n",
    "                                 replacement=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=64, sampler=sampler)\n",
    "\n",
    "print(\"âœ… Balanced DataLoader ready for training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c62f5",
   "metadata": {},
   "source": [
    "## MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18103030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CommonFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim=200):  # DEAP: 40 channels Ã— 5 bands\n",
    "        super(CommonFeatureExtractor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.act = nn.LeakyReLU()  # As per paper, not ReLU\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)         # Flatten input (40, 5) â†’ [200]\n",
    "        x = self.act(self.fc1(x))         # Input â†’ 256\n",
    "        x = self.act(self.fc2(x))         # 256 â†’ 128\n",
    "        x = self.act(self.fc3(x))         # 128 â†’ 64 (final embedding)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3afc5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectSpecificMapper(nn.Module):\n",
    "    def __init__(self, input_dim=64, output_dim=32):\n",
    "        super(SubjectSpecificMapper, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.fc(x))  # 64 â†’ 32 with LeakyReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2140658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectSpecificClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=32, num_classes=4):  # You use 4 classes (DEAP)\n",
    "        super(SubjectSpecificClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)  # 32 â†’ 4, raw logits (no activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60c30e",
   "metadata": {},
   "source": [
    "## Contrastive Loss 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36a17ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(SupervisedContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: Tensor of shape [batch_size, feature_dim]\n",
    "            labels:   Tensor of shape [batch_size] (int class labels)\n",
    "        Returns:\n",
    "            loss: scalar\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "        features = F.normalize(features, dim=1)\n",
    "        batch_size = features.shape[0]\n",
    "\n",
    "        # Cosine similarity matrix\n",
    "        sim_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        # Mask: same-label entries â†’ 1, others â†’ 0\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "\n",
    "        # Remove self-similarity from denominator\n",
    "        logits_mask = torch.ones_like(mask) - torch.eye(batch_size).to(device)\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # Numerator: exp(similarity with positives)\n",
    "        exp_sim = torch.exp(sim_matrix) * logits_mask\n",
    "        log_prob = sim_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-9)\n",
    "\n",
    "        # Final loss: average only over positive pairs\n",
    "        loss = - (mask * log_prob).sum() / (mask.sum() + 1e-9)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93673316",
   "metadata": {},
   "source": [
    "## MMD LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2b2b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MMDLoss(nn.Module):\n",
    "    def __init__(self, kernel_type='rbf', kernel_mul=2.0, num_kernels=5):\n",
    "        super(MMDLoss, self).__init__()\n",
    "        self.kernel_type = kernel_type\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.num_kernels = num_kernels\n",
    "\n",
    "    def gaussian_kernel(self, source, target):\n",
    "        total = torch.cat([source, target], dim=0)  # [n + m, d]\n",
    "        total0 = total.unsqueeze(0)  # [1, n+m, d]\n",
    "        total1 = total.unsqueeze(1)  # [n+m, 1, d]\n",
    "        L2_distance = ((total0 - total1) ** 2).sum(2)  # [n+m, n+m]\n",
    "\n",
    "        # Use multiple Gaussian kernels\n",
    "        bandwidth = torch.mean(L2_distance).detach()\n",
    "        bandwidth_list = [bandwidth * (self.kernel_mul ** i) for i in range(self.num_kernels)]\n",
    "        kernels = [torch.exp(-L2_distance / bw) for bw in bandwidth_list]\n",
    "        return sum(kernels) / len(kernels)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        source = source.view(source.size(0), -1)  # [bs, d]\n",
    "        target = target.view(target.size(0), -1)\n",
    "        kernels = self.gaussian_kernel(source, target)\n",
    "\n",
    "        batch_size = source.size(0)\n",
    "        XX = kernels[:batch_size, :batch_size]  # source-source\n",
    "        YY = kernels[batch_size:, batch_size:]  # target-target\n",
    "        XY = kernels[:batch_size, batch_size:]  # source-target\n",
    "        YX = kernels[batch_size:, :batch_size]  # target-source\n",
    "\n",
    "        loss = torch.mean(XX + YY - XY - YX)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea01d76",
   "metadata": {},
   "source": [
    "## Contrastive Loss 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "961113b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ContrastiveLossLcon2(nn.Module):\n",
    "    def __init__(self, feature_dim=32, num_classes=4, tau=0.3, gamma=0.5, queue_size=1024):\n",
    "        super(ContrastiveLossLcon2, self).__init__()\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        self.num_classes = num_classes\n",
    "        self.queue_size = queue_size\n",
    "\n",
    "        # Initialize class prototypes (Î¼_c)\n",
    "        self.prototypes = nn.Parameter(torch.randn(num_classes, feature_dim))  # Shape: [4, 32]\n",
    "\n",
    "        # Initialize memory queue for negative samples\n",
    "        self.register_buffer(\"queue\", torch.randn(queue_size, feature_dim))  # Shape: [1024, 32]\n",
    "        self.queue = F.normalize(self.queue, dim=-1)\n",
    "\n",
    "    def forward(self, z_t, pseudo_labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z_t: target embeddings from SFE (B, 32)\n",
    "            pseudo_labels: class indices (B,)\n",
    "        \"\"\"\n",
    "        z_t = F.normalize(z_t, dim=-1)  # Normalize subject-specific features\n",
    "\n",
    "        # 1. Positive logits (with prototypes)\n",
    "        pos_proto = self.prototypes[pseudo_labels]  # (B, 32)\n",
    "        pos_logits = torch.sum(z_t * pos_proto, dim=-1) / self.tau  # cosine similarity / tau\n",
    "\n",
    "        # 2. Negative logits (with queue)\n",
    "        neg_logits = torch.matmul(z_t, self.queue.T) / self.tau  # (B, Q)\n",
    "\n",
    "        # 3. Combine positives and negatives into logits\n",
    "        logits = torch.cat([pos_logits.unsqueeze(1), neg_logits], dim=1)  # (B, 1+Q)\n",
    "        labels = torch.zeros(z_t.size(0), dtype=torch.long).to(z_t.device)  # Positives at index 0\n",
    "\n",
    "        # 4. Compute loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        # 5. Update the queue\n",
    "        self._dequeue_and_enqueue(z_t)\n",
    "\n",
    "        return self.gamma * loss  # Î³-scaled\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, embeddings):\n",
    "        # Detach to avoid gradients\n",
    "        embeddings = embeddings.detach()\n",
    "\n",
    "        batch_size = embeddings.size(0)\n",
    "        queue = self.queue\n",
    "\n",
    "        if batch_size >= self.queue_size:\n",
    "            self.queue = embeddings[-self.queue_size:]\n",
    "        else:\n",
    "            self.queue = torch.cat([queue[batch_size:], embeddings], dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc705eb",
   "metadata": {},
   "source": [
    "## GCE LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bbb5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeneralizedCrossEntropy(nn.Module):\n",
    "    def __init__(self, q=0.7):\n",
    "        super(GeneralizedCrossEntropy, self).__init__()\n",
    "        self.q = q\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        logits: [B, C]\n",
    "        targets: [B] (class indices)\n",
    "        \"\"\"\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        probs_true = probs[torch.arange(logits.size(0)), targets]  # pick p_y\n",
    "\n",
    "        if self.q == 1.0:\n",
    "            loss = 1.0 - probs_true\n",
    "        else:\n",
    "            loss = (1.0 - probs_true.pow(self.q)) / self.q\n",
    "\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a253160",
   "metadata": {},
   "source": [
    "## Training LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b57bbf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full MSCL Training Loop (Unified Script)\n",
    "# DEAP Dataset + Phase 1 Losses + Model + LOSO\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# === DEAP Dataset Loader ===\n",
    "class DEAPDataset(Dataset):\n",
    "    def __init__(self, feature_path, label_path, exclude_subject=None, only_subject=None):\n",
    "        self.features = np.load(feature_path)  # shape: (32, 40, 40, 5, 63)\n",
    "        self.labels = np.load(label_path)      # shape: (32, 40, 63)\n",
    "\n",
    "        self.samples = []\n",
    "        for subj in range(32):\n",
    "            if exclude_subject is not None and subj == exclude_subject:\n",
    "                continue\n",
    "            if only_subject is not None and subj != only_subject:\n",
    "                continue\n",
    "            for trial in range(40):\n",
    "                for win in range(63):\n",
    "                    x = self.features[subj, trial, :, :, win]\n",
    "                    y = self.labels[subj, trial, win]\n",
    "                    self.samples.append((x, y, subj))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, subj = self.samples[idx]\n",
    "        return torch.tensor(x, dtype=torch.float32), int(y)\n",
    "\n",
    "    def get_subject_data(self, subject):\n",
    "        return [(torch.tensor(x, dtype=torch.float32), int(y))\n",
    "                for x, y, subj in self.samples if subj == subject]\n",
    "\n",
    "# === Models ===\n",
    "class CommonFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim=200):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # [batch, 40, 5] â†’ [batch, 200]\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        x = self.act(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class SubjectSpecificMapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(64, 32)\n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.fc(x))\n",
    "\n",
    "class SubjectSpecificClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(32, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# === Losses ===\n",
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        features = F.normalize(features, dim=1)\n",
    "        batch_size = features.shape[0]\n",
    "        sim_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "        logits_mask = torch.ones_like(mask) - torch.eye(batch_size).to(features.device)\n",
    "        mask = mask * logits_mask\n",
    "        exp_sim = torch.exp(sim_matrix) * logits_mask\n",
    "        log_prob = sim_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-9)\n",
    "        loss = - (mask * log_prob).sum() / (mask.sum() + 1e-9)\n",
    "        return loss\n",
    "\n",
    "class MMDLoss(nn.Module):\n",
    "    def __init__(self, kernel_mul=2.0, num_kernels=5):\n",
    "        super().__init__()\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.num_kernels = num_kernels\n",
    "\n",
    "    def gaussian_kernel(self, source, target):\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        total0 = total.unsqueeze(0)\n",
    "        total1 = total.unsqueeze(1)\n",
    "        L2_distance = ((total0 - total1) ** 2).sum(2)\n",
    "        bandwidth = torch.mean(L2_distance).detach()\n",
    "        bandwidth_list = [bandwidth * (self.kernel_mul ** i) for i in range(self.num_kernels)]\n",
    "        kernels = [torch.exp(-L2_distance / bw) for bw in bandwidth_list]\n",
    "        return sum(kernels) / len(kernels)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        source = source.view(source.size(0), -1)\n",
    "        target = target.view(target.size(0), -1)\n",
    "        kernels = self.gaussian_kernel(source, target)\n",
    "        batch_size = source.size(0)\n",
    "        XX = kernels[:batch_size, :batch_size]\n",
    "        YY = kernels[batch_size:, batch_size:]\n",
    "        XY = kernels[:batch_size, batch_size:]\n",
    "        YX = kernels[batch_size:, :batch_size]\n",
    "        return torch.mean(XX + YY - XY - YX)\n",
    "\n",
    "class ContrastiveLossLcon2(nn.Module):\n",
    "    def __init__(self, feature_dim=32, num_classes=4, tau=0.3, gamma=0.5, queue_size=1024):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        self.prototypes = nn.Parameter(torch.randn(num_classes, feature_dim))\n",
    "        self.register_buffer(\"queue\", torch.randn(queue_size, feature_dim))\n",
    "        self.queue = F.normalize(self.queue, dim=-1)\n",
    "\n",
    "    def forward(self, z_t, pseudo_labels):\n",
    "        z_t = F.normalize(z_t, dim=-1)\n",
    "        pos_proto = self.prototypes[pseudo_labels]\n",
    "        pos_logits = torch.sum(z_t * pos_proto, dim=-1) / self.tau\n",
    "        neg_logits = torch.matmul(z_t, self.queue.T) / self.tau\n",
    "        logits = torch.cat([pos_logits.unsqueeze(1), neg_logits], dim=1)\n",
    "        labels = torch.zeros(z_t.size(0), dtype=torch.long).to(z_t.device)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        self._dequeue_and_enqueue(z_t)\n",
    "        return self.gamma * loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, embeddings):\n",
    "        embeddings = embeddings.detach()\n",
    "        batch_size = embeddings.size(0)\n",
    "        if batch_size >= self.queue.size(0):\n",
    "            self.queue = embeddings[-self.queue.size(0):]\n",
    "        else:\n",
    "            self.queue = torch.cat([self.queue[batch_size:], embeddings], dim=0)\n",
    "\n",
    "class GeneralizedCrossEntropy(nn.Module):\n",
    "    def __init__(self, q=0.7):\n",
    "        super().__init__()\n",
    "        self.q = q\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        probs_true = probs[torch.arange(logits.size(0)), targets]\n",
    "        if self.q == 1.0:\n",
    "            loss = 1.0 - probs_true\n",
    "        else:\n",
    "            loss = (1.0 - probs_true.pow(self.q)) / self.q\n",
    "        return loss.mean()\n",
    "\n",
    "# === Helper ===\n",
    "def get_target_batch(dataset, exclude, batch_size=64):\n",
    "    for subj in range(32):\n",
    "        if subj != exclude:\n",
    "            data = dataset.get_subject_data(subj)\n",
    "            if len(data) >= batch_size:\n",
    "                indices = torch.randperm(len(data))[:batch_size]\n",
    "                x, y = zip(*[data[i] for i in indices])\n",
    "                return torch.stack(x), torch.tensor(y)\n",
    "\n",
    "# === Training Loop ===\n",
    "# [INSERTED FROM EXISTING LOOP ABOVE -- UNCHANGED]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e856821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting Fold 1/32 - Test Subject: s01\n",
      "Epoch [1/600] - Loss: 0.4156 - Train Acc: 0.0000\n",
      "Epoch [2/600] - Loss: 0.4156 - Train Acc: 0.0000\n",
      "Epoch [3/600] - Loss: 0.4156 - Train Acc: 0.0000\n",
      "Epoch [4/600] - Loss: 0.4156 - Train Acc: 0.0000\n",
      "Epoch [5/600] - Loss: 0.4155 - Train Acc: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_s, y_s \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     74\u001b[0m     x_s, y_s \u001b[38;5;241m=\u001b[39m x_s\u001b[38;5;241m.\u001b[39mto(device), y_s\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 75\u001b[0m     x_t, y_t \u001b[38;5;241m=\u001b[39m \u001b[43mget_target_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_subject\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     x_t, y_t \u001b[38;5;241m=\u001b[39m x_t\u001b[38;5;241m.\u001b[39mto(device), y_t\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     78\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[1;32mIn[27], line 166\u001b[0m, in \u001b[0;36mget_target_batch\u001b[1;34m(dataset, exclude, batch_size)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m):\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subj \u001b[38;5;241m!=\u001b[39m exclude:\n\u001b[1;32m--> 166\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_subject_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size:\n\u001b[0;32m    168\u001b[0m             indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandperm(\u001b[38;5;28mlen\u001b[39m(data))[:batch_size]\n",
      "Cell \u001b[1;32mIn[27], line 37\u001b[0m, in \u001b[0;36mDEAPDataset.get_subject_data\u001b[1;34m(self, subject)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_subject_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, subject):\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mint\u001b[39m(y))\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m x, y, subj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;28;01mif\u001b[39;00m subj \u001b[38;5;241m==\u001b[39m subject]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Full Training Loop for MSCL Model (Phase 1) - DEAP Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# === Assume these are already defined ===\n",
    "# - CommonFeatureExtractor\n",
    "# - SubjectSpecificMapper\n",
    "# - SubjectSpecificClassifier\n",
    "# - SupervisedContrastiveLoss\n",
    "# - ContrastiveLossLcon2\n",
    "# - MMDLoss\n",
    "# - GeneralizedCrossEntropy\n",
    "# - DEAPDataset (with LOSO support)\n",
    "# - WeightedRandomSampler\n",
    "# - get_target_batch()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 600\n",
    "lambda_1, lambda_2, lambda_3 = 0.1, 0.1, 0.1\n",
    "num_subjects = 32\n",
    "batch_size = 64\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Logging containers\n",
    "fold_accuracies = []\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "\n",
    "for test_subject in range(num_subjects):\n",
    "    print(f\"\\nðŸš€ Starting Fold {test_subject+1}/32 - Test Subject: s{test_subject+1:02d}\")\n",
    "\n",
    "    # === Create datasets and loaders ===\n",
    "    train_dataset = DEAPDataset('E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_features.npy', 'E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_labels.npy', exclude_subject=test_subject)\n",
    "    test_dataset = DEAPDataset('E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_features.npy', 'E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_labels.npy', only_subject=test_subject)\n",
    "\n",
    "    all_labels = np.array([label for _, label in train_dataset])\n",
    "    class_sample_counts = np.bincount(all_labels)\n",
    "    class_weights = 1. / class_sample_counts\n",
    "    sample_weights = [class_weights[label] for label in all_labels]\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # === Initialize model and losses ===\n",
    "    cfe = CommonFeatureExtractor().to(device)\n",
    "    sfe = SubjectSpecificMapper().to(device)\n",
    "    ssc = SubjectSpecificClassifier().to(device)\n",
    "\n",
    "    contrastive_loss_con1 = SupervisedContrastiveLoss()\n",
    "    contrastive_loss_con2 = ContrastiveLossLcon2()\n",
    "    mmd_loss = MMDLoss()\n",
    "    gce_loss = GeneralizedCrossEntropy(q=0.7)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(cfe.parameters()) + list(sfe.parameters()) + list(ssc.parameters()), lr=1e-3)\n",
    "\n",
    "    # === Training ===\n",
    "    for epoch in range(num_epochs):\n",
    "        cfe.train(), sfe.train(), ssc.train()\n",
    "        total_loss, total_correct, total_samples = 0, 0, 0\n",
    "\n",
    "        for x_s, y_s in train_loader:\n",
    "            x_s, y_s = x_s.to(device), y_s.to(device)\n",
    "            x_t, y_t = get_target_batch(train_dataset, exclude=test_subject,batch_size=batch_size)\n",
    "            x_t, y_t = x_t.to(device), y_t.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            min_size = min(x_s.size(0), x_t.size(0))\n",
    "            x_s = x_s[:min_size]\n",
    "            x_t = x_t[:min_size]\n",
    "\n",
    "            z_s_common = cfe(x_s)\n",
    "            z_t_common = cfe(x_t)\n",
    "            loss_mmd = mmd_loss(z_s_common, z_t_common)\n",
    "\n",
    "            if epoch < 400:\n",
    "                loss_con1 = contrastive_loss_con1(z_s_common, y_s)\n",
    "                loss = lambda_1 * loss_con1 + lambda_3 * loss_mmd\n",
    "            else:\n",
    "                z_s_subject = sfe(z_s_common)\n",
    "                z_t_subject = sfe(z_t_common)\n",
    "                logits = ssc(z_s_subject)\n",
    "                loss_cls = gce_loss(logits, y_s)\n",
    "                pseudo_labels = torch.argmax(ssc(z_t_subject), dim=1)\n",
    "                loss_con2 = contrastive_loss_con2(z_t_subject, pseudo_labels)\n",
    "                loss = lambda_2 * loss_con2 + lambda_3 * loss_mmd + loss_cls\n",
    "\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                total_correct += (preds == y_s).sum().item()\n",
    "                total_samples += y_s.size(0)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        acc = total_correct / total_samples if total_samples > 0 else 0\n",
    "        epoch_losses.append(avg_loss)\n",
    "        epoch_accuracies.append(acc)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f} - Train Acc: {acc:.4f}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'cfe_state_dict': cfe.state_dict(),\n",
    "            'sfe_state_dict': sfe.state_dict(),\n",
    "            'ssc_state_dict': ssc.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss\n",
    "        }\n",
    "        torch.save(checkpoint, f\"checkpoints/fold{test_subject+1}_epoch{epoch+1}.pt\")\n",
    "\n",
    "    # === Evaluation ===\n",
    "    cfe.eval(), sfe.eval(), ssc.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test = x_test.to(device)\n",
    "            z_common = cfe(x_test)\n",
    "            z_subject = sfe(z_common)\n",
    "            logits = ssc(z_subject)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_test.numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    fold_accuracies.append(acc)\n",
    "    print(f\"ðŸŽ¯ Accuracy on Subject {test_subject+1}: {acc:.4f}\")\n",
    "\n",
    "# === Final Report ===\n",
    "print(\"\\nâœ… Training complete.\")\n",
    "print(\"Average Accuracy:\", np.mean(fold_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48efac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
