{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Data Shape: (32, 40, 40, 8064)\n",
      "Labels Shape: (32, 40, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load DEAP dataset (Change path accordingly)\n",
    "data_path = \"E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/data_preprocessed_matlab/\"\n",
    "subject_data = []\n",
    "subject_labels = []\n",
    "\n",
    "# Load all 32 subjects\n",
    "for i in range(1, 33):\n",
    "    mat = scipy.io.loadmat(f\"{data_path}s{i:02d}.mat\")\n",
    "    \n",
    "    # Extract EEG data and labels\n",
    "    subject_data.append(mat[\"data\"])     # Shape: (40 trials, 40 channels, 8064 samples)\n",
    "    subject_labels.append(mat[\"labels\"]) # Shape: (40 trials, 4 labels)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "subject_data = np.array(subject_data)     # Expected Shape: (32, 40, 40, 8064)\n",
    "subject_labels = np.array(subject_labels) # Expected Shape: (32, 40, 4)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(\"EEG Data Shape:\", subject_data.shape)   # (32, 40, 40, 8064)\n",
    "print(\"Labels Shape:\", subject_labels.shape)   # (32, 40, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE Feature Shape: (32, 40, 40, 5, 63)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "# Frequency band definitions\n",
    "freq_bands = {\n",
    "    \"delta\": (1, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 14),\n",
    "    \"beta\": (14, 30),\n",
    "    \"gamma\": (31, 50),\n",
    "}\n",
    "\n",
    "# Define function to compute Differential Entropy (DE)\n",
    "def compute_de(signal):\n",
    "    \"\"\"Compute Differential Entropy (DE) for a given EEG segment\"\"\"\n",
    "    variance = np.var(signal, axis=-1, keepdims=True)  # Compute variance\n",
    "    de = 0.5 * np.log(2 * np.pi * np.e * variance)  # Apply DE formula\n",
    "    return de.squeeze()  # Remove extra dimensions\n",
    "\n",
    "# Define function to extract DE features\n",
    "def extract_de_features(subject_data, fs=128, window_size=128):\n",
    "    \"\"\"\n",
    "    Extract DE features from EEG data.\n",
    "    - subject_data: EEG data of shape (32, 40, 40, 8064)\n",
    "    - fs: Sampling frequency (128 Hz)\n",
    "    - window_size: 1 second (128 samples)\n",
    "    Returns: DE feature array of shape (32, 40, 40, 5, 63)\n",
    "    \"\"\"\n",
    "    num_subjects, num_trials, num_channels, num_samples = subject_data.shape\n",
    "    num_bands = len(freq_bands)\n",
    "    num_windows = num_samples // window_size  # 8064 / 128 = 63 windows\n",
    "\n",
    "    # Initialize DE feature array\n",
    "    de_features = np.zeros((num_subjects, num_trials, num_channels, num_bands, num_windows))\n",
    "\n",
    "    # Loop through subjects, trials, and channels\n",
    "    for subj in range(num_subjects):\n",
    "        for trial in range(num_trials):\n",
    "            for ch in range(num_channels):\n",
    "                # Extract single-channel EEG data for this trial\n",
    "                signal = subject_data[subj, trial, ch, :]\n",
    "\n",
    "                # Apply bandpass filters and compute DE for each frequency band\n",
    "                for b_idx, (band, (low, high)) in enumerate(freq_bands.items()):\n",
    "                    # Bandpass filter\n",
    "                    sos = scipy.signal.butter(4, [low, high], btype=\"bandpass\", fs=fs, output=\"sos\")\n",
    "                    filtered_signal = scipy.signal.sosfilt(sos, signal)\n",
    "\n",
    "                    # Segment into 1-second windows (128 samples each)\n",
    "                    segmented = np.array(np.split(filtered_signal, num_windows, axis=-1))\n",
    "\n",
    "                    # Compute DE for each window\n",
    "                    de_features[subj, trial, ch, b_idx, :] = compute_de(segmented)\n",
    "\n",
    "    return de_features\n",
    "\n",
    "# Extract DE features\n",
    "de_features = extract_de_features(subject_data)\n",
    "\n",
    "# Print shape to confirm\n",
    "print(\"DE Feature Shape:\", de_features.shape)  # Expected: (32, 40, 40, 5, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(de_features))  # Should be <class 'numpy.ndarray'>, NOT a tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization Step - Shape: (32, 40, 40, 5, 63)\n",
      "Normalized DE Feature Shape: (32, 40, 40, 5, 63)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_de_features(de_features):\n",
    "    \"\"\"\n",
    "    Normalize DE features using Z-score normalization.\n",
    "    Ensures compatibility with NumPy arrays.\n",
    "    \"\"\"\n",
    "    de_features = np.array(de_features)  # Ensure NumPy format\n",
    "    print(\"Normalization Step - Shape:\", de_features.shape)  # Debugging\n",
    "\n",
    "    # Compute mean and std deviation across subjects & trials (axes 0,1), not windows\n",
    "    mean = np.mean(de_features, axis=(0, 1), keepdims=True)  \n",
    "    std = np.std(de_features, axis=(0, 1), keepdims=True)  \n",
    "\n",
    "    return (de_features - mean) / (std + 1e-6)  # Normalize & avoid division by zero\n",
    "\n",
    "# Apply normalization\n",
    "de_features = normalize_de_features(de_features)\n",
    "\n",
    "# Print shape to confirm\n",
    "print(\"Normalized DE Feature Shape:\", de_features.shape)  # Should remain (32, 40, 40, 5, 63)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Reduced Feature Shape: (32, 40, 1000)\n"
     ]
    }
   ],
   "source": [
    "### Reshaping defeatures\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reshape DE features to (1280, 12600)\n",
    "reshaped_features = de_features.reshape(-1, 12600)  \n",
    "\n",
    "# Apply PCA with the desired feature size (e.g., 500 instead of 200)\n",
    "pca = PCA(n_components=1000)\n",
    "pca_features = pca.fit_transform(reshaped_features)  # Shape: (1280, 500)\n",
    "\n",
    "# Reshape back to (32, 40, 500)\n",
    "pca_features = pca_features.reshape(32, 40, 1000)\n",
    "\n",
    "# Print shape to confirm\n",
    "print(\"PCA Reduced Feature Shape:\", pca_features.shape)  # Expected: (32, 40, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance by first 1000 components: 0.9912161190295471\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance by first 1000 components:\", sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMON FEATURE EXTRACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Common Feature Extractor (CFE)\n",
    "class CommonFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim=1000, output_dim=64):\n",
    "        super(CommonFeatureExtractor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHECKING CFE IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([32, 40, 500])\n",
      "Output Shape: torch.Size([1280, 64])\n"
     ]
    }
   ],
   "source": [
    "# Generate random input matching PCA-reduced feature size\n",
    "test_input = torch.randn(32, 40, 500)  # Batch of 32 subjects, 40 trials each\n",
    "\n",
    "# Initialize CFE model\n",
    "cfe = CommonFeatureExtractor(input_dim=500, output_dim=64)\n",
    "\n",
    "# Forward pass\n",
    "output = cfe(test_input.view(-1, 500))  # Flatten batch & trials\n",
    "\n",
    "# Check output shape\n",
    "print(\"Input Shape:\", test_input.shape)    # Expected: (32, 40, 500)\n",
    "print(\"Output Shape:\", output.shape)       # Expected: (32*40, 64) â†’ (1280, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
