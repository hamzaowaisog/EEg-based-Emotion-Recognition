{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2848cb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef7841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEAPDataset(Dataset):\n",
    "    def __init__(self, feature_path, label_path, exclude_subject=None, only_subject=None, normalize=True):\n",
    "        self.features = np.load(feature_path)  # shape: (32, 40, 40, 5, 63)\n",
    "        self.labels = np.load(label_path)      # shape: (32, 40, 63)\n",
    "        \n",
    "        # Compute statistics for normalization if requested\n",
    "        if normalize:\n",
    "            all_features = []\n",
    "            for subj in range(32):\n",
    "                if exclude_subject is not None and subj == exclude_subject:\n",
    "                    continue\n",
    "                if only_subject is not None and subj != only_subject:\n",
    "                    continue\n",
    "                \n",
    "                # Reshape to get all features for this subject\n",
    "                subj_features = self.features[subj].transpose(0, 1, 3, 2).reshape(-1, 40, 5)  # Result: (N, 40, 5)\n",
    "                all_features.append(subj_features)\n",
    "            \n",
    "            if all_features:  # Check if list is not empty\n",
    "                all_features = np.concatenate(all_features, axis=0)\n",
    "                self.mean = np.mean(all_features, axis=0)\n",
    "                self.std = np.std(all_features, axis=0) + 1e-8\n",
    "            else:\n",
    "                # Default if no subjects selected\n",
    "                self.mean = 0\n",
    "                self.std = 1\n",
    "        else:\n",
    "            self.mean = 0\n",
    "            self.std = 1\n",
    "            \n",
    "        # Prepare samples\n",
    "        self.samples = []\n",
    "        for subj in range(32):\n",
    "            if exclude_subject is not None and subj == exclude_subject:\n",
    "                continue\n",
    "            if only_subject is not None and subj != only_subject:\n",
    "                continue\n",
    "                \n",
    "            for trial in range(40):\n",
    "                for win in range(63):\n",
    "                    x = self.features[subj, trial, :, :, win]\n",
    "                    y = self.labels[subj, trial, win]\n",
    "                    self.samples.append((x, y, subj))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, subj = self.samples[idx]\n",
    "        # Normalize the data\n",
    "        x = (x - self.mean) / self.std\n",
    "        return torch.tensor(x, dtype=torch.float32), int(y)\n",
    "\n",
    "    def get_subject_data(self, subject):\n",
    "        return [(torch.tensor((x - self.mean) / self.std, dtype=torch.float32), int(y))\n",
    "                for x, y, subj in self.samples if subj == subject]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b208ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim=200):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # [batch, 40, 5] → [batch, 200]\n",
    "        x = self.act(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.act(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.act(self.bn3(self.fc3(x)))\n",
    "        return x\n",
    "\n",
    "class SubjectSpecificMapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(64, 32)\n",
    "        self.bn = nn.BatchNorm1d(32)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class SubjectSpecificClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(32, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f9f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        features = F.normalize(features, dim=1)\n",
    "        batch_size = features.shape[0]\n",
    "        \n",
    "        # Handle case where batch size is 1\n",
    "        if batch_size <= 1:\n",
    "            return torch.tensor(0.0, device=features.device, requires_grad=True)\n",
    "            \n",
    "        sim_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "        logits_mask = torch.ones_like(mask) - torch.eye(batch_size).to(features.device)\n",
    "        mask = mask * logits_mask\n",
    "        \n",
    "        # Handle case where there are no positive pairs\n",
    "        if mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=features.device, requires_grad=True)\n",
    "            \n",
    "        exp_sim = torch.exp(sim_matrix) * logits_mask\n",
    "        log_prob = sim_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-9)\n",
    "        loss = - (mask * log_prob).sum() / (mask.sum() + 1e-9)\n",
    "        return loss\n",
    "\n",
    "class MMDLoss(nn.Module):\n",
    "    def __init__(self, kernel_mul=2.0, num_kernels=5):\n",
    "        super().__init__()\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.num_kernels = num_kernels\n",
    "\n",
    "    def gaussian_kernel(self, source, target):\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        \n",
    "        # Handle small batch sizes\n",
    "        if total.shape[0] <= 1:\n",
    "            return torch.tensor(0.0, device=source.device, requires_grad=True)\n",
    "            \n",
    "        total0 = total.unsqueeze(0)\n",
    "        total1 = total.unsqueeze(1)\n",
    "        L2_distance = ((total0 - total1) ** 2).sum(2)\n",
    "        \n",
    "        # Prevent division by zero\n",
    "        bandwidth = torch.mean(L2_distance.detach()) + 1e-8\n",
    "        bandwidth_list = [bandwidth * (self.kernel_mul ** i) for i in range(self.num_kernels)]\n",
    "        kernels = [torch.exp(-L2_distance / bw) for bw in bandwidth_list]\n",
    "        return sum(kernels) / len(kernels)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        source = source.view(source.size(0), -1)\n",
    "        target = target.view(target.size(0), -1)\n",
    "        \n",
    "        # Handle empty batches\n",
    "        if source.shape[0] == 0 or target.shape[0] == 0:\n",
    "            return torch.tensor(0.0, device=source.device, requires_grad=True)\n",
    "            \n",
    "        kernels = self.gaussian_kernel(source, target)\n",
    "        batch_size = source.size(0)\n",
    "        XX = kernels[:batch_size, :batch_size]\n",
    "        YY = kernels[batch_size:, batch_size:]\n",
    "        XY = kernels[:batch_size, batch_size:]\n",
    "        YX = kernels[batch_size:, :batch_size]\n",
    "        return torch.mean(XX + YY - XY - YX)\n",
    "\n",
    "class ContrastiveLossLcon2(nn.Module):\n",
    "    def __init__(self, feature_dim=32, num_classes=4, tau=0.1, gamma=0.5, queue_size=1024):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        self.prototypes = nn.Parameter(torch.randn(num_classes, feature_dim))\n",
    "        self.register_buffer(\"queue\", torch.randn(queue_size, feature_dim))\n",
    "        self.queue = F.normalize(self.queue, dim=-1)\n",
    "\n",
    "    def forward(self, z_t, pseudo_labels):\n",
    "        # Handle empty batches\n",
    "        if z_t.shape[0] == 0:\n",
    "            return torch.tensor(0.0, device=z_t.device, requires_grad=True)\n",
    "            \n",
    "        z_t = F.normalize(z_t, dim=-1)\n",
    "        device = z_t.device\n",
    "        pseudo_labels = pseudo_labels.to(device)\n",
    "        \n",
    "        pos_proto = self.prototypes.to(device)[pseudo_labels]\n",
    "        \n",
    "        # Compute positive and negative logits\n",
    "        pos_logits = torch.sum(z_t * pos_proto, dim=-1) / self.tau\n",
    "        \n",
    "        # Handle case where queue is empty\n",
    "        if self.queue.shape[0] == 0:\n",
    "            return self.gamma * F.cross_entropy(pos_logits.unsqueeze(1), torch.zeros(z_t.size(0), dtype=torch.long, device=device))\n",
    "            \n",
    "        neg_logits = torch.matmul(z_t, self.queue.to(device).T) / self.tau\n",
    "        logits = torch.cat([pos_logits.unsqueeze(1), neg_logits], dim=1)\n",
    "        labels = torch.zeros(z_t.size(0), dtype=torch.long).to(device)\n",
    "        \n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        self._dequeue_and_enqueue(z_t)\n",
    "        return self.gamma * loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, embeddings):\n",
    "        embeddings = embeddings.detach().to(self.queue.device)\n",
    "        batch_size = embeddings.size(0)\n",
    "        queue_size = self.queue.size(0)\n",
    "        \n",
    "        if batch_size >= queue_size:\n",
    "            self.queue = embeddings[-queue_size:]\n",
    "        else:\n",
    "            self.queue = torch.cat([self.queue[batch_size:], embeddings], dim=0)\n",
    "\n",
    "class GeneralizedCrossEntropy(nn.Module):\n",
    "    def __init__(self, q=0.7, weight=None):\n",
    "        super().__init__()\n",
    "        self.q = q\n",
    "        self.weight = weight  # class weights (tensor)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Handle empty batches\n",
    "        if targets.shape[0] == 0:\n",
    "            return torch.tensor(0.0, device=logits.device, requires_grad=True)\n",
    "            \n",
    "        targets_onehot = F.one_hot(targets, num_classes=probs.shape[1]).float()\n",
    "        probs = torch.sum(probs * targets_onehot, dim=1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            weights = self.weight[targets]\n",
    "            loss = (1 - probs ** self.q) / self.q\n",
    "            return (weights * loss).mean()\n",
    "        else:\n",
    "            return ((1 - probs ** self.q) / self.q).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d36043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_batch(dataset, exclude, batch_size=64):\n",
    "    \"\"\"Get a batch of data from target subjects\"\"\"\n",
    "    for subj in range(32):\n",
    "        if subj != exclude:\n",
    "            data = dataset.get_subject_data(subj)\n",
    "            if len(data) >= batch_size:\n",
    "                indices = torch.randperm(len(data))[:batch_size]\n",
    "                x, y = zip(*[data[i] for i in indices])\n",
    "                return torch.stack(x), torch.tensor(y)\n",
    "    \n",
    "    # Fallback: Return a small batch if no subject has enough data\n",
    "    all_data = []\n",
    "    for subj in range(32):\n",
    "        if subj != exclude:\n",
    "            all_data.extend(dataset.get_subject_data(subj))\n",
    "    \n",
    "    if len(all_data) == 0:\n",
    "        # Empty tensor with correct shape as a fallback\n",
    "        empty_sample = next(iter(dataset))\n",
    "        return torch.zeros((0, *empty_sample[0].shape), dtype=torch.float32), torch.zeros(0, dtype=torch.long)\n",
    "        \n",
    "    indices = torch.randperm(len(all_data))[:min(batch_size, len(all_data))]\n",
    "    x, y = zip(*[all_data[i] for i in indices])\n",
    "    return torch.stack(x), torch.tensor(y)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, subject_idx):\n",
    "    \"\"\"Create and save confusion matrix plot\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - Subject {subject_idx+1}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(f'plots/confmat_subject{subject_idx+1}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3838163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting Fold 1/32 - Test Subject: s01\n",
      "Epoch [1/100] - Loss: 6.1770 - Con1: 6.1770 - MMD: 0.0042 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.1500\n",
      "Epoch [2/100] - Loss: 4.1407 - Con1: 4.1406 - MMD: 0.0054 - Train Acc: 0.0000\n",
      "Epoch [3/100] - Loss: 4.1355 - Con1: 4.1354 - MMD: 0.0040 - Train Acc: 0.0000\n",
      "Epoch [4/100] - Loss: 4.1309 - Con1: 4.1308 - MMD: 0.0039 - Train Acc: 0.0000\n",
      "Epoch [5/100] - Loss: 4.1265 - Con1: 4.1263 - MMD: 0.0038 - Train Acc: 0.0000\n",
      "Epoch [6/100] - Loss: 4.1222 - Con1: 4.1220 - MMD: 0.0039 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.1500\n",
      "Epoch [7/100] - Loss: 4.1182 - Con1: 4.1180 - MMD: 0.0036 - Train Acc: 0.0000\n",
      "Epoch [8/100] - Loss: 4.1156 - Con1: 4.1154 - MMD: 0.0036 - Cls: 0.0001 - Train Acc: 0.2662\n",
      "🏆 New best accuracy for fold 1: 0.2662\n",
      "Epoch [9/100] - Loss: 3.5984 - Con1: 4.1122 - MMD: 0.0036 - Cls: 0.0001 - Train Acc: 0.4504\n",
      "🏆 New best accuracy for fold 1: 0.4504\n",
      "Epoch [10/100] - Loss: 3.0831 - Con1: 4.1105 - MMD: 0.0036 - Cls: 0.0001 - Train Acc: 0.4744\n",
      "🏆 New best accuracy for fold 1: 0.4744\n",
      "Epoch [11/100] - Loss: 2.5726 - Con1: 4.1158 - MMD: 0.0035 - Cls: 0.0001 - Train Acc: 0.4637\n",
      "📊 Validation Accuracy on Subject 1: 0.1714\n",
      "Epoch [12/100] - Loss: 2.0572 - Con1: 4.1140 - MMD: 0.0026 - Cls: 0.0001 - Train Acc: 0.4688\n",
      "Epoch [13/100] - Loss: 1.5416 - Con1: 4.1102 - MMD: 0.0022 - Cls: 0.0000 - Train Acc: 0.4802\n",
      "🏆 New best accuracy for fold 1: 0.4802\n",
      "Epoch [14/100] - Loss: 1.0271 - Con1: 4.1075 - MMD: 0.0019 - Cls: 0.0000 - Train Acc: 0.4868\n",
      "🏆 New best accuracy for fold 1: 0.4868\n",
      "Epoch [15/100] - Loss: 0.5129 - Con1: 4.1014 - MMD: 0.0016 - Cls: 0.0000 - Train Acc: 0.4975\n",
      "🏆 New best accuracy for fold 1: 0.4975\n",
      "Epoch [16/100] - Loss: 3.5763 - Con2: 7.1522 - MMD: 0.0014 - Cls: 0.0000 - Train Acc: 0.4969\n",
      "📊 Validation Accuracy on Subject 1: 0.2167\n",
      "Epoch [17/100] - Loss: 3.5135 - Con2: 7.0266 - MMD: 0.0014 - Cls: 0.0000 - Train Acc: 0.4949\n",
      "Epoch [18/100] - Loss: 3.4456 - Con2: 6.8909 - MMD: 0.0012 - Cls: 0.0000 - Train Acc: 0.4846\n",
      "Epoch [19/100] - Loss: 3.3516 - Con2: 6.7028 - MMD: 0.0011 - Cls: 0.0000 - Train Acc: 0.4794\n",
      "Epoch [20/100] - Loss: 3.2079 - Con2: 6.4155 - MMD: 0.0010 - Cls: 0.0000 - Train Acc: 0.4701\n",
      "Epoch [21/100] - Loss: 0.0378 - Con2: 0.0756 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.1606\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [22/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [23/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [24/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [25/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [26/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [27/100] - Loss: 0.0038 - Con2: 0.0076 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.2031\n",
      "Epoch [28/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [29/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [30/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [31/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [32/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [33/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [34/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [35/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [36/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [37/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [38/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [39/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [40/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [41/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [42/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [43/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [44/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [45/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [46/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [47/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [48/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [49/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [50/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [51/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [52/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [53/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [54/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [55/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [56/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [57/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [58/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [59/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [60/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [61/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [62/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [63/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [64/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [65/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [66/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [67/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [68/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [69/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [70/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [71/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [72/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [73/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [74/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [75/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [76/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [77/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [78/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [79/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [80/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [81/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [82/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [83/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [84/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [85/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [86/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [87/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [88/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [89/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [90/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [91/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [92/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [93/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [94/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [95/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [96/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "Epoch [97/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [98/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [99/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [100/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 1: 0.2500\n",
      "🎯 Final Accuracy on Subject 1: 0.2500\n",
      "\n",
      "🚀 Starting Fold 2/32 - Test Subject: s02\n",
      "Epoch [1/100] - Loss: 6.1280 - Con1: 6.1280 - MMD: 0.0032 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.3151\n",
      "Epoch [2/100] - Loss: 4.1406 - Con1: 4.1406 - MMD: 0.0026 - Train Acc: 0.0000\n",
      "Epoch [3/100] - Loss: 4.1361 - Con1: 4.1360 - MMD: 0.0032 - Train Acc: 0.0000\n",
      "Epoch [4/100] - Loss: 4.1312 - Con1: 4.1311 - MMD: 0.0037 - Train Acc: 0.0000\n",
      "Epoch [5/100] - Loss: 4.1266 - Con1: 4.1264 - MMD: 0.0043 - Train Acc: 0.0000\n",
      "Epoch [6/100] - Loss: 4.1235 - Con1: 4.1234 - MMD: 0.0041 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2091\n",
      "Epoch [7/100] - Loss: 4.1186 - Con1: 4.1185 - MMD: 0.0037 - Train Acc: 0.0000\n",
      "Epoch [8/100] - Loss: 4.1159 - Con1: 4.1157 - MMD: 0.0039 - Cls: 0.0001 - Train Acc: 0.2540\n",
      "🏆 New best accuracy for fold 2: 0.2540\n",
      "Epoch [9/100] - Loss: 3.5989 - Con1: 4.1128 - MMD: 0.0039 - Cls: 0.0001 - Train Acc: 0.4496\n",
      "🏆 New best accuracy for fold 2: 0.4496\n",
      "Epoch [10/100] - Loss: 3.0837 - Con1: 4.1113 - MMD: 0.0037 - Cls: 0.0001 - Train Acc: 0.4777\n",
      "🏆 New best accuracy for fold 2: 0.4777\n",
      "Epoch [11/100] - Loss: 2.5742 - Con1: 4.1184 - MMD: 0.0025 - Cls: 0.0001 - Train Acc: 0.4597\n",
      "📊 Validation Accuracy on Subject 2: 0.1667\n",
      "Epoch [12/100] - Loss: 2.0577 - Con1: 4.1149 - MMD: 0.0025 - Cls: 0.0001 - Train Acc: 0.4721\n",
      "Epoch [13/100] - Loss: 1.5422 - Con1: 4.1119 - MMD: 0.0023 - Cls: 0.0000 - Train Acc: 0.4809\n",
      "🏆 New best accuracy for fold 2: 0.4809\n",
      "Epoch [14/100] - Loss: 1.0276 - Con1: 4.1097 - MMD: 0.0020 - Cls: 0.0000 - Train Acc: 0.4852\n",
      "🏆 New best accuracy for fold 2: 0.4852\n",
      "Epoch [15/100] - Loss: 0.5133 - Con1: 4.1047 - MMD: 0.0017 - Cls: 0.0000 - Train Acc: 0.4914\n",
      "🏆 New best accuracy for fold 2: 0.4914\n",
      "Epoch [16/100] - Loss: 3.7208 - Con2: 7.4413 - MMD: 0.0016 - Cls: 0.0000 - Train Acc: 0.5020\n",
      "🏆 New best accuracy for fold 2: 0.5020\n",
      "📊 Validation Accuracy on Subject 2: 0.1619\n",
      "Epoch [17/100] - Loss: 3.6990 - Con2: 7.3976 - MMD: 0.0014 - Cls: 0.0000 - Train Acc: 0.4983\n",
      "Epoch [18/100] - Loss: 3.6110 - Con2: 7.2216 - MMD: 0.0014 - Cls: 0.0000 - Train Acc: 0.4923\n",
      "Epoch [19/100] - Loss: 3.6375 - Con2: 7.2747 - MMD: 0.0013 - Cls: 0.0000 - Train Acc: 0.4875\n",
      "Epoch [20/100] - Loss: 3.0559 - Con2: 6.1115 - MMD: 0.0010 - Cls: 0.0000 - Train Acc: 0.4692\n",
      "Epoch [21/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2202\n",
      "Epoch [22/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [23/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [24/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [25/100] - Loss: 0.0155 - Con2: 0.0309 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.1979\n",
      "Epoch [26/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "Epoch [27/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [28/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [29/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [30/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [31/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2004\n",
      "Epoch [32/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [33/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [34/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [35/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [36/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "Epoch [37/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [38/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [39/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [40/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [41/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "Epoch [42/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [43/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [44/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [45/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [46/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "Epoch [47/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [48/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [49/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [50/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [51/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "Epoch [52/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [53/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [54/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [55/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [56/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "Epoch [57/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [58/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [59/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [60/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [61/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "Epoch [62/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [63/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [64/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [65/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [66/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2004\n",
      "Epoch [67/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [68/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [69/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [70/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [71/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2004\n",
      "Epoch [72/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [73/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [74/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [75/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [76/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2004\n",
      "Epoch [77/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [78/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [79/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [80/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [81/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "Epoch [82/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [83/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [84/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [85/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [86/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2004\n",
      "Epoch [87/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [88/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [89/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [90/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [91/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2004\n",
      "Epoch [92/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [93/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [94/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [95/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [96/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "Epoch [97/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [98/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [99/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [100/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 2: 0.2000\n",
      "🎯 Final Accuracy on Subject 2: 0.2000\n",
      "\n",
      "🚀 Starting Fold 3/32 - Test Subject: s03\n",
      "Epoch [1/100] - Loss: 6.1687 - Con1: 6.1687 - MMD: 0.0032 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.3925\n",
      "Epoch [2/100] - Loss: 4.1417 - Con1: 4.1417 - MMD: 0.0034 - Train Acc: 0.0000\n",
      "Epoch [3/100] - Loss: 4.1370 - Con1: 4.1369 - MMD: 0.0036 - Train Acc: 0.0000\n",
      "Epoch [4/100] - Loss: 4.1322 - Con1: 4.1321 - MMD: 0.0038 - Train Acc: 0.0000\n",
      "Epoch [5/100] - Loss: 4.1287 - Con1: 4.1286 - MMD: 0.0038 - Train Acc: 0.0000\n",
      "Epoch [6/100] - Loss: 4.1244 - Con1: 4.1243 - MMD: 0.0038 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.2627\n",
      "Epoch [7/100] - Loss: 4.1202 - Con1: 4.1201 - MMD: 0.0034 - Train Acc: 0.0000\n",
      "Epoch [8/100] - Loss: 4.1176 - Con1: 4.1174 - MMD: 0.0037 - Cls: 0.0001 - Train Acc: 0.2741\n",
      "🏆 New best accuracy for fold 3: 0.2741\n",
      "Epoch [9/100] - Loss: 3.5993 - Con1: 4.1132 - MMD: 0.0034 - Cls: 0.0001 - Train Acc: 0.4305\n",
      "🏆 New best accuracy for fold 3: 0.4305\n",
      "Epoch [10/100] - Loss: 3.0850 - Con1: 4.1130 - MMD: 0.0036 - Cls: 0.0001 - Train Acc: 0.4584\n",
      "🏆 New best accuracy for fold 3: 0.4584\n",
      "Epoch [11/100] - Loss: 2.5744 - Con1: 4.1187 - MMD: 0.0031 - Cls: 0.0001 - Train Acc: 0.4540\n",
      "📊 Validation Accuracy on Subject 3: 0.3385\n",
      "Epoch [12/100] - Loss: 2.0587 - Con1: 4.1170 - MMD: 0.0025 - Cls: 0.0001 - Train Acc: 0.4622\n",
      "🏆 New best accuracy for fold 3: 0.4622\n",
      "Epoch [13/100] - Loss: 1.5424 - Con1: 4.1125 - MMD: 0.0022 - Cls: 0.0001 - Train Acc: 0.4744\n",
      "🏆 New best accuracy for fold 3: 0.4744\n",
      "Epoch [14/100] - Loss: 1.0274 - Con1: 4.1089 - MMD: 0.0018 - Cls: 0.0000 - Train Acc: 0.4803\n",
      "🏆 New best accuracy for fold 3: 0.4803\n",
      "Epoch [15/100] - Loss: 0.5133 - Con1: 4.1047 - MMD: 0.0016 - Cls: 0.0000 - Train Acc: 0.4903\n",
      "🏆 New best accuracy for fold 3: 0.4903\n",
      "Epoch [16/100] - Loss: 2.2714 - Con2: 4.5423 - MMD: 0.0016 - Cls: 0.0000 - Train Acc: 0.4918\n",
      "🏆 New best accuracy for fold 3: 0.4918\n",
      "📊 Validation Accuracy on Subject 3: 0.1175\n",
      "Epoch [17/100] - Loss: 2.2679 - Con2: 4.5353 - MMD: 0.0015 - Cls: 0.0000 - Train Acc: 0.4943\n",
      "🏆 New best accuracy for fold 3: 0.4943\n",
      "Epoch [18/100] - Loss: 2.2685 - Con2: 4.5366 - MMD: 0.0015 - Cls: 0.0000 - Train Acc: 0.4875\n",
      "Epoch [19/100] - Loss: 2.2498 - Con2: 4.4993 - MMD: 0.0014 - Cls: 0.0000 - Train Acc: 0.4814\n",
      "Epoch [20/100] - Loss: 0.8105 - Con2: 1.6209 - MMD: 0.0005 - Cls: 0.0000 - Train Acc: 0.4614\n",
      "Epoch [21/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [22/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [23/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [24/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [25/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [26/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [27/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [28/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [29/100] - Loss: 0.0029 - Con2: 0.0057 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.2500\n",
      "Epoch [30/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [31/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [32/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [33/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [34/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [35/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [36/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [37/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [38/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [39/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [40/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [41/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [42/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [43/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [44/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [45/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [46/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [47/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [48/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [49/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [50/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [51/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [52/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [53/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [54/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [55/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [56/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [57/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [58/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [59/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [60/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [61/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [62/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [63/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [64/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [65/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [66/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [67/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [68/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [69/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [70/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [71/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [72/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [73/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [74/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [75/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [76/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.5250\n",
      "Epoch [77/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [78/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [79/100] - Loss: 0.2379 - Con2: 0.4757 - MMD: 0.0001 - Cls: 0.0000 - Train Acc: 0.2579\n",
      "Epoch [80/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [81/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.3810\n",
      "Epoch [82/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [83/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [84/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [85/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [86/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.3706\n",
      "Epoch [87/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [88/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [89/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [90/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [91/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.3718\n",
      "Epoch [92/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [93/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [94/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [95/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [96/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.3726\n",
      "Epoch [97/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [98/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [99/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [100/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 3: 0.3798\n",
      "🎯 Final Accuracy on Subject 3: 0.3798\n",
      "\n",
      "🚀 Starting Fold 4/32 - Test Subject: s04\n",
      "Epoch [1/100] - Loss: 6.1690 - Con1: 6.1690 - MMD: 0.0033 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4143\n",
      "Epoch [2/100] - Loss: 4.1416 - Con1: 4.1415 - MMD: 0.0029 - Train Acc: 0.0000\n",
      "Epoch [3/100] - Loss: 4.1372 - Con1: 4.1371 - MMD: 0.0032 - Train Acc: 0.0000\n",
      "Epoch [4/100] - Loss: 4.1331 - Con1: 4.1330 - MMD: 0.0035 - Train Acc: 0.0000\n",
      "Epoch [5/100] - Loss: 4.1290 - Con1: 4.1289 - MMD: 0.0031 - Train Acc: 0.0000\n",
      "Epoch [6/100] - Loss: 4.1257 - Con1: 4.1256 - MMD: 0.0033 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4972\n",
      "Epoch [7/100] - Loss: 4.1214 - Con1: 4.1212 - MMD: 0.0033 - Train Acc: 0.0000\n",
      "Epoch [8/100] - Loss: 4.1176 - Con1: 4.1174 - MMD: 0.0033 - Cls: 0.0001 - Train Acc: 0.2507\n",
      "🏆 New best accuracy for fold 4: 0.2507\n",
      "Epoch [9/100] - Loss: 3.6002 - Con1: 4.1143 - MMD: 0.0031 - Cls: 0.0001 - Train Acc: 0.4142\n",
      "🏆 New best accuracy for fold 4: 0.4142\n",
      "Epoch [10/100] - Loss: 3.0852 - Con1: 4.1133 - MMD: 0.0033 - Cls: 0.0001 - Train Acc: 0.4500\n",
      "🏆 New best accuracy for fold 4: 0.4500\n",
      "Epoch [11/100] - Loss: 2.5748 - Con1: 4.1193 - MMD: 0.0028 - Cls: 0.0001 - Train Acc: 0.4470\n",
      "📊 Validation Accuracy on Subject 4: 0.1218\n",
      "Epoch [12/100] - Loss: 2.0589 - Con1: 4.1174 - MMD: 0.0025 - Cls: 0.0001 - Train Acc: 0.4609\n",
      "🏆 New best accuracy for fold 4: 0.4609\n",
      "Epoch [13/100] - Loss: 1.5428 - Con1: 4.1136 - MMD: 0.0020 - Cls: 0.0001 - Train Acc: 0.4708\n",
      "🏆 New best accuracy for fold 4: 0.4708\n",
      "Epoch [14/100] - Loss: 1.0279 - Con1: 4.1107 - MMD: 0.0020 - Cls: 0.0001 - Train Acc: 0.4782\n",
      "🏆 New best accuracy for fold 4: 0.4782\n",
      "Epoch [15/100] - Loss: 0.5134 - Con1: 4.1054 - MMD: 0.0017 - Cls: 0.0000 - Train Acc: 0.4873\n",
      "🏆 New best accuracy for fold 4: 0.4873\n",
      "Epoch [16/100] - Loss: 2.5849 - Con2: 5.1694 - MMD: 0.0015 - Cls: 0.0000 - Train Acc: 0.4847\n",
      "📊 Validation Accuracy on Subject 4: 0.4940\n",
      "Epoch [17/100] - Loss: 2.6519 - Con2: 5.3033 - MMD: 0.0014 - Cls: 0.0000 - Train Acc: 0.4772\n",
      "Epoch [18/100] - Loss: 2.6827 - Con2: 5.3650 - MMD: 0.0014 - Cls: 0.0000 - Train Acc: 0.4804\n",
      "Epoch [19/100] - Loss: 2.7799 - Con2: 5.5594 - MMD: 0.0012 - Cls: 0.0000 - Train Acc: 0.4795\n",
      "Epoch [20/100] - Loss: 2.4409 - Con2: 4.8815 - MMD: 0.0011 - Cls: 0.0000 - Train Acc: 0.4696\n",
      "Epoch [21/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4897\n",
      "Epoch [22/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [23/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [24/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [25/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [26/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4901\n",
      "Epoch [27/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [28/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [29/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [30/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [31/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4869\n",
      "Epoch [32/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [33/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [34/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [35/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [36/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4952\n",
      "Epoch [37/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [38/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [39/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [40/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [41/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4913\n",
      "Epoch [42/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [43/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [44/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [45/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [46/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4921\n",
      "Epoch [47/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [48/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [49/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [50/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [51/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4956\n",
      "Epoch [52/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [53/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [54/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [55/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [56/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4952\n",
      "Epoch [57/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [58/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [59/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [60/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [61/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4937\n",
      "Epoch [62/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [63/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [64/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [65/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [66/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4952\n",
      "Epoch [67/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [68/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [69/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [70/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [71/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4937\n",
      "Epoch [72/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [73/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [74/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [75/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [76/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "📊 Validation Accuracy on Subject 4: 0.4948\n",
      "Epoch [77/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [78/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n",
      "Epoch [79/100] - Loss: 0.0000 - Con2: 0.0000 - MMD: 0.0000 - Cls: 0.0000 - Train Acc: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 290\u001b[0m\n\u001b[0;32m    287\u001b[0m label_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_labels.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m fold_accuracies, global_true, global_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_subjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 72\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(feature_path, label_path, num_subjects, num_epochs, warmup_epochs, batch_size)\u001b[0m\n\u001b[0;32m     69\u001b[0m x_s, y_s \u001b[38;5;241m=\u001b[39m x_s\u001b[38;5;241m.\u001b[39mto(device), y_s\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Get target batch\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m x_t, y_t \u001b[38;5;241m=\u001b[39m \u001b[43mget_target_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_subject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m x_t, y_t \u001b[38;5;241m=\u001b[39m x_t\u001b[38;5;241m.\u001b[39mto(device), y_t\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Skip this batch if either source or target is empty\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m, in \u001b[0;36mget_target_batch\u001b[1;34m(dataset, exclude, batch_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subj \u001b[38;5;241m!=\u001b[39m exclude:\n\u001b[1;32m----> 5\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_subject_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size:\n\u001b[0;32m      7\u001b[0m             indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandperm(\u001b[38;5;28mlen\u001b[39m(data))[:batch_size]\n",
      "Cell \u001b[1;32mIn[9], line 55\u001b[0m, in \u001b[0;36mDEAPDataset.get_subject_data\u001b[1;34m(self, subject)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_subject_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, subject):\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mint\u001b[39m(y))\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m x, y, subj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;28;01mif\u001b[39;00m subj \u001b[38;5;241m==\u001b[39m subject]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(feature_path, label_path, num_subjects=32, num_epochs=100, \n",
    "                warmup_epochs=15, batch_size=64):\n",
    "    \"\"\"Main training function for all folds\"\"\"\n",
    "    \n",
    "    # Hyperparameters\n",
    "    lambda_1 = 1.0  # For contrastive_loss_con1 during warmup\n",
    "    lambda_2 = 0.5  # For contrastive_loss_con2 after warmup\n",
    "    lambda_3_init = 0.1  # Initial value for MMD loss\n",
    "    \n",
    "    # Logging containers\n",
    "    fold_accuracies = []\n",
    "    global_true = []\n",
    "    global_pred = []\n",
    "    \n",
    "    for test_subject in range(num_subjects):\n",
    "        print(f\"\\n🚀 Starting Fold {test_subject+1}/{num_subjects} - Test Subject: s{test_subject+1:02d}\")\n",
    "        \n",
    "        # Create datasets and loaders\n",
    "        train_dataset = DEAPDataset(feature_path, label_path, exclude_subject=test_subject, normalize=True)\n",
    "        test_dataset = DEAPDataset(feature_path, label_path, only_subject=test_subject, normalize=True)\n",
    "        \n",
    "        # Create balanced sampler\n",
    "        all_labels = np.array([label for _, label in train_dataset])\n",
    "        class_sample_counts = np.bincount(all_labels)\n",
    "        class_weights = 1. / class_sample_counts\n",
    "        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "        sample_weights = [class_weights[label] for label in all_labels]\n",
    "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Initialize models\n",
    "        cfe = CommonFeatureExtractor().to(device)\n",
    "        sfe = SubjectSpecificMapper().to(device)\n",
    "        ssc = SubjectSpecificClassifier().to(device)\n",
    "        \n",
    "        # Initialize losses\n",
    "        contrastive_loss_con1 = SupervisedContrastiveLoss(temperature=0.03).to(device)\n",
    "        contrastive_loss_con2 = ContrastiveLossLcon2(tau=0.1).to(device)\n",
    "        mmd_loss = MMDLoss().to(device)\n",
    "        gce_loss = GeneralizedCrossEntropy(q=0.3, weight=class_weights_tensor).to(device)\n",
    "        \n",
    "        # Initialize optimizer and scheduler\n",
    "        all_params = list(cfe.parameters()) + list(sfe.parameters()) + list(ssc.parameters())\n",
    "        optimizer = torch.optim.AdamW(all_params, lr=1e-3, weight_decay=1e-4)\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "        \n",
    "        # Training tracking\n",
    "        best_acc = 0\n",
    "        transition_start = warmup_epochs // 2\n",
    "        \n",
    "        # Track loss components\n",
    "        loss_history = {\n",
    "            'total': [], 'con1': [], 'con2': [], 'mmd': [], 'cls': [],\n",
    "            'train_acc': [], 'val_acc': []\n",
    "        }\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            cfe.train()\n",
    "            sfe.train()\n",
    "            ssc.train()\n",
    "            \n",
    "            epoch_losses = {'total': 0, 'con1': 0, 'con2': 0, 'mmd': 0, 'cls': 0}\n",
    "            total_correct, total_samples = 0, 0\n",
    "            \n",
    "            for x_s, y_s in train_loader:\n",
    "                x_s, y_s = x_s.to(device), y_s.to(device)\n",
    "                \n",
    "                # Get target batch\n",
    "                x_t, y_t = get_target_batch(train_dataset, exclude=test_subject, batch_size=batch_size)\n",
    "                x_t, y_t = x_t.to(device), y_t.to(device)\n",
    "                \n",
    "                # Skip this batch if either source or target is empty\n",
    "                if x_s.shape[0] == 0 or x_t.shape[0] == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Match batch sizes\n",
    "                min_size = min(x_s.size(0), x_t.size(0))\n",
    "                x_s = x_s[:min_size]\n",
    "                y_s = y_s[:min_size]\n",
    "                x_t = x_t[:min_size]\n",
    "                y_t = y_t[:min_size]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Extract features\n",
    "                z_s_common = cfe(x_s)\n",
    "                z_t_common = cfe(x_t)\n",
    "                \n",
    "                # Always extract subject-specific features\n",
    "                z_s_subject = sfe(z_s_common)\n",
    "                z_t_subject = sfe(z_t_common)\n",
    "                \n",
    "                # Domain adaptation loss (always applied)\n",
    "                loss_mmd = mmd_loss(z_s_common, z_t_common)\n",
    "                \n",
    "                # Adjusted MMD weight - gradually increase during warmup\n",
    "                lambda_3 = lambda_3_init\n",
    "                if epoch < warmup_epochs:\n",
    "                    lambda_3 = lambda_3_init * (epoch + 1) / warmup_epochs\n",
    "                \n",
    "                # Different training phases\n",
    "                if epoch < transition_start:\n",
    "                    # Pure contrastive phase\n",
    "                    loss_con1 = contrastive_loss_con1(z_s_common, y_s)\n",
    "                    loss = lambda_1 * loss_con1 + lambda_3 * loss_mmd\n",
    "                    \n",
    "                    # Track loss components\n",
    "                    epoch_losses['con1'] += loss_con1.item()\n",
    "                    epoch_losses['mmd'] += loss_mmd.item()\n",
    "                    \n",
    "                elif epoch < warmup_epochs:\n",
    "                    # Transition phase - gradually introduce classification\n",
    "                    transition_factor = (epoch - transition_start) / (warmup_epochs - transition_start)\n",
    "                    \n",
    "                    loss_con1 = contrastive_loss_con1(z_s_common, y_s)\n",
    "                    logits = ssc(z_s_subject)\n",
    "                    loss_cls = gce_loss(logits, y_s)\n",
    "                    \n",
    "                    loss = (1 - transition_factor) * (lambda_1 * loss_con1) + \\\n",
    "                           transition_factor * loss_cls + lambda_3 * loss_mmd\n",
    "                    \n",
    "                    # Track loss components\n",
    "                    epoch_losses['con1'] += loss_con1.item()\n",
    "                    epoch_losses['cls'] += loss_cls.item()\n",
    "                    epoch_losses['mmd'] += loss_mmd.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    preds = torch.argmax(logits, dim=1)\n",
    "                    total_correct += (preds == y_s).sum().item()\n",
    "                    total_samples += y_s.size(0)\n",
    "                    \n",
    "                else:\n",
    "                    # Full classification phase\n",
    "                    logits = ssc(z_s_subject)\n",
    "                    loss_cls = gce_loss(logits, y_s)\n",
    "                    \n",
    "                    # Use pseudo labels for target domain\n",
    "                    with torch.no_grad():\n",
    "                        pseudo_logits = ssc(z_t_subject)\n",
    "                        pseudo_probs = F.softmax(pseudo_logits, dim=1)\n",
    "                        pseudo_conf, pseudo_labels = torch.max(pseudo_probs, dim=1)\n",
    "                        confident_mask = pseudo_conf > 0.5\n",
    "                        if confident_mask.sum() == 0:\n",
    "                            continue\n",
    "                        z_t_subject = z_t_subject[confident_mask]\n",
    "                        pseudo_labels = pseudo_labels[confident_mask]\n",
    "                    \n",
    "                    loss_con2 = contrastive_loss_con2(z_t_subject, pseudo_labels)\n",
    "                    loss = loss_cls + lambda_2 * loss_con2 + lambda_3 * loss_mmd\n",
    "                    \n",
    "                    # Track loss components\n",
    "                    epoch_losses['cls'] += loss_cls.item()\n",
    "                    epoch_losses['con2'] += loss_con2.item()\n",
    "                    epoch_losses['mmd'] += loss_mmd.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    preds = torch.argmax(logits, dim=1)\n",
    "                    total_correct += (preds == y_s).sum().item()\n",
    "                    total_samples += y_s.size(0)\n",
    "                \n",
    "                # Update total loss\n",
    "                epoch_losses['total'] += loss.item()\n",
    "                \n",
    "                # Backpropagation with gradient clipping\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(all_params, max_norm=1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Calculate average losses\n",
    "            num_batches = len(train_loader)\n",
    "            avg_total_loss = epoch_losses['total'] / num_batches\n",
    "            avg_train_acc = total_correct / total_samples if total_samples > 0 else 0\n",
    "            \n",
    "            # Update loss history\n",
    "            loss_history['total'].append(avg_total_loss)\n",
    "            loss_history['train_acc'].append(avg_train_acc)\n",
    "            \n",
    "            for key in ['con1', 'con2', 'mmd', 'cls']:\n",
    "                if epoch_losses[key] > 0:\n",
    "                    loss_history[key].append(epoch_losses[key] / num_batches)\n",
    "                else:\n",
    "                    loss_history[key].append(0)\n",
    "            \n",
    "            # Print progress\n",
    "            progress_str = f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_total_loss:.4f}\"\n",
    "            if epoch < warmup_epochs:\n",
    "                progress_str += f\" - Con1: {loss_history['con1'][-1]:.4f}\"\n",
    "            else:\n",
    "                progress_str += f\" - Con2: {loss_history['con2'][-1]:.4f}\"\n",
    "            \n",
    "            progress_str += f\" - MMD: {loss_history['mmd'][-1]:.4f}\"\n",
    "            \n",
    "            if epoch >= transition_start:\n",
    "                progress_str += f\" - Cls: {loss_history['cls'][-1]:.4f}\"\n",
    "                \n",
    "            progress_str += f\" - Train Acc: {avg_train_acc:.4f}\"\n",
    "            print(progress_str)\n",
    "            \n",
    "            # Save checkpoint if accuracy improves\n",
    "            if avg_train_acc > best_acc:\n",
    "                best_acc = avg_train_acc\n",
    "                print(f\"🏆 New best accuracy for fold {test_subject+1}: {best_acc:.4f}\")\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'cfe_state_dict': cfe.state_dict(),\n",
    "                    'sfe_state_dict': sfe.state_dict(),\n",
    "                    'ssc_state_dict': ssc.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'loss': avg_total_loss,\n",
    "                    'accuracy': avg_train_acc\n",
    "                }, f\"checkpoints/fold{test_subject+1}_best.pt\")\n",
    "            \n",
    "            # Evaluation after each epoch\n",
    "            if epoch % 5 == 0 or epoch == num_epochs - 1:\n",
    "                cfe.eval()\n",
    "                sfe.eval()\n",
    "                ssc.eval()\n",
    "                \n",
    "                all_preds, all_labels = [], []\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for x_test, y_test in test_loader:\n",
    "                        x_test = x_test.to(device)\n",
    "                        z_common = cfe(x_test)\n",
    "                        z_subject = sfe(z_common)\n",
    "                        logits = ssc(z_subject)\n",
    "                        preds = torch.argmax(logits, dim=1)\n",
    "                        \n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "                        all_labels.extend(y_test.numpy())\n",
    "                \n",
    "                val_acc = accuracy_score(all_labels, all_preds)\n",
    "                loss_history['val_acc'].append(val_acc)\n",
    "                print(f\"📊 Validation Accuracy on Subject {test_subject+1}: {val_acc:.4f}\")\n",
    "        \n",
    "        # Final evaluation\n",
    "        cfe.eval()\n",
    "        sfe.eval()\n",
    "        ssc.eval()\n",
    "        \n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_test = x_test.to(device)\n",
    "                z_common = cfe(x_test)\n",
    "                z_subject = sfe(z_common)\n",
    "                logits = ssc(z_subject)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y_test.numpy())\n",
    "        \n",
    "        final_acc = accuracy_score(all_labels, all_preds)\n",
    "        fold_accuracies.append(final_acc)\n",
    "        print(f\"🎯 Final Accuracy on Subject {test_subject+1}: {final_acc:.4f}\")\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(all_labels, all_preds, test_subject)\n",
    "        global_true.extend(all_labels)\n",
    "        global_pred.extend(all_preds)\n",
    "        \n",
    "        # Save loss history for this fold\n",
    "        np.save(f\"logs/fold{test_subject+1}_loss_history.npy\", loss_history)\n",
    "    \n",
    "    # Final report\n",
    "    print(\"\\n✅ Training complete.\")\n",
    "    print(\"Subject-wise accuracies:\", fold_accuracies)\n",
    "    print(\"Average Accuracy:\", np.mean(fold_accuracies))\n",
    "    print(\"Overall Accuracy:\", accuracy_score(global_true, global_pred))\n",
    "    \n",
    "    # Plot overall confusion matrix\n",
    "    plot_confusion_matrix(global_true, global_pred, 32)  # Use index 32 for global\n",
    "    \n",
    "    return fold_accuracies, global_true, global_pred\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths to your data\n",
    "    feature_path = 'E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_features.npy'\n",
    "    label_path = 'E:/FYP/Finalise Fyp/EEg-based-Emotion-Recognition/de_labels.npy'\n",
    "    \n",
    "    # Run training\n",
    "    fold_accuracies, global_true, global_pred = train_model(\n",
    "        feature_path=feature_path,\n",
    "        label_path=label_path,\n",
    "        num_subjects=32,\n",
    "        num_epochs=100,\n",
    "        warmup_epochs=15,\n",
    "        batch_size=64\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c2ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
