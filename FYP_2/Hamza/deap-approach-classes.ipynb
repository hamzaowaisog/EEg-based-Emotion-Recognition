{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-09T18:07:15.828610Z",
     "iopub.status.busy": "2025-03-09T18:07:15.828273Z",
     "iopub.status.idle": "2025-03-09T18:07:20.032608Z",
     "shell.execute_reply": "2025-03-09T18:07:20.031665Z",
     "shell.execute_reply.started": "2025-03-09T18:07:15.828582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:07:20.034229Z",
     "iopub.status.busy": "2025-03-09T18:07:20.033782Z",
     "iopub.status.idle": "2025-03-09T18:07:59.470680Z",
     "shell.execute_reply": "2025-03-09T18:07:59.469917Z",
     "shell.execute_reply.started": "2025-03-09T18:07:20.034198Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Data Shape: (32, 40, 40, 8064)\n",
      "Labels Shape: (32, 40, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load DEAP dataset (Change path accordingly)\n",
    "data_path = \"/kaggle/input/deap-matlab/\"\n",
    "subject_data = []\n",
    "subject_labels = []\n",
    "\n",
    "# Load all 32 subjects\n",
    "for i in range(1, 33):\n",
    "    mat = scipy.io.loadmat(f\"{data_path}s{i:02d}.mat\")\n",
    "    \n",
    "    # Extract EEG data and labels\n",
    "    subject_data.append(mat[\"data\"])     # Shape: (40 trials, 40 channels, 8064 samples)\n",
    "    subject_labels.append(mat[\"labels\"]) # Shape: (40 trials, 4 labels)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "subject_data = np.array(subject_data)     # Expected Shape: (32, 40, 40, 8064)\n",
    "subject_labels = np.array(subject_labels) # Expected Shape: (32, 40, 4)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(\"EEG Data Shape:\", subject_data.shape)   # (32, 40, 40, 8064)\n",
    "print(\"Labels Shape:\", subject_labels.shape)   # (32, 40, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:07:59.472418Z",
     "iopub.status.busy": "2025-03-09T18:07:59.472170Z",
     "iopub.status.idle": "2025-03-09T18:13:03.280860Z",
     "shell.execute_reply": "2025-03-09T18:13:03.280053Z",
     "shell.execute_reply.started": "2025-03-09T18:07:59.472398Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE Feature Shape: (32, 40, 40, 5, 63)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "# Frequency band definitions\n",
    "freq_bands = {\n",
    "    \"delta\": (1, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 14),\n",
    "    \"beta\": (14, 30),\n",
    "    \"gamma\": (31, 50),\n",
    "}\n",
    "\n",
    "# Define function to compute Differential Entropy (DE)\n",
    "def compute_de(signal):\n",
    "    \"\"\"Compute Differential Entropy (DE) for a given EEG segment\"\"\"\n",
    "    variance = np.var(signal, axis=-1, keepdims=True)  # Compute variance\n",
    "    de = 0.5 * np.log(2 * np.pi * np.e * variance)  # Apply DE formula\n",
    "    return de.squeeze()  # Remove extra dimensions\n",
    "\n",
    "# Define function to extract DE features\n",
    "def extract_de_features(subject_data, fs=128, window_size=128):\n",
    "    \"\"\"\n",
    "    Extract DE features from EEG data.\n",
    "    - subject_data: EEG data of shape (32, 40, 40, 8064)\n",
    "    - fs: Sampling frequency (128 Hz)\n",
    "    - window_size: 1 second (128 samples)\n",
    "    Returns: DE feature array of shape (32, 40, 40, 5, 63)\n",
    "    \"\"\"\n",
    "    num_subjects, num_trials, num_channels, num_samples = subject_data.shape\n",
    "    num_bands = len(freq_bands)\n",
    "    num_windows = num_samples // window_size  # 8064 / 128 = 63 windows\n",
    "\n",
    "    # Initialize DE feature array\n",
    "    de_features = np.zeros((num_subjects, num_trials, num_channels, num_bands, num_windows))\n",
    "\n",
    "    # Loop through subjects, trials, and channels\n",
    "    for subj in range(num_subjects):\n",
    "        for trial in range(num_trials):\n",
    "            for ch in range(num_channels):\n",
    "                # Extract single-channel EEG data for this trial\n",
    "                signal = subject_data[subj, trial, ch, :]\n",
    "\n",
    "                # Apply bandpass filters and compute DE for each frequency band\n",
    "                for b_idx, (band, (low, high)) in enumerate(freq_bands.items()):\n",
    "                    # Bandpass filter\n",
    "                    sos = scipy.signal.butter(4, [low, high], btype=\"bandpass\", fs=fs, output=\"sos\")\n",
    "                    filtered_signal = scipy.signal.sosfilt(sos, signal)\n",
    "\n",
    "                    # Segment into 1-second windows (128 samples each)\n",
    "                    segmented = np.array(np.split(filtered_signal, num_windows, axis=-1))\n",
    "\n",
    "                    # Compute DE for each window\n",
    "                    de_features[subj, trial, ch, b_idx, :] = compute_de(segmented)\n",
    "\n",
    "    return de_features\n",
    "\n",
    "# Extract DE features\n",
    "de_features = extract_de_features(subject_data)\n",
    "\n",
    "# Print shape to confirm\n",
    "print(\"DE Feature Shape:\", de_features.shape)  # Expected: (32, 40, 40, 5, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:13:03.282884Z",
     "iopub.status.busy": "2025-03-09T18:13:03.282596Z",
     "iopub.status.idle": "2025-03-09T18:13:03.289075Z",
     "shell.execute_reply": "2025-03-09T18:13:03.288257Z",
     "shell.execute_reply.started": "2025-03-09T18:13:03.282861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "1. Common Feature Extractor (CFE)\n",
    "class CommonFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim=200, output_dim=64):\n",
    "        super(CommonFeatureExtractor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:13:03.290205Z",
     "iopub.status.busy": "2025-03-09T18:13:03.289980Z",
     "iopub.status.idle": "2025-03-09T18:13:03.311295Z",
     "shell.execute_reply": "2025-03-09T18:13:03.310611Z",
     "shell.execute_reply.started": "2025-03-09T18:13:03.290187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Contrastive Loss L_con1\n",
    "class ContrastiveLossLcon1(nn.Module):\n",
    "    def __init__(self, tau=0.2):\n",
    "        super(ContrastiveLossLcon1, self).__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, q):\n",
    "        batch_size = q.shape[0]\n",
    "        q = F.normalize(q, dim=-1)\n",
    "        sim_matrix = torch.mm(q, q.T)  \n",
    "        mask = torch.eye(batch_size, dtype=torch.bool, device=q.device)\n",
    "        sim_matrix.masked_fill_(mask, -5.0)  \n",
    "        if labels is None:\n",
    "            exp_sim = torch.exp(sim_matrix / self.tau)\n",
    "            loss = -torch.log(exp_sim / (exp_sim.sum(dim=-1, keepdim=True) + 1e-9)).mean()\n",
    "        # Supervised contrastive loss (labels provided)\n",
    "        else:\n",
    "            exp_sim = torch.exp(sim_matrix / self.tau)\n",
    "            mask_same_class = labels.unsqueeze(1) == labels.unsqueeze(0)\n",
    "            exp_sim_same = exp_sim * mask_same_class.float()  \n",
    "            loss = -torch.log(exp_sim_same.sum(dim=-1) / (exp_sim.sum(dim=-1) + 1e-9)).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:13:03.312375Z",
     "iopub.status.busy": "2025-03-09T18:13:03.312157Z",
     "iopub.status.idle": "2025-03-09T18:13:03.332832Z",
     "shell.execute_reply": "2025-03-09T18:13:03.332153Z",
     "shell.execute_reply.started": "2025-03-09T18:13:03.312356Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3. Subject-Specific Feature Extractor (SFE)\n",
    "\n",
    "class SubjectSpecificFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim=64, output_dim=32):\n",
    "        super(SubjectSpecificFeatureExtractor, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.fc(x))  # Output shape: (batch_size, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:13:03.333717Z",
     "iopub.status.busy": "2025-03-09T18:13:03.333467Z",
     "iopub.status.idle": "2025-03-09T18:13:03.350170Z",
     "shell.execute_reply": "2025-03-09T18:13:03.349362Z",
     "shell.execute_reply.started": "2025-03-09T18:13:03.333674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#4. Maximum Mean Discrepancy (MMD) Loss\n",
    "def mmd_loss(source_features, target_features):\n",
    "    source_mean = source_features.mean(dim=0)\n",
    "    target_mean = target_features.mean(dim=0)\n",
    "    loss = torch.norm(source_mean - target_mean, p=2) ** 2  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:13:03.352444Z",
     "iopub.status.busy": "2025-03-09T18:13:03.352197Z",
     "iopub.status.idle": "2025-03-09T18:13:03.366637Z",
     "shell.execute_reply": "2025-03-09T18:13:03.365816Z",
     "shell.execute_reply.started": "2025-03-09T18:13:03.352415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 5. Contrastive Loss L_con2 with Class Prototypes\n",
    "class ContrastiveLossLcon2(nn.Module):\n",
    "    def __init__(self, feature_dim=32, num_classes=4, tau=0.3, gamma=0.5, queue_size=1024):\n",
    "        super(ContrastiveLossLcon2, self).__init__()\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        self.num_classes = num_classes\n",
    "        self.queue_size = queue_size\n",
    "\n",
    "        # Initialize class prototypes (μ_c)\n",
    "        self.prototypes = nn.Parameter(torch.randn(num_classes, feature_dim))  # Shape: (4, 32)\n",
    "\n",
    "        # Initialize memory queue for negative samples\n",
    "        self.queue = torch.randn(queue_size, feature_dim)  # Shape: (1024, 32)\n",
    "        self.queue = F.normalize(self.queue, dim=-1)  # Normalize queue embeddings\n",
    "\n",
    "    def forward(self, z_t, pseudo_labels):\n",
    "        \"\"\"\n",
    "        Compute contrastive loss L_con2 for inter-domain alignment.\n",
    "        - z_t: Target domain features (batch_size, trials, time_windows, 32)\n",
    "        - pseudo_labels: Pseudo-labels for target samples (batch_size, trials, time_windows)\n",
    "\n",
    "        Returns:\n",
    "            Contrastive loss scalar\n",
    "        \"\"\"\n",
    "        batch_size, trials, time_windows, feature_dim = z_t.shape\n",
    "\n",
    "        # Flatten input for processing\n",
    "        z_t = z_t.view(-1, feature_dim)  # Shape: (batch_size * trials * time_windows, 32)\n",
    "        pseudo_labels = pseudo_labels.view(-1)  # Shape: (batch_size * trials * time_windows)\n",
    "\n",
    "        # Normalize embeddings\n",
    "        z_t = F.normalize(z_t, dim=-1)  # Normalize target embeddings\n",
    "        self.prototypes.data = F.normalize(self.prototypes.data, dim=-1)  # Normalize prototypes\n",
    "\n",
    "        # Compute similarity to class prototypes\n",
    "        similarity = torch.mm(z_t, self.prototypes.T)  # Shape: (batch_size * trials * time_windows, 4)\n",
    "        \n",
    "        # Select correct class prototype based on pseudo-labels\n",
    "        proto_sim = similarity.gather(1, pseudo_labels.unsqueeze(1))  # Shape: (batch_size * trials * time_windows, 1)\n",
    "\n",
    "        # Compute softmax denominator (all possible embeddings)\n",
    "        queue_sim = torch.mm(z_t, self.queue.T)  # Shape: (batch_size * trials * time_windows, queue_size)\n",
    "        exp_sim = torch.cat([proto_sim, queue_sim], dim=1)  # Concatenate prototypes & queue\n",
    "        exp_sim = torch.exp(exp_sim / self.tau)  # Apply temperature scaling\n",
    "\n",
    "        # Contrastive loss computation\n",
    "        loss = -torch.log(exp_sim[:, 0] / exp_sim.sum(dim=1))  # Only consider prototype similarity\n",
    "        loss = loss.mean()\n",
    "\n",
    "        # Update prototypes with momentum (γ)\n",
    "        for i in range(self.num_classes):\n",
    "            class_mask = (pseudo_labels == i).float().unsqueeze(1)  # Mask for samples of class i\n",
    "            class_mean = (class_mask * z_t).sum(dim=0) / (class_mask.sum() + 1e-9)  # Compute class mean\n",
    "            self.prototypes.data[i] = F.normalize(self.gamma * self.prototypes.data[i] + (1 - self.gamma) * class_mean, dim=-1)\n",
    "\n",
    "        # Update memory queue (FIFO replacement)\n",
    "        self.queue = torch.cat([self.queue[batch_size:], z_t.detach()], dim=0)  # Remove old, add new\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:13:03.367637Z",
     "iopub.status.busy": "2025-03-09T18:13:03.367445Z",
     "iopub.status.idle": "2025-03-09T18:13:03.384639Z",
     "shell.execute_reply": "2025-03-09T18:13:03.383911Z",
     "shell.execute_reply.started": "2025-03-09T18:13:03.367620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 6. Subject-Specific Classifier (SSC)\n",
    "class SubjectSpecificClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=32, num_classes=4):\n",
    "        super(SubjectSpecificClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:13:03.385402Z",
     "iopub.status.busy": "2025-03-09T18:13:03.385179Z",
     "iopub.status.idle": "2025-03-09T18:13:03.399962Z",
     "shell.execute_reply": "2025-03-09T18:13:03.399219Z",
     "shell.execute_reply.started": "2025-03-09T18:13:03.385384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 7. Generalized Cross-Entropy (GCE) Loss\n",
    "class GCELoss(nn.Module):\n",
    "    def __init__(self, q=0.55):\n",
    "        super(GCELoss, self).__init__()\n",
    "        self.q = q\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        true_probs = probs.gather(1, targets.unsqueeze(1)).squeeze()\n",
    "        loss = (1 - true_probs ** self.q) / self.q\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "de_features = torch.tensor(de_features, dtype=torch.float32)  # (32, 40, 40, 5, 63)\n",
    "num_subjects, num_trials, num_channels, num_bands, num_windows = de_features.shape\n",
    "de_features = de_features.view(num_subjects, num_trials, num_windows, num_channels * num_bands)  # (32, 40, 63, 200)\n",
    "print(\"Final Shape:\", de_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T18:21:21.504270Z",
     "iopub.status.busy": "2025-03-09T18:21:21.503964Z",
     "iopub.status.idle": "2025-03-09T18:21:21.556129Z",
     "shell.execute_reply": "2025-03-09T18:21:21.555116Z",
     "shell.execute_reply.started": "2025-03-09T18:21:21.504244Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Shape: torch.Size([32, 40, 63, 200])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 24.23 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.89 GiB is free. Process 5515 has 872.00 MiB memory in use. Of the allocated memory 729.07 MiB is allocated by PyTorch, and 16.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ea563279aa64>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Forward pass through CFE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mshared_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_features\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mcommon_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrastive_loss_lcon1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Forward pass through SFE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6a5425e90dfb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msim_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.23 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.89 GiB is free. Process 5515 has 872.00 MiB memory in use. Of the allocated memory 729.07 MiB is allocated by PyTorch, and 16.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cfe = CommonFeatureExtractor().to(device)\n",
    "sfe = SubjectSpecificFeatureExtractor().to(device)\n",
    "ssc = SubjectSpecificClassifier().to(device)\n",
    "contrastive_loss_lcon1 = ContrastiveLossLcon1().to(device)\n",
    "contrastive_loss_lcon2 = ContrastiveLossLcon2().to(device)\n",
    "gce_loss_fn = GCELoss().to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(list(cfe.parameters()) + list(sfe.parameters()) + list(ssc.parameters()), lr=0.01)\n",
    "\n",
    "# Training settings\n",
    "epochs = 50\n",
    "batch_size = 32  # Matches subjects in dataset\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Reshape DE features for CFE input\n",
    "    num_subjects, num_trials, num_windows, feature_dim = de_features.shape  # (32, 40, 63, 200)\n",
    "\n",
    "    # Reshape into (batch_size * trials * time_windows, 200)\n",
    "    reshaped_features = de_features.reshape(-1, feature_dim)\n",
    "    reshaped_features = reshaped_features.to(device)\n",
    "\n",
    "    print(\"Final Shape:\", de_features.shape)  # Expected: (32 * 40 * 63, 200)\n",
    "\n",
    "    # Forward pass through CFE\n",
    "    shared_features = cfe(reshaped_features)  # (batch_size, 64)\n",
    "    common_loss = contrastive_loss_lcon1(shared_features)\n",
    "\n",
    "    # Forward pass through SFE\n",
    "    subject_features = sfe(shared_features)  # (batch_size, 32)\n",
    "\n",
    "    # Compute MMD loss (iterations < 420)\n",
    "    if epoch < 420:\n",
    "        mmd_value = mmd_loss(shared_features, subject_features)\n",
    "    else:\n",
    "        mmd_value = torch.tensor(0.0)\n",
    "\n",
    "    # Forward pass through SSC\n",
    "    predictions = ssc(subject_features)  # (batch_size, 4)\n",
    "\n",
    "    # Compute GCE Loss\n",
    "    labels = torch.randint(0, 4, (batch_size,))\n",
    "    gce_loss = gce_loss_fn(predictions, labels)\n",
    "\n",
    "    # Compute L_con2\n",
    "    pseudo_labels = torch.randint(0, 4, (batch_size,))\n",
    "    lcon2_value = contrastive_loss_lcon2(subject_features, pseudo_labels)\n",
    "\n",
    "    # Final Loss\n",
    "    total_loss = gce_loss + mmd_value + common_loss + lcon2_value\n",
    "\n",
    "    # Backpropagation\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Total Loss: {total_loss.item():.4f}\")\n",
    "\n",
    "print(\"✅ MSCL Training Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6735639,
     "sourceId": 10845560,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
