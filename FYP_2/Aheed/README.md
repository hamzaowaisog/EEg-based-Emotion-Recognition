# EEG-based Emotion Recognition - Aheed Module

## Overview
This directory contains the implementation of multimodal emotion recognition models that combine EEG and facial expression data. The code provides a comprehensive pipeline for preprocessing, training, and evaluating various approaches to emotion recognition.

## Directory Structure
- **Face_Model/**: Implementation of facial expression-based emotion recognition models
- **Last/**: Latest version of the models with improved architectures and training methodologies
  - **models/src/**: Source code for all model implementations, training scripts, and evaluation tools
- **FYP-Pipeline.ipynb**: Jupyter notebook demonstrating the complete emotion recognition pipeline
- **pipeline.ipynb**: Optimized version of the emotion recognition pipeline

## Key Features
- Multimodal fusion of EEG and facial expression data
- Advanced model architectures for improved performance
- Comprehensive evaluation metrics and visualization tools
- Data augmentation techniques for EEG signals
- Cross-subject emotion recognition capabilities

## Usage
The main pipeline can be accessed through the Jupyter notebooks. For detailed usage of specific components, refer to the README files in the respective subdirectories. 