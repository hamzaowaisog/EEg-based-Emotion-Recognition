{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 2 Using better ICA Gpu Rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-09 17:47:23] INFO (torcheeg/MainThread) ðŸ” | Detected cached processing results, reading cache from C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing record _record_0...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_0...\n",
      "Downsampling to 100 Hz for record _record_0...\n",
      "Applying Infomax ICA for artifact removal on record _record_0...\n",
      "EOG components identified: [2, 23]\n",
      "Muscle artifact components identified: [5, 7, 10, 17, 22, 24, 26, 29, 30, 35, 36, 37, 38, 42, 44, 46, 47, 48, 51, 53, 56, 58]\n",
      "Excluded components for record _record_0: [2, 23]\n",
      "Processed and saved record _record_0 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_0.fif\n",
      "Processing record _record_1...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_1...\n",
      "Downsampling to 100 Hz for record _record_1...\n",
      "Applying Infomax ICA for artifact removal on record _record_1...\n",
      "EOG components identified: [4]\n",
      "Muscle artifact components identified: [2, 3, 4, 6, 18, 21, 22, 23, 28, 31, 35, 37, 40, 41, 42, 43, 44, 48, 49, 54, 55, 57, 58, 59, 60]\n",
      "Excluded components for record _record_1: [4, 2]\n",
      "Processed and saved record _record_1 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_1.fif\n",
      "Processing record _record_2...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_2...\n",
      "Downsampling to 100 Hz for record _record_2...\n",
      "Applying Infomax ICA for artifact removal on record _record_2...\n",
      "EOG components identified: [1, 6]\n",
      "Muscle artifact components identified: [2, 9, 10, 11, 14, 15, 19, 25, 29, 30, 32, 33, 38, 40, 44, 46, 47, 49, 55, 56, 57, 58, 59, 60]\n",
      "Excluded components for record _record_2: [1, 6]\n",
      "Processed and saved record _record_2 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_2.fif\n",
      "Processing record _record_3...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_3...\n",
      "Downsampling to 100 Hz for record _record_3...\n",
      "Applying Infomax ICA for artifact removal on record _record_3...\n",
      "EOG components identified: [1, 0]\n",
      "Muscle artifact components identified: [4, 5, 11, 15, 16, 23, 26, 27, 30, 31, 33, 34, 39, 40, 43, 46, 48, 49, 50, 53, 54, 55, 56, 57]\n",
      "Excluded components for record _record_3: [1, 0]\n",
      "Processed and saved record _record_3 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_3.fif\n",
      "Processing record _record_4...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_4...\n",
      "Downsampling to 100 Hz for record _record_4...\n",
      "Applying Infomax ICA for artifact removal on record _record_4...\n",
      "EOG components identified: [1, 0]\n",
      "Muscle artifact components identified: [3, 8, 11, 12, 17, 18, 19, 22, 23, 24, 25, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 50, 51, 52, 54, 55, 58]\n",
      "Excluded components for record _record_4: [1, 0]\n",
      "Processed and saved record _record_4 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_4.fif\n",
      "Processing record _record_5...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_5...\n",
      "Downsampling to 100 Hz for record _record_5...\n",
      "Applying Infomax ICA for artifact removal on record _record_5...\n",
      "EOG components identified: [0]\n",
      "Muscle artifact components identified: [5, 6, 8, 10, 14, 18, 28, 33, 40, 41, 47, 48, 49, 50, 51, 53, 54, 55, 57]\n",
      "Excluded components for record _record_5: [0, 5]\n",
      "Processed and saved record _record_5 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_5.fif\n",
      "Processing record _record_6...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_6...\n",
      "Downsampling to 100 Hz for record _record_6...\n",
      "Applying Infomax ICA for artifact removal on record _record_6...\n",
      "EOG components identified: [0]\n",
      "Muscle artifact components identified: [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 21, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 59, 60]\n",
      "Excluded components for record _record_6: [2, 0]\n",
      "Processed and saved record _record_6 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_6.fif\n",
      "Processing record _record_7...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_7...\n",
      "Downsampling to 100 Hz for record _record_7...\n",
      "Applying Infomax ICA for artifact removal on record _record_7...\n",
      "EOG components identified: [2]\n",
      "Muscle artifact components identified: [0, 3, 5, 7, 9, 10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57, 58, 60]\n",
      "Excluded components for record _record_7: [2, 0]\n",
      "Processed and saved record _record_7 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_7.fif\n",
      "Processing record _record_8...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_8...\n",
      "Downsampling to 100 Hz for record _record_8...\n",
      "Applying Infomax ICA for artifact removal on record _record_8...\n",
      "EOG components identified: [0]\n",
      "Muscle artifact components identified: [1, 2, 3, 11, 12, 13, 14, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59]\n",
      "Excluded components for record _record_8: [0, 1]\n",
      "Processed and saved record _record_8 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_8.fif\n",
      "Processing record _record_9...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_9...\n",
      "Downsampling to 100 Hz for record _record_9...\n",
      "Applying Infomax ICA for artifact removal on record _record_9...\n",
      "EOG components identified: [3]\n",
      "Muscle artifact components identified: [2, 6, 7, 9, 11, 14, 17, 20, 21, 23, 25, 29, 30, 31, 33, 34, 36, 37, 43, 44, 45, 46, 47, 49, 51, 52, 55, 56, 58, 60]\n",
      "Excluded components for record _record_9: [3, 2]\n",
      "Processed and saved record _record_9 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_9.fif\n",
      "Processing record _record_10...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_10...\n",
      "Downsampling to 100 Hz for record _record_10...\n",
      "Applying Infomax ICA for artifact removal on record _record_10...\n",
      "EOG components identified: [2]\n",
      "Muscle artifact components identified: [0, 2, 13, 18, 21, 23, 24, 26, 28, 30, 31, 32, 33, 34, 35, 37, 42, 43, 46, 50, 51, 52, 54, 57, 58, 60]\n",
      "Excluded components for record _record_10: [0, 2]\n",
      "Processed and saved record _record_10 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_10.fif\n",
      "Processing record _record_11...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_11...\n",
      "Downsampling to 100 Hz for record _record_11...\n",
      "Applying Infomax ICA for artifact removal on record _record_11...\n",
      "EOG components identified: [1]\n",
      "Muscle artifact components identified: [1, 12, 14, 16, 17, 18, 22, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 37, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59]\n",
      "Excluded components for record _record_11: [1, 1]\n",
      "Processed and saved record _record_11 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_11.fif\n",
      "Processing record _record_12...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_12...\n",
      "Downsampling to 100 Hz for record _record_12...\n",
      "Applying Infomax ICA for artifact removal on record _record_12...\n",
      "EOG components identified: [8, 2]\n",
      "Muscle artifact components identified: [0, 5, 6, 7, 9, 12, 13, 16, 21, 28, 30, 31, 40, 44, 49, 50, 51, 52, 53, 55, 56, 59, 60]\n",
      "Excluded components for record _record_12: [8, 2]\n",
      "Processed and saved record _record_12 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_12.fif\n",
      "Processing record _record_13...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_13...\n",
      "Downsampling to 100 Hz for record _record_13...\n",
      "Applying Infomax ICA for artifact removal on record _record_13...\n",
      "EOG components identified: [5, 12]\n",
      "Muscle artifact components identified: [9, 16, 22, 23, 27, 30, 33, 35, 36, 37, 40, 43, 50, 53, 55]\n",
      "Excluded components for record _record_13: [5, 12]\n",
      "Processed and saved record _record_13 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_13.fif\n",
      "Processing record _record_14...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_14...\n",
      "Downsampling to 100 Hz for record _record_14...\n",
      "Applying Infomax ICA for artifact removal on record _record_14...\n",
      "EOG components identified: [1, 8]\n",
      "Muscle artifact components identified: [3, 4, 5, 6, 11, 16, 18, 20, 21, 22, 24, 26, 27, 28, 29, 32, 33, 35, 36, 37, 39, 40, 41, 45, 46, 51, 54, 55, 57, 59]\n",
      "Excluded components for record _record_14: [1, 8]\n",
      "Processed and saved record _record_14 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_14.fif\n",
      "Processing record _record_15...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_15...\n",
      "Downsampling to 100 Hz for record _record_15...\n",
      "Applying Infomax ICA for artifact removal on record _record_15...\n",
      "EOG components identified: [17, 27, 32]\n",
      "Muscle artifact components identified: [11, 13, 15, 18, 19, 20, 21, 22, 25, 26, 28, 29, 30, 33, 35, 36, 38, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60]\n",
      "Excluded components for record _record_15: [27, 17]\n",
      "Processed and saved record _record_15 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_15.fif\n",
      "Processing record _record_16...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_16...\n",
      "Downsampling to 100 Hz for record _record_16...\n",
      "Applying Infomax ICA for artifact removal on record _record_16...\n",
      "EOG components identified: [4, 9, 11]\n",
      "Muscle artifact components identified: [0, 2, 3, 5, 6, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 34, 37, 38, 40, 41, 42, 44, 48, 49, 50, 55, 59, 60]\n",
      "Excluded components for record _record_16: [4, 9]\n",
      "Processed and saved record _record_16 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_16.fif\n",
      "Processing record _record_17...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_17...\n",
      "Downsampling to 100 Hz for record _record_17...\n",
      "Applying Infomax ICA for artifact removal on record _record_17...\n",
      "EOG components identified: [1, 6, 2]\n",
      "Muscle artifact components identified: [3, 7, 9, 10, 11, 15, 16, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 34, 35, 36, 38, 41, 45, 49, 50, 51, 55, 56, 57, 58, 59]\n",
      "Excluded components for record _record_17: [1, 6]\n",
      "Processed and saved record _record_17 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_17.fif\n",
      "Processing record _record_18...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_18...\n",
      "Downsampling to 100 Hz for record _record_18...\n",
      "Applying Infomax ICA for artifact removal on record _record_18...\n",
      "EOG components identified: [3]\n",
      "Muscle artifact components identified: [2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 60]\n",
      "Excluded components for record _record_18: [3, 2]\n",
      "Processed and saved record _record_18 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_18.fif\n",
      "Processing record _record_19...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_19...\n",
      "Downsampling to 100 Hz for record _record_19...\n",
      "Applying Infomax ICA for artifact removal on record _record_19...\n",
      "EOG components identified: [1]\n",
      "Muscle artifact components identified: [3, 4, 6, 9, 10, 11, 12, 13, 15, 18, 20, 21, 22, 24, 25, 28, 30, 31, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 58, 59]\n",
      "Excluded components for record _record_19: [1, 3]\n",
      "Processed and saved record _record_19 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_19.fif\n",
      "Processing record _record_20...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_20...\n",
      "Downsampling to 100 Hz for record _record_20...\n",
      "Applying Infomax ICA for artifact removal on record _record_20...\n",
      "EOG components identified: [7]\n",
      "Muscle artifact components identified: [1, 3, 4, 6, 9, 10, 11, 16, 20, 21, 22, 25, 33, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 60]\n",
      "Excluded components for record _record_20: [7, 1]\n",
      "Processed and saved record _record_20 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_20.fif\n",
      "Processing record _record_21...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_21...\n",
      "Downsampling to 100 Hz for record _record_21...\n",
      "Applying Infomax ICA for artifact removal on record _record_21...\n",
      "EOG components identified: [3]\n",
      "Muscle artifact components identified: [8, 13, 20, 21, 22, 23, 24, 25, 31, 37, 39, 41, 43, 44, 45, 47, 48, 49, 50, 53, 56, 57, 58, 59]\n",
      "Excluded components for record _record_21: [3, 8]\n",
      "Processed and saved record _record_21 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_21.fif\n",
      "Processing record _record_22...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_22...\n",
      "Downsampling to 100 Hz for record _record_22...\n",
      "Applying Infomax ICA for artifact removal on record _record_22...\n",
      "EOG components identified: [6, 1]\n",
      "Muscle artifact components identified: [2, 11, 12, 17, 20, 24, 30, 33, 34, 40, 45, 51, 53, 54, 60]\n",
      "Excluded components for record _record_22: [1, 6]\n",
      "Processed and saved record _record_22 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_22.fif\n",
      "Processing record _record_23...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_23...\n",
      "Downsampling to 100 Hz for record _record_23...\n",
      "Applying Infomax ICA for artifact removal on record _record_23...\n",
      "EOG components identified: [2, 0, 3]\n",
      "Muscle artifact components identified: [0, 3, 4, 26, 28, 32, 34, 37, 38, 39, 40, 41, 42, 44, 46, 51, 52, 54, 55, 57, 58]\n",
      "Excluded components for record _record_23: [2, 0]\n",
      "Processed and saved record _record_23 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_23.fif\n",
      "Processing record _record_24...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_24...\n",
      "Downsampling to 100 Hz for record _record_24...\n",
      "Applying Infomax ICA for artifact removal on record _record_24...\n",
      "EOG components identified: [13, 27]\n",
      "Muscle artifact components identified: [1, 9, 10, 11, 12, 14, 18, 29, 32, 37, 40, 42, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60]\n",
      "Excluded components for record _record_24: [27, 13]\n",
      "Processed and saved record _record_24 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_24.fif\n",
      "Processing record _record_25...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_25...\n",
      "Downsampling to 100 Hz for record _record_25...\n",
      "Applying Infomax ICA for artifact removal on record _record_25...\n",
      "EOG components identified: [4, 12]\n",
      "Muscle artifact components identified: [8, 10, 12, 15, 17, 21, 24, 25, 26, 27, 28, 29, 30, 32, 34, 37, 38, 39, 40, 42, 43, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 60]\n",
      "Excluded components for record _record_25: [4, 12]\n",
      "Processed and saved record _record_25 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_25.fif\n",
      "Processing record _record_26...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_26...\n",
      "Downsampling to 100 Hz for record _record_26...\n",
      "Applying Infomax ICA for artifact removal on record _record_26...\n",
      "EOG components identified: [8, 5, 2]\n",
      "Muscle artifact components identified: [6, 10, 14, 22, 23, 24, 25, 28, 31, 32, 35, 36, 39, 40, 42, 46, 47, 49, 50, 51, 52, 53, 56, 58, 60]\n",
      "Excluded components for record _record_26: [5, 8]\n",
      "Processed and saved record _record_26 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_26.fif\n",
      "Processing record _record_27...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_27...\n",
      "Downsampling to 100 Hz for record _record_27...\n",
      "Applying Infomax ICA for artifact removal on record _record_27...\n",
      "EOG components identified: [5, 3, 9]\n",
      "Muscle artifact components identified: [6, 7, 8, 10, 11, 13, 14, 17, 23, 24, 25, 26, 27, 28, 30, 33, 36, 38, 39, 44, 45, 48, 49, 53, 54, 55, 57, 58]\n",
      "Excluded components for record _record_27: [5, 3]\n",
      "Processed and saved record _record_27 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_27.fif\n",
      "Processing record _record_28...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_28...\n",
      "Downsampling to 100 Hz for record _record_28...\n",
      "Applying Infomax ICA for artifact removal on record _record_28...\n",
      "EOG components identified: [2, 1]\n",
      "Muscle artifact components identified: [1, 3, 7, 8, 15, 18, 21, 22, 24, 25, 31, 34, 36, 37, 38, 42, 52, 53, 54, 56, 57]\n",
      "Excluded components for record _record_28: [2, 1]\n",
      "Processed and saved record _record_28 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_28.fif\n",
      "Processing record _record_29...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_29...\n",
      "Downsampling to 100 Hz for record _record_29...\n",
      "Applying Infomax ICA for artifact removal on record _record_29...\n",
      "EOG components identified: [15, 11, 27]\n",
      "Muscle artifact components identified: [5, 8, 13, 14, 17, 18, 21, 22, 23, 24, 25, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 45, 46, 48, 51, 53, 58]\n",
      "Excluded components for record _record_29: [15, 11]\n",
      "Processed and saved record _record_29 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_29.fif\n",
      "Processing record _record_30...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_30...\n",
      "Downsampling to 100 Hz for record _record_30...\n",
      "Applying Infomax ICA for artifact removal on record _record_30...\n",
      "EOG components identified: [4, 15]\n",
      "Muscle artifact components identified: [0, 2, 5, 7, 8, 9, 10, 11, 14, 15, 16, 18, 19, 22, 23, 24, 26, 27, 29, 30, 31, 35, 36, 38, 39, 41, 43, 46, 47, 53, 55]\n",
      "Excluded components for record _record_30: [15, 4]\n",
      "Processed and saved record _record_30 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_30.fif\n",
      "Processing record _record_31...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_31...\n",
      "Downsampling to 100 Hz for record _record_31...\n",
      "Applying Infomax ICA for artifact removal on record _record_31...\n",
      "EOG components identified: [2, 4]\n",
      "Muscle artifact components identified: [4, 5, 6, 7, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 24, 26, 27, 28, 30, 31, 33, 34, 35, 37, 41, 42, 46, 48, 51, 53, 54, 55, 56, 57, 58, 60]\n",
      "Excluded components for record _record_31: [4, 2]\n",
      "Processed and saved record _record_31 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_31.fif\n",
      "Processing record _record_32...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_32...\n",
      "Downsampling to 100 Hz for record _record_32...\n",
      "Applying Infomax ICA for artifact removal on record _record_32...\n",
      "EOG components identified: [1]\n",
      "Muscle artifact components identified: [0, 5, 6, 7, 8, 9, 10, 13, 14, 17, 21, 22, 24, 26, 28, 32, 34, 35, 37, 38, 40, 42, 43, 46, 48, 50, 54, 55, 60]\n",
      "Excluded components for record _record_32: [1, 0]\n",
      "Processed and saved record _record_32 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_32.fif\n",
      "Processing record _record_33...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_33...\n",
      "Downsampling to 100 Hz for record _record_33...\n",
      "Applying Infomax ICA for artifact removal on record _record_33...\n",
      "EOG components identified: [6, 19]\n",
      "Muscle artifact components identified: [0, 2, 3, 4, 9, 14, 17, 18, 19, 20, 27, 28, 30, 32, 33, 35, 36, 37, 41, 42, 43, 44, 45, 46, 47, 52, 54, 56, 58, 59]\n",
      "Excluded components for record _record_33: [6, 19]\n",
      "Processed and saved record _record_33 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_33.fif\n",
      "Processing record _record_34...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_34...\n",
      "Downsampling to 100 Hz for record _record_34...\n",
      "Applying Infomax ICA for artifact removal on record _record_34...\n",
      "EOG components identified: [13, 1, 18]\n",
      "Muscle artifact components identified: [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 15, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 40, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60]\n",
      "Excluded components for record _record_34: [13, 1]\n",
      "Processed and saved record _record_34 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_34.fif\n",
      "Processing record _record_35...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_35...\n",
      "Downsampling to 100 Hz for record _record_35...\n",
      "Applying Infomax ICA for artifact removal on record _record_35...\n",
      "EOG components identified: [1, 26]\n",
      "Muscle artifact components identified: [2, 5, 7, 8, 9, 11, 12, 17, 18, 20, 23, 24, 25, 27, 29, 30, 33, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60]\n",
      "Excluded components for record _record_35: [1, 26]\n",
      "Processed and saved record _record_35 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_35.fif\n",
      "Processing record _record_36...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_36...\n",
      "Downsampling to 100 Hz for record _record_36...\n",
      "Applying Infomax ICA for artifact removal on record _record_36...\n",
      "EOG components identified: [4, 5]\n",
      "Muscle artifact components identified: [0, 1, 5, 6, 12, 15, 19, 20, 22, 24, 27, 28, 29, 31, 32, 35, 38, 40, 42, 43, 45, 47, 51, 52, 53, 55]\n",
      "Excluded components for record _record_36: [4, 5]\n",
      "Processed and saved record _record_36 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_36.fif\n",
      "Processing record _record_37...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_37...\n",
      "Downsampling to 100 Hz for record _record_37...\n",
      "Applying Infomax ICA for artifact removal on record _record_37...\n",
      "EOG components identified: [3, 1, 8]\n",
      "Muscle artifact components identified: [0, 1, 3, 4, 7, 9, 11, 14, 15, 16, 17, 18, 22, 25, 26, 29, 30, 31, 32, 34, 35, 40, 41, 42, 43, 45, 51, 52, 53, 55, 57, 58, 59, 60]\n",
      "Excluded components for record _record_37: [3, 1]\n",
      "Processed and saved record _record_37 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_37.fif\n",
      "Processing record _record_38...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_38...\n",
      "Downsampling to 100 Hz for record _record_38...\n",
      "Applying Infomax ICA for artifact removal on record _record_38...\n",
      "EOG components identified: [6, 5]\n",
      "Muscle artifact components identified: [1, 5, 7, 13, 14, 15, 16, 18, 19, 20, 24, 25, 26, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 43, 45, 48, 54, 55, 57, 59, 60]\n",
      "Excluded components for record _record_38: [6, 5]\n",
      "Processed and saved record _record_38 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_38.fif\n",
      "Processing record _record_39...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_39...\n",
      "Downsampling to 100 Hz for record _record_39...\n",
      "Applying Infomax ICA for artifact removal on record _record_39...\n",
      "EOG components identified: [2]\n",
      "Muscle artifact components identified: [0, 1, 3, 7, 8, 9, 11, 14, 15, 16, 17, 18, 19, 20, 24, 25, 27, 31, 33, 34, 38, 39, 40, 41, 42, 43, 45, 49, 52, 53, 54, 55, 56, 60]\n",
      "Excluded components for record _record_39: [2, 0]\n",
      "Processed and saved record _record_39 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_39.fif\n",
      "Processing record _record_40...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_40...\n",
      "Downsampling to 100 Hz for record _record_40...\n",
      "Applying Infomax ICA for artifact removal on record _record_40...\n",
      "EOG components identified: [2]\n",
      "Muscle artifact components identified: [0, 1, 3, 5, 6, 8, 10, 11, 13, 15, 18, 19, 20, 21, 22, 23, 25, 26, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 55, 57, 59, 60]\n",
      "Excluded components for record _record_40: [2, 0]\n",
      "Processed and saved record _record_40 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_40.fif\n",
      "Processing record _record_41...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_41...\n",
      "Downsampling to 100 Hz for record _record_41...\n",
      "Applying Infomax ICA for artifact removal on record _record_41...\n",
      "EOG components identified: [0]\n",
      "Muscle artifact components identified: [1, 2, 3, 5, 6, 7, 9, 11, 12, 13, 17, 20, 22, 24, 25, 26, 30, 32, 35, 36, 38, 41, 43, 44, 45, 48, 49, 50, 51, 56, 58, 60]\n",
      "Excluded components for record _record_41: [1, 0]\n",
      "Processed and saved record _record_41 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_41.fif\n",
      "Processing record _record_42...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_42...\n",
      "Downsampling to 100 Hz for record _record_42...\n",
      "Applying Infomax ICA for artifact removal on record _record_42...\n",
      "EOG components identified: [3]\n",
      "Muscle artifact components identified: [0, 5, 7, 8, 9, 10, 11, 12, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59]\n",
      "Excluded components for record _record_42: [3, 0]\n",
      "Processed and saved record _record_42 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_42.fif\n",
      "Processing record _record_43...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_43...\n",
      "Downsampling to 100 Hz for record _record_43...\n",
      "Applying Infomax ICA for artifact removal on record _record_43...\n",
      "EOG components identified: [0]\n",
      "Muscle artifact components identified: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n",
      "Excluded components for record _record_43: [0, 2]\n",
      "Processed and saved record _record_43 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_43.fif\n",
      "Processing record _record_44...\n",
      "Applying 0.05â€“47 Hz bandpass filter for record _record_44...\n",
      "Downsampling to 100 Hz for record _record_44...\n",
      "Applying Infomax ICA for artifact removal on record _record_44...\n",
      "EOG components identified: [0]\n",
      "Muscle artifact components identified: [2, 3, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 33, 35, 37, 39, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 56, 57, 59]\n",
      "Excluded components for record _record_44: [0, 2]\n",
      "Processed and saved record _record_44 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_44.fif\n",
      "All records have been processed and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from torcheeg.datasets import SEEDDataset\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load the SEED Dataset\n",
    "# ---------------------------------------------------------------\n",
    "dataset = SEEDDataset(\n",
    "    io_path='C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS',\n",
    "    online_transform=None,\n",
    "    label_transform=None,\n",
    "    num_worker=6\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Directory to Save the Cleaned Data\n",
    "# ---------------------------------------------------------------\n",
    "save_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Group Samples by Record ID\n",
    "# ---------------------------------------------------------------\n",
    "record_groups = defaultdict(list)\n",
    "\n",
    "for idx in range(len(dataset)):\n",
    "    eeg_data, label = dataset[idx]\n",
    "    record_id = label['_record_id']\n",
    "    record_groups[record_id].append(eeg_data)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Process Each Unique Record\n",
    "# ---------------------------------------------------------------\n",
    "for record_id, eeg_samples in record_groups.items():\n",
    "    print(f\"Processing record {record_id}...\")\n",
    "\n",
    "    # Concatenate all samples within the record along the time axis\n",
    "    eeg_data = np.hstack(eeg_samples)  # Shape: (channels, combined_time_points)\n",
    "\n",
    "    # Create MNE info object\n",
    "    sfreq = 200  # Original sampling frequency (200 Hz)\n",
    "    ch_names = [f'Ch{i+1}' for i in range(eeg_data.shape[0])]\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=['eeg'] * len(ch_names))\n",
    "\n",
    "    # Create MNE Raw object\n",
    "    raw = mne.io.RawArray(eeg_data, info)\n",
    "\n",
    "    # Assign a standard montage\n",
    "    montage = mne.channels.make_standard_montage('standard_1005')\n",
    "    raw.rename_channels({f'Ch{i+1}': montage.ch_names[i] for i in range(len(ch_names))})\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Preprocessing: Bandpass Filter (0.05â€“47 Hz) and Downsampling\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(f\"Applying 0.05â€“47 Hz bandpass filter for record {record_id}...\")\n",
    "    raw.filter(l_freq=0.05, h_freq=47.0, fir_design='firwin')\n",
    "\n",
    "    # Downsample to 100 Hz to speed up ICA\n",
    "    print(f\"Downsampling to 100 Hz for record {record_id}...\")\n",
    "    raw.resample(sfreq=100)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Apply ICA for Artifact Removal (Infomax)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(f\"Applying Infomax ICA for artifact removal on record {record_id}...\")\n",
    "\n",
    "    # Set ICA parameters to use Infomax with a reduced number of components\n",
    "    ica = mne.preprocessing.ICA(\n",
    "        n_components=len(ch_names) - 1, # Limit to 30 components for faster processing\n",
    "        method='infomax',      # Use Infomax algorithm as specified in the paper\n",
    "        max_iter=200,          # Default max_iter\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit ICA to the data\n",
    "    ica.fit(raw, picks='all')\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Automatically Detect and Limit Exclusions to 2 Worst Components\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Define virtual EOG channels (frontal electrodes)\n",
    "    eog_virtual_channels = ['Fp1', 'Fp2']\n",
    "\n",
    "    try:\n",
    "        # Detect EOG artifacts using virtual EOG channels\n",
    "        eog_indices, eog_scores = ica.find_bads_eog(raw, ch_name=eog_virtual_channels)\n",
    "        print(f\"EOG components identified: {eog_indices}\")\n",
    "    except RuntimeError:\n",
    "        print(\"No suitable EOG channels found. Skipping EOG artifact detection.\")\n",
    "        eog_indices, eog_scores = [], []\n",
    "\n",
    "    # Detect muscle artifacts\n",
    "    muscle_indices, muscle_scores = ica.find_bads_muscle(raw)\n",
    "    print(f\"Muscle artifact components identified: {muscle_indices}\")\n",
    "\n",
    "    # Combine indices and scores\n",
    "    # Combine indices and scores\n",
    "    # Combine indices and scores\n",
    "    all_indices = eog_indices + muscle_indices\n",
    "    all_scores = eog_scores + muscle_scores\n",
    "\n",
    "    # Ensure all scores are scalar values by taking the maximum absolute value if they are arrays\n",
    "    all_scores = [np.max(np.abs(score)) if isinstance(score, (np.ndarray, list)) else abs(score) for score in all_scores]\n",
    "\n",
    "    # Limit to the 2 worst components (highest scores)\n",
    "    if len(all_indices) > 2:\n",
    "        worst_indices = [idx for _, idx in sorted(zip(all_scores, all_indices), key=lambda x: x[0], reverse=True)[:2]]\n",
    "    else:\n",
    "        worst_indices = all_indices\n",
    "\n",
    "    # Set components to exclude\n",
    "    ica.exclude = worst_indices\n",
    "    print(f\"Excluded components for record {record_id}: {ica.exclude}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Apply ICA to remove the selected components\n",
    "    ica.apply(raw)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Save the Cleaned Data\n",
    "    # -------------------------------------------------------------------------\n",
    "    save_path = os.path.join(save_dir, f'cleaned_{record_id}.fif')\n",
    "    raw.save(save_path, overwrite=True)\n",
    "    print(f\"Processed and saved record {record_id} to {save_path}\")\n",
    "\n",
    "print(\"All records have been processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-09 17:02:39] INFO (torcheeg/MainThread) ðŸ” | Detected cached processing results, reading cache from C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOG components identified: [0]\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from torcheeg.datasets import SEEDDataset\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load the SEED Dataset\n",
    "# ---------------------------------------------------------------\n",
    "dataset = SEEDDataset(\n",
    "    io_path='C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS',\n",
    "    online_transform=None,\n",
    "    label_transform=None,\n",
    "    num_worker=6\n",
    ")\n",
    "\n",
    "# Load a single sample to test\n",
    "eeg_data, label = dataset[0]\n",
    "\n",
    "# Create MNE info object\n",
    "sfreq = 200  # Sampling frequency (200 Hz)\n",
    "ch_names = [f'Ch{i+1}' for i in range(eeg_data.shape[0])]\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=['eeg'] * len(ch_names))\n",
    "\n",
    "# Create MNE Raw object\n",
    "raw = mne.io.RawArray(eeg_data, info)\n",
    "\n",
    "# Assign a standard montage\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "raw.rename_channels({f'Ch{i+1}': montage.ch_names[i] for i in range(len(ch_names))})\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# Apply bandpass filtering (0.05â€“47 Hz)\n",
    "raw.filter(l_freq=0.05, h_freq=47.0, fir_design='firwin')\n",
    "\n",
    "# Create ICA object with fewer components and fit on a small subset of data\n",
    "ica = mne.preprocessing.ICA(\n",
    "    n_components=20,       # Use fewer components to speed up the process\n",
    "    method='infomax',\n",
    "    max_iter=100,          # Reduce iterations for quicker fitting\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit ICA on the available duration of data\n",
    "raw_subset = raw.copy().crop(tmin=0, tmax=raw.times[-1])\n",
    "ica.fit(raw_subset, picks='all')\n",
    "\n",
    "# Check virtual EOG channels\n",
    "eog_virtual_channels = ['Fp1', 'Fp2']  # Adjust based on your montage\n",
    "\n",
    "try:\n",
    "    # Attempt to find EOG artifacts\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(raw_subset, ch_name=eog_virtual_channels)\n",
    "    print(f\"EOG components identified: {eog_indices}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed all_scores: [0.8, 0.5, 0.3, 0.7, 0.9]\n",
      "Worst components to exclude: [10, 2]\n"
     ]
    }
   ],
   "source": [
    "# Mock scores for quick testing\n",
    "eog_scores = [np.array([0.8]), np.array([-0.5])]\n",
    "muscle_scores = [np.array([0.3]), np.array([0.7]), np.array([-0.9])]\n",
    "\n",
    "# Combine indices and scores for testing\n",
    "eog_indices = [2, 23]\n",
    "muscle_indices = [5, 7, 10]\n",
    "\n",
    "all_indices = eog_indices + muscle_indices\n",
    "all_scores = eog_scores + muscle_scores\n",
    "\n",
    "# Ensure all scores are scalar values\n",
    "all_scores = [np.max(np.abs(score)) if isinstance(score, (np.ndarray, list)) else abs(score) for score in all_scores]\n",
    "\n",
    "# Print the processed scores\n",
    "print(f\"Processed all_scores: {all_scores}\")\n",
    "\n",
    "# Limit to the 2 worst components\n",
    "if len(all_indices) > 2:\n",
    "    worst_indices = [idx for _, idx in sorted(zip(all_scores, all_indices), key=lambda x: x[0], reverse=True)[:2]]\n",
    "else:\n",
    "    worst_indices = all_indices\n",
    "\n",
    "print(f\"Worst components to exclude: {worst_indices}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising and Bandpass 4-47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file cleaned__record_0.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_0.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_0.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_0...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_0...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_0...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_0.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_0.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_0.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_0 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_0.fif\n",
      "Processing file cleaned__record_1.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_1.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing automatic denoising for cleaned__record_1...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_1...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_1...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_1.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_1.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_1 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_1.fif\n",
      "Processing file cleaned__record_10.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_10.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_10.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing automatic denoising for cleaned__record_10...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_10...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_10...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_10.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_10.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_10.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_10 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_10.fif\n",
      "Processing file cleaned__record_11.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_11.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_11.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing automatic denoising for cleaned__record_11...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_11...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_11...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_11.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_11.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_11.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_11 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_11.fif\n",
      "Processing file cleaned__record_12.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_12.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_12.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_12...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_12...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_12...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_12.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_12.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_12.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_12 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_12.fif\n",
      "Processing file cleaned__record_13.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_13.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_13.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_13...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_13...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_13...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_13.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_13.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_13.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_13 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_13.fif\n",
      "Processing file cleaned__record_14.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_14.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_14.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_14...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_14...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_14...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_14.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_14.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_14.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_14 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_14.fif\n",
      "Processing file cleaned__record_15.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_15.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_15.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_15...\n",
      "Noisy channels identified: ['F7', 'FT7']\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 95.1 mm\n",
      "Computing interpolation matrix from 60 sensor positions\n",
      "Interpolating 2 sensors\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_15...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_15...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_15.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_15.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_15.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_15 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_15.fif\n",
      "Processing file cleaned__record_16.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_16.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_16.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_16...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_16...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_16...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_16.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_16.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_16.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_16 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_16.fif\n",
      "Processing file cleaned__record_17.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_17.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_17.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_17...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_17...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_17...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_17.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_17.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_17.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_17 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_17.fif\n",
      "Processing file cleaned__record_18.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_18.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_18.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_18...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_18...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_18...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_18.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_18.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_18.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_18 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_18.fif\n",
      "Processing file cleaned__record_19.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_19.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_19.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_19...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_19...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_19...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_19.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_19.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_19.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_19 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_19.fif\n",
      "Processing file cleaned__record_2.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_2.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_2.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_2...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_2...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_2...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_2.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_2.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_2.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_2 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_2.fif\n",
      "Processing file cleaned__record_20.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_20.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_20.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing automatic denoising for cleaned__record_20...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_20...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_20...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_20.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_20.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_20.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_20 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_20.fif\n",
      "Processing file cleaned__record_21.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_21.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_21.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_21...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_21...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_21...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_21.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_21.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_21.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_21 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_21.fif\n",
      "Processing file cleaned__record_22.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_22.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_22.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_22...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_22...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_22...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_22.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_22.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_22.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_22 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_22.fif\n",
      "Processing file cleaned__record_23.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_23.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_23.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_23...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_23...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_23...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_23.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_23.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_23.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_23 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_23.fif\n",
      "Processing file cleaned__record_24.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_24.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_24.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_24...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_24...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_24...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_24.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_24.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_24.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_24 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_24.fif\n",
      "Processing file cleaned__record_25.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_25.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_25.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_25...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_25...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_25...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_25.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_25.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_25.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_25 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_25.fif\n",
      "Processing file cleaned__record_26.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_26.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_26.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_26...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_26...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_26...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_26.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_26.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_26.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_26 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_26.fif\n",
      "Processing file cleaned__record_27.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_27.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_27.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_27...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_27...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_27...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_27.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_27.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_27.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_27 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_27.fif\n",
      "Processing file cleaned__record_28.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_28.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_28.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_28...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_28...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_28...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_28.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_28.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_28.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_28 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_28.fif\n",
      "Processing file cleaned__record_29.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_29.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_29.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_29...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_29...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_29...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_29.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_29.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_29.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_29 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_29.fif\n",
      "Processing file cleaned__record_3.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_3.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_3.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_3...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_3...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_3...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_3.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_3.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_3.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_3 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_3.fif\n",
      "Processing file cleaned__record_30.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_30.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_30.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_30...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_30...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_30...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_30.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_30.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_30.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_30 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_30.fif\n",
      "Processing file cleaned__record_31.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_31.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_31.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_31...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_31...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_31...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_31.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_31.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_31.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_31 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_31.fif\n",
      "Processing file cleaned__record_32.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_32.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_32.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_32...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_32...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_32...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_32.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_32.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_32.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_32 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_32.fif\n",
      "Processing file cleaned__record_33.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_33.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_33.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_33...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_33...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_33...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_33.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_33.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_33.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_33 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_33.fif\n",
      "Processing file cleaned__record_34.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_34.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_34.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_34...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_34...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_34...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_34.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_34.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_34.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_34 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_34.fif\n",
      "Processing file cleaned__record_35.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_35.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_35.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_35...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_35...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_35...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_35.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_35.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_35.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_35 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_35.fif\n",
      "Processing file cleaned__record_36.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_36.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_36.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_36...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_36...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_36...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_36.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_36.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_36.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_36 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_36.fif\n",
      "Processing file cleaned__record_37.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_37.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_37.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_37...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_37...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_37...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_37.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_37.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_37.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_37 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_37.fif\n",
      "Processing file cleaned__record_38.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_38.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_38.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_38...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_38...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_38...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_38.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_38.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_38.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_38 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_38.fif\n",
      "Processing file cleaned__record_39.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_39.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_39.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_39...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_39...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_39...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_39.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_39.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_39.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_39 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_39.fif\n",
      "Processing file cleaned__record_4.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_4.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_4.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_4...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_4...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_4...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_4.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_4.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_4.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_4 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_4.fif\n",
      "Processing file cleaned__record_40.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_40.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_40.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing automatic denoising for cleaned__record_40...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_40...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_40...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_40.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_40.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_40.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_40 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_40.fif\n",
      "Processing file cleaned__record_41.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_41.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_41.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_41...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_41...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_41...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_41.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_41.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_41.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_41 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_41.fif\n",
      "Processing file cleaned__record_42.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_42.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_42.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_42...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_42...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_42...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_42.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_42.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_42.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_42 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_42.fif\n",
      "Processing file cleaned__record_43.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_43.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_43.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_43...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_43...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_43...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_43.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_43.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_43.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_43 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_43.fif\n",
      "Processing file cleaned__record_44.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_44.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_44.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_44...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_44...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_44...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_44.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_44.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_44.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_44 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_44.fif\n",
      "Processing file cleaned__record_5.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_5.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_5.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_5...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_5...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_5...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_5.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_5.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_5.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_5 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_5.fif\n",
      "Processing file cleaned__record_6.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_6.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_6.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_6...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_6...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_6...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_6.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_6.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_6.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_6 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_6.fif\n",
      "Processing file cleaned__record_7.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_7.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_7.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_7...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_7...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_7...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_7.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_7.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_7.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_7 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_7.fif\n",
      "Processing file cleaned__record_8.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_8.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_8.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_8...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_8...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_8...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_8.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_8.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_8.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_8 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_8.fif\n",
      "Processing file cleaned__record_9.fif...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_9.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:57: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data\\cleaned__record_9.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n",
      "Performing automatic denoising for cleaned__record_9...\n",
      "Noisy channels identified: []\n",
      "Applying 4â€“47 Hz bandpass filter for cleaned__record_9...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 47 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 47.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 48.50 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-referencing to common average for cleaned__record_9...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Writing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_9.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_6692\\3407955171.py:81: RuntimeWarning: This filename (C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_9.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(save_path, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\denoised_data\\denoised_cleaned__record_9.fif\n",
      "[done]\n",
      "Processed and saved cleaned__record_9 to C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_9.fif\n",
      "All cleaned records have been denoised and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Directories for Cleaned and Denoised Data\n",
    "# ---------------------------------------------------------------\n",
    "cleaned_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data'\n",
    "denoised_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data'\n",
    "os.makedirs(denoised_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Function for Automatic Denoising\n",
    "# ---------------------------------------------------------------\n",
    "def denoise_eeg(raw, threshold=3, noisy_channel_ratio=0.3, spike_threshold=100):\n",
    "    # Get data and channel names\n",
    "    data = raw.get_data()\n",
    "    ch_names = raw.info['ch_names']\n",
    "    \n",
    "    # Identify noisy channels\n",
    "    noisy_channels = []\n",
    "    for i in range(data.shape[0]):\n",
    "        median_abs = np.median(np.abs(data[i]))\n",
    "        outliers = np.abs(data[i]) > (threshold * median_abs)\n",
    "        if np.sum(outliers) / data.shape[1] > noisy_channel_ratio:\n",
    "            noisy_channels.append(ch_names[i])\n",
    "    \n",
    "    print(f\"Noisy channels identified: {noisy_channels}\")\n",
    "\n",
    "    # Interpolate noisy channels\n",
    "    if noisy_channels:\n",
    "        raw.info['bads'] = noisy_channels\n",
    "        raw.interpolate_bads(reset_bads=True, mode='nearest')\n",
    "\n",
    "    # Fix remaining spikes\n",
    "    for i in range(data.shape[0]):\n",
    "        diffs = np.abs(np.diff(data[i]))\n",
    "        spike_indices = np.where(diffs > spike_threshold)[0]\n",
    "        for idx in spike_indices:\n",
    "            data[i, idx + 1] = data[i, idx]\n",
    "\n",
    "    # Update raw object with cleaned data\n",
    "    raw._data = data\n",
    "    return raw\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Process Each Cleaned File\n",
    "# ---------------------------------------------------------------\n",
    "for filename in os.listdir(cleaned_dir):\n",
    "    if filename.endswith('.fif'):\n",
    "        record_id = filename.split('.')[0]\n",
    "        cleaned_path = os.path.join(cleaned_dir, filename)\n",
    "        \n",
    "        print(f\"Processing file {filename}...\")\n",
    "\n",
    "        # Load the cleaned data\n",
    "        raw = mne.io.read_raw_fif(cleaned_path, preload=True)\n",
    "\n",
    "        # -------------------------------------------------------------------------\n",
    "        # Automatic Denoising\n",
    "        # -------------------------------------------------------------------------\n",
    "        print(f\"Performing automatic denoising for {record_id}...\")\n",
    "        raw = denoise_eeg(raw)\n",
    "\n",
    "        # -------------------------------------------------------------------------\n",
    "        # Bandpass Filter (4â€“47 Hz)\n",
    "        # -------------------------------------------------------------------------\n",
    "        print(f\"Applying 4â€“47 Hz bandpass filter for {record_id}...\")\n",
    "        raw.filter(l_freq=4.0, h_freq=47.0, fir_design='firwin')\n",
    "\n",
    "        # -------------------------------------------------------------------------\n",
    "        # Re-reference to Common Average\n",
    "        # -------------------------------------------------------------------------\n",
    "        print(f\"Re-referencing to common average for {record_id}...\")\n",
    "        raw.set_eeg_reference('average', projection=False)\n",
    "\n",
    "        # -------------------------------------------------------------------------\n",
    "        # Save the Denoised Data\n",
    "        # -------------------------------------------------------------------------\n",
    "        save_path = os.path.join(denoised_dir, f'denoised_{record_id}.fif')\n",
    "        raw.save(save_path, overwrite=True)\n",
    "        print(f\"Processed and saved {record_id} to {save_path}\")\n",
    "\n",
    "print(\"All cleaned records have been denoised and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the Data Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating contrastive pairs in batches...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_0.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_0.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_1.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_10.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_10.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_11.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_11.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_12.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_12.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_13.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_13.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_14.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_14.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_15.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_15.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_16.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_16.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_17.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_17.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_18.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_18.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_19.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_19.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_2.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_2.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_20.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_20.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_21.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_21.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_22.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\.venv\\Lib\\site-packages\\cupy\\_creation\\from_data.py:88: RuntimeWarning: overflow encountered in cast\n",
      "  return _core.array(a, dtype, False, order, blocking=blocking)\n",
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_22.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_23.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_23.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_24.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_24.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_25.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_25.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_26.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_26.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_27.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_27.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_28.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_28.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_29.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_29.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_3.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_3.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_30.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_30.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_31.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_31.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_32.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_32.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_33.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_33.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_34.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_34.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_35.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_35.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_36.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_36.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_37.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_37.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_38.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_38.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_39.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_39.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_4.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_4.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_40.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_40.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_41.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_41.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_42.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_42.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_43.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_43.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_44.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_44.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_5.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_5.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_6.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_6.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_7.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_7.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_8.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_8.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_9.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_11864\\2663074120.py:23: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_9.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 0 with 100 pairs.\n",
      "Saved batch 1 with 100 pairs.\n",
      "Saved batch 2 with 100 pairs.\n",
      "Saved batch 3 with 100 pairs.\n",
      "Saved batch 4 with 100 pairs.\n",
      "Saved batch 5 with 100 pairs.\n",
      "Saved batch 6 with 66 pairs.\n",
      "Saved batch 7 with 100 pairs.\n",
      "Saved batch 8 with 100 pairs.\n",
      "Saved batch 9 with 100 pairs.\n",
      "Saved batch 10 with 100 pairs.\n",
      "Saved batch 11 with 100 pairs.\n",
      "Saved batch 12 with 100 pairs.\n",
      "Saved batch 13 with 66 pairs.\n",
      "Saved batch 14 with 100 pairs.\n",
      "Saved batch 15 with 100 pairs.\n",
      "Saved batch 16 with 100 pairs.\n",
      "Saved batch 17 with 100 pairs.\n",
      "Saved batch 18 with 100 pairs.\n",
      "Saved batch 19 with 100 pairs.\n",
      "Saved batch 20 with 66 pairs.\n",
      "Saved batch 21 with 100 pairs.\n",
      "Saved batch 22 with 100 pairs.\n",
      "Saved batch 23 with 100 pairs.\n",
      "Saved batch 24 with 100 pairs.\n",
      "Saved batch 25 with 100 pairs.\n",
      "Saved batch 26 with 100 pairs.\n",
      "Saved batch 27 with 66 pairs.\n",
      "Saved batch 28 with 100 pairs.\n",
      "Saved batch 29 with 100 pairs.\n",
      "Saved batch 30 with 100 pairs.\n",
      "Saved batch 31 with 100 pairs.\n",
      "Saved batch 32 with 100 pairs.\n",
      "Saved batch 33 with 100 pairs.\n",
      "Saved batch 34 with 66 pairs.\n",
      "Saved batch 35 with 100 pairs.\n",
      "Saved batch 36 with 100 pairs.\n",
      "Saved batch 37 with 100 pairs.\n",
      "Saved batch 38 with 100 pairs.\n",
      "Saved batch 39 with 100 pairs.\n",
      "Saved batch 40 with 22 pairs.\n",
      "Saved batch 41 with 100 pairs.\n",
      "Saved batch 42 with 100 pairs.\n",
      "Saved batch 43 with 100 pairs.\n",
      "Saved batch 44 with 100 pairs.\n",
      "Saved batch 45 with 100 pairs.\n",
      "Saved batch 46 with 100 pairs.\n",
      "Saved batch 47 with 66 pairs.\n",
      "Saved batch 48 with 100 pairs.\n",
      "Saved batch 49 with 100 pairs.\n",
      "Saved batch 50 with 100 pairs.\n",
      "Saved batch 51 with 100 pairs.\n",
      "Saved batch 52 with 100 pairs.\n",
      "Saved batch 53 with 100 pairs.\n",
      "Saved batch 54 with 66 pairs.\n",
      "Saved batch 55 with 100 pairs.\n",
      "Saved batch 56 with 100 pairs.\n",
      "Saved batch 57 with 100 pairs.\n",
      "Saved batch 58 with 100 pairs.\n",
      "Saved batch 59 with 100 pairs.\n",
      "Saved batch 60 with 100 pairs.\n",
      "Saved batch 61 with 66 pairs.\n",
      "Saved batch 62 with 100 pairs.\n",
      "Saved batch 63 with 100 pairs.\n",
      "Saved batch 64 with 100 pairs.\n",
      "Saved batch 65 with 100 pairs.\n",
      "Saved batch 66 with 100 pairs.\n",
      "Saved batch 67 with 100 pairs.\n",
      "Saved batch 68 with 66 pairs.\n",
      "Saved batch 69 with 100 pairs.\n",
      "Saved batch 70 with 100 pairs.\n",
      "Saved batch 71 with 100 pairs.\n",
      "Saved batch 72 with 100 pairs.\n",
      "Saved batch 73 with 100 pairs.\n",
      "Saved batch 74 with 100 pairs.\n",
      "Saved batch 75 with 66 pairs.\n",
      "Saved batch 76 with 100 pairs.\n",
      "Saved batch 77 with 100 pairs.\n",
      "Saved batch 78 with 100 pairs.\n",
      "Saved batch 79 with 100 pairs.\n",
      "Saved batch 80 with 100 pairs.\n",
      "Saved batch 81 with 100 pairs.\n",
      "Saved batch 82 with 66 pairs.\n",
      "Saved batch 83 with 100 pairs.\n",
      "Saved batch 84 with 100 pairs.\n",
      "Saved batch 85 with 100 pairs.\n",
      "Saved batch 86 with 100 pairs.\n",
      "Saved batch 87 with 100 pairs.\n",
      "Saved batch 88 with 22 pairs.\n",
      "Saved batch 89 with 100 pairs.\n",
      "Saved batch 90 with 100 pairs.\n",
      "Saved batch 91 with 100 pairs.\n",
      "Saved batch 92 with 100 pairs.\n",
      "Saved batch 93 with 100 pairs.\n",
      "Saved batch 94 with 100 pairs.\n",
      "Saved batch 95 with 66 pairs.\n",
      "Saved batch 96 with 100 pairs.\n",
      "Saved batch 97 with 100 pairs.\n",
      "Saved batch 98 with 100 pairs.\n",
      "Saved batch 99 with 100 pairs.\n",
      "Saved batch 100 with 100 pairs.\n",
      "Saved batch 101 with 100 pairs.\n",
      "Saved batch 102 with 66 pairs.\n",
      "Saved batch 103 with 100 pairs.\n",
      "Saved batch 104 with 100 pairs.\n",
      "Saved batch 105 with 100 pairs.\n",
      "Saved batch 106 with 100 pairs.\n",
      "Saved batch 107 with 100 pairs.\n",
      "Saved batch 108 with 100 pairs.\n",
      "Saved batch 109 with 66 pairs.\n",
      "Saved batch 110 with 100 pairs.\n",
      "Saved batch 111 with 100 pairs.\n",
      "Saved batch 112 with 100 pairs.\n",
      "Saved batch 113 with 100 pairs.\n",
      "Saved batch 114 with 100 pairs.\n",
      "Saved batch 115 with 100 pairs.\n",
      "Saved batch 116 with 66 pairs.\n",
      "Saved batch 117 with 100 pairs.\n",
      "Saved batch 118 with 100 pairs.\n",
      "Saved batch 119 with 100 pairs.\n",
      "Saved batch 120 with 100 pairs.\n",
      "Saved batch 121 with 100 pairs.\n",
      "Saved batch 122 with 100 pairs.\n",
      "Saved batch 123 with 66 pairs.\n",
      "Saved batch 124 with 100 pairs.\n",
      "Saved batch 125 with 100 pairs.\n",
      "Saved batch 126 with 100 pairs.\n",
      "Saved batch 127 with 100 pairs.\n",
      "Saved batch 128 with 100 pairs.\n",
      "Saved batch 129 with 100 pairs.\n",
      "Saved batch 130 with 66 pairs.\n",
      "Saved batch 131 with 100 pairs.\n",
      "Saved batch 132 with 100 pairs.\n",
      "Saved batch 133 with 100 pairs.\n",
      "Saved batch 134 with 100 pairs.\n",
      "Saved batch 135 with 100 pairs.\n",
      "Saved batch 136 with 22 pairs.\n",
      "Saved batch 137 with 100 pairs.\n",
      "Saved batch 138 with 100 pairs.\n",
      "Saved batch 139 with 100 pairs.\n",
      "Saved batch 140 with 100 pairs.\n",
      "Saved batch 141 with 100 pairs.\n",
      "Saved batch 142 with 100 pairs.\n",
      "Saved batch 143 with 66 pairs.\n",
      "Saved batch 144 with 100 pairs.\n",
      "Saved batch 145 with 100 pairs.\n",
      "Saved batch 146 with 100 pairs.\n",
      "Saved batch 147 with 100 pairs.\n",
      "Saved batch 148 with 100 pairs.\n",
      "Saved batch 149 with 100 pairs.\n",
      "Saved batch 150 with 66 pairs.\n",
      "Saved batch 151 with 100 pairs.\n",
      "Saved batch 152 with 100 pairs.\n",
      "Saved batch 153 with 100 pairs.\n",
      "Saved batch 154 with 100 pairs.\n",
      "Saved batch 155 with 100 pairs.\n",
      "Saved batch 156 with 100 pairs.\n",
      "Saved batch 157 with 66 pairs.\n",
      "Saved batch 158 with 100 pairs.\n",
      "Saved batch 159 with 100 pairs.\n",
      "Saved batch 160 with 100 pairs.\n",
      "Saved batch 161 with 100 pairs.\n",
      "Saved batch 162 with 100 pairs.\n",
      "Saved batch 163 with 100 pairs.\n",
      "Saved batch 164 with 66 pairs.\n",
      "Saved batch 165 with 100 pairs.\n",
      "Saved batch 166 with 100 pairs.\n",
      "Saved batch 167 with 100 pairs.\n",
      "Saved batch 168 with 100 pairs.\n",
      "Saved batch 169 with 100 pairs.\n",
      "Saved batch 170 with 100 pairs.\n",
      "Saved batch 171 with 66 pairs.\n",
      "Saved batch 172 with 100 pairs.\n",
      "Saved batch 173 with 100 pairs.\n",
      "Saved batch 174 with 100 pairs.\n",
      "Saved batch 175 with 100 pairs.\n",
      "Saved batch 176 with 100 pairs.\n",
      "Saved batch 177 with 100 pairs.\n",
      "Saved batch 178 with 66 pairs.\n",
      "Saved batch 179 with 100 pairs.\n",
      "Saved batch 180 with 100 pairs.\n",
      "Saved batch 181 with 100 pairs.\n",
      "Saved batch 182 with 100 pairs.\n",
      "Saved batch 183 with 100 pairs.\n",
      "Saved batch 184 with 22 pairs.\n",
      "Saved batch 185 with 100 pairs.\n",
      "Saved batch 186 with 100 pairs.\n",
      "Saved batch 187 with 100 pairs.\n",
      "Saved batch 188 with 100 pairs.\n",
      "Saved batch 189 with 100 pairs.\n",
      "Saved batch 190 with 100 pairs.\n",
      "Saved batch 191 with 66 pairs.\n",
      "Saved batch 192 with 100 pairs.\n",
      "Saved batch 193 with 100 pairs.\n",
      "Saved batch 194 with 100 pairs.\n",
      "Saved batch 195 with 100 pairs.\n",
      "Saved batch 196 with 100 pairs.\n",
      "Saved batch 197 with 100 pairs.\n",
      "Saved batch 198 with 66 pairs.\n",
      "Saved batch 199 with 100 pairs.\n",
      "Saved batch 200 with 100 pairs.\n",
      "Saved batch 201 with 100 pairs.\n",
      "Saved batch 202 with 100 pairs.\n",
      "Saved batch 203 with 100 pairs.\n",
      "Saved batch 204 with 100 pairs.\n",
      "Saved batch 205 with 66 pairs.\n",
      "Saved batch 206 with 100 pairs.\n",
      "Saved batch 207 with 100 pairs.\n",
      "Saved batch 208 with 100 pairs.\n",
      "Saved batch 209 with 100 pairs.\n",
      "Saved batch 210 with 100 pairs.\n",
      "Saved batch 211 with 100 pairs.\n",
      "Saved batch 212 with 66 pairs.\n",
      "Saved batch 213 with 100 pairs.\n",
      "Saved batch 214 with 100 pairs.\n",
      "Saved batch 215 with 100 pairs.\n",
      "Saved batch 216 with 100 pairs.\n",
      "Saved batch 217 with 100 pairs.\n",
      "Saved batch 218 with 100 pairs.\n",
      "Saved batch 219 with 66 pairs.\n",
      "Saved batch 220 with 100 pairs.\n",
      "Saved batch 221 with 100 pairs.\n",
      "Saved batch 222 with 100 pairs.\n",
      "Saved batch 223 with 100 pairs.\n",
      "Saved batch 224 with 100 pairs.\n",
      "Saved batch 225 with 100 pairs.\n",
      "Saved batch 226 with 66 pairs.\n",
      "Saved batch 227 with 100 pairs.\n",
      "Saved batch 228 with 100 pairs.\n",
      "Saved batch 229 with 100 pairs.\n",
      "Saved batch 230 with 100 pairs.\n",
      "Saved batch 231 with 100 pairs.\n",
      "Saved batch 232 with 22 pairs.\n",
      "Saved batch 233 with 100 pairs.\n",
      "Saved batch 234 with 100 pairs.\n",
      "Saved batch 235 with 100 pairs.\n",
      "Saved batch 236 with 100 pairs.\n",
      "Saved batch 237 with 100 pairs.\n",
      "Saved batch 238 with 100 pairs.\n",
      "Saved batch 239 with 66 pairs.\n",
      "Saved batch 240 with 100 pairs.\n",
      "Saved batch 241 with 100 pairs.\n",
      "Saved batch 242 with 100 pairs.\n",
      "Saved batch 243 with 100 pairs.\n",
      "Saved batch 244 with 100 pairs.\n",
      "Saved batch 245 with 100 pairs.\n",
      "Saved batch 246 with 66 pairs.\n",
      "Saved batch 247 with 100 pairs.\n",
      "Saved batch 248 with 100 pairs.\n",
      "Saved batch 249 with 100 pairs.\n",
      "Saved batch 250 with 100 pairs.\n",
      "Saved batch 251 with 100 pairs.\n",
      "Saved batch 252 with 100 pairs.\n",
      "Saved batch 253 with 66 pairs.\n",
      "Saved batch 254 with 100 pairs.\n",
      "Saved batch 255 with 100 pairs.\n",
      "Saved batch 256 with 100 pairs.\n",
      "Saved batch 257 with 100 pairs.\n",
      "Saved batch 258 with 100 pairs.\n",
      "Saved batch 259 with 100 pairs.\n",
      "Saved batch 260 with 66 pairs.\n",
      "Saved batch 261 with 100 pairs.\n",
      "Saved batch 262 with 100 pairs.\n",
      "Saved batch 263 with 100 pairs.\n",
      "Saved batch 264 with 100 pairs.\n",
      "Saved batch 265 with 100 pairs.\n",
      "Saved batch 266 with 100 pairs.\n",
      "Saved batch 267 with 66 pairs.\n",
      "Saved batch 268 with 100 pairs.\n",
      "Saved batch 269 with 100 pairs.\n",
      "Saved batch 270 with 100 pairs.\n",
      "Saved batch 271 with 100 pairs.\n",
      "Saved batch 272 with 100 pairs.\n",
      "Saved batch 273 with 100 pairs.\n",
      "Saved batch 274 with 66 pairs.\n",
      "Saved batch 275 with 100 pairs.\n",
      "Saved batch 276 with 100 pairs.\n",
      "Saved batch 277 with 100 pairs.\n",
      "Saved batch 278 with 100 pairs.\n",
      "Saved batch 279 with 100 pairs.\n",
      "Saved batch 280 with 22 pairs.\n",
      "Saved batch 281 with 100 pairs.\n",
      "Saved batch 282 with 100 pairs.\n",
      "Saved batch 283 with 100 pairs.\n",
      "Saved batch 284 with 100 pairs.\n",
      "Saved batch 285 with 100 pairs.\n",
      "Saved batch 286 with 100 pairs.\n",
      "Saved batch 287 with 66 pairs.\n",
      "Saved batch 288 with 100 pairs.\n",
      "Saved batch 289 with 100 pairs.\n",
      "Saved batch 290 with 100 pairs.\n",
      "Saved batch 291 with 100 pairs.\n",
      "Saved batch 292 with 100 pairs.\n",
      "Saved batch 293 with 100 pairs.\n",
      "Saved batch 294 with 66 pairs.\n",
      "Saved batch 295 with 100 pairs.\n",
      "Saved batch 296 with 100 pairs.\n",
      "Saved batch 297 with 100 pairs.\n",
      "Saved batch 298 with 100 pairs.\n",
      "Saved batch 299 with 100 pairs.\n",
      "Saved batch 300 with 100 pairs.\n",
      "Saved batch 301 with 66 pairs.\n",
      "Saved batch 302 with 100 pairs.\n",
      "Saved batch 303 with 100 pairs.\n",
      "Saved batch 304 with 100 pairs.\n",
      "Saved batch 305 with 100 pairs.\n",
      "Saved batch 306 with 100 pairs.\n",
      "Saved batch 307 with 100 pairs.\n",
      "Saved batch 308 with 66 pairs.\n",
      "Saved batch 309 with 100 pairs.\n",
      "Saved batch 310 with 100 pairs.\n",
      "Saved batch 311 with 100 pairs.\n",
      "Saved batch 312 with 100 pairs.\n",
      "Saved batch 313 with 100 pairs.\n",
      "Saved batch 314 with 100 pairs.\n",
      "Saved batch 315 with 66 pairs.\n",
      "Saved batch 316 with 100 pairs.\n",
      "Saved batch 317 with 100 pairs.\n",
      "Saved batch 318 with 100 pairs.\n",
      "Saved batch 319 with 100 pairs.\n",
      "Saved batch 320 with 100 pairs.\n",
      "Saved batch 321 with 100 pairs.\n",
      "Saved batch 322 with 66 pairs.\n",
      "Saved batch 323 with 100 pairs.\n",
      "Saved batch 324 with 100 pairs.\n",
      "Saved batch 325 with 100 pairs.\n",
      "Saved batch 326 with 100 pairs.\n",
      "Saved batch 327 with 100 pairs.\n",
      "Saved batch 328 with 22 pairs.\n",
      "Saved batch 329 with 100 pairs.\n",
      "Saved batch 330 with 100 pairs.\n",
      "Saved batch 331 with 100 pairs.\n",
      "Saved batch 332 with 100 pairs.\n",
      "Saved batch 333 with 100 pairs.\n",
      "Saved batch 334 with 100 pairs.\n",
      "Saved batch 335 with 66 pairs.\n",
      "Saved batch 336 with 100 pairs.\n",
      "Saved batch 337 with 100 pairs.\n",
      "Saved batch 338 with 100 pairs.\n",
      "Saved batch 339 with 100 pairs.\n",
      "Saved batch 340 with 100 pairs.\n",
      "Saved batch 341 with 100 pairs.\n",
      "Saved batch 342 with 66 pairs.\n",
      "Saved batch 343 with 100 pairs.\n",
      "Saved batch 344 with 100 pairs.\n",
      "Saved batch 345 with 100 pairs.\n",
      "Saved batch 346 with 100 pairs.\n",
      "Saved batch 347 with 100 pairs.\n",
      "Saved batch 348 with 100 pairs.\n",
      "Saved batch 349 with 66 pairs.\n",
      "Saved batch 350 with 100 pairs.\n",
      "Saved batch 351 with 100 pairs.\n",
      "Saved batch 352 with 100 pairs.\n",
      "Saved batch 353 with 100 pairs.\n",
      "Saved batch 354 with 100 pairs.\n",
      "Saved batch 355 with 100 pairs.\n",
      "Saved batch 356 with 66 pairs.\n",
      "Saved batch 357 with 100 pairs.\n",
      "Saved batch 358 with 100 pairs.\n",
      "Saved batch 359 with 100 pairs.\n",
      "Saved batch 360 with 100 pairs.\n",
      "Saved batch 361 with 100 pairs.\n",
      "Saved batch 362 with 100 pairs.\n",
      "Saved batch 363 with 66 pairs.\n",
      "Saved batch 364 with 100 pairs.\n",
      "Saved batch 365 with 100 pairs.\n",
      "Saved batch 366 with 100 pairs.\n",
      "Saved batch 367 with 100 pairs.\n",
      "Saved batch 368 with 100 pairs.\n",
      "Saved batch 369 with 100 pairs.\n",
      "Saved batch 370 with 66 pairs.\n",
      "Saved batch 371 with 100 pairs.\n",
      "Saved batch 372 with 100 pairs.\n",
      "Saved batch 373 with 100 pairs.\n",
      "Saved batch 374 with 100 pairs.\n",
      "Saved batch 375 with 100 pairs.\n",
      "Saved batch 376 with 22 pairs.\n",
      "Saved batch 377 with 100 pairs.\n",
      "Saved batch 378 with 100 pairs.\n",
      "Saved batch 379 with 100 pairs.\n",
      "Saved batch 380 with 100 pairs.\n",
      "Saved batch 381 with 100 pairs.\n",
      "Saved batch 382 with 100 pairs.\n",
      "Saved batch 383 with 66 pairs.\n",
      "Saved batch 384 with 100 pairs.\n",
      "Saved batch 385 with 100 pairs.\n",
      "Saved batch 386 with 100 pairs.\n",
      "Saved batch 387 with 100 pairs.\n",
      "Saved batch 388 with 100 pairs.\n",
      "Saved batch 389 with 100 pairs.\n",
      "Saved batch 390 with 66 pairs.\n",
      "Saved batch 391 with 100 pairs.\n",
      "Saved batch 392 with 100 pairs.\n",
      "Saved batch 393 with 100 pairs.\n",
      "Saved batch 394 with 100 pairs.\n",
      "Saved batch 395 with 100 pairs.\n",
      "Saved batch 396 with 100 pairs.\n",
      "Saved batch 397 with 66 pairs.\n",
      "Saved batch 398 with 100 pairs.\n",
      "Saved batch 399 with 100 pairs.\n",
      "Saved batch 400 with 100 pairs.\n",
      "Saved batch 401 with 100 pairs.\n",
      "Saved batch 402 with 100 pairs.\n",
      "Saved batch 403 with 100 pairs.\n",
      "Saved batch 404 with 66 pairs.\n",
      "Saved batch 405 with 100 pairs.\n",
      "Saved batch 406 with 100 pairs.\n",
      "Saved batch 407 with 100 pairs.\n",
      "Saved batch 408 with 100 pairs.\n",
      "Saved batch 409 with 100 pairs.\n",
      "Saved batch 410 with 100 pairs.\n",
      "Saved batch 411 with 66 pairs.\n",
      "Saved batch 412 with 100 pairs.\n",
      "Saved batch 413 with 100 pairs.\n",
      "Saved batch 414 with 100 pairs.\n",
      "Saved batch 415 with 100 pairs.\n",
      "Saved batch 416 with 100 pairs.\n",
      "Saved batch 417 with 100 pairs.\n",
      "Saved batch 418 with 66 pairs.\n",
      "Saved batch 419 with 100 pairs.\n",
      "Saved batch 420 with 100 pairs.\n",
      "Saved batch 421 with 100 pairs.\n",
      "Saved batch 422 with 100 pairs.\n",
      "Saved batch 423 with 100 pairs.\n",
      "Saved batch 424 with 22 pairs.\n",
      "Saved batch 425 with 100 pairs.\n",
      "Saved batch 426 with 100 pairs.\n",
      "Saved batch 427 with 100 pairs.\n",
      "Saved batch 428 with 100 pairs.\n",
      "Saved batch 429 with 100 pairs.\n",
      "Saved batch 430 with 100 pairs.\n",
      "Saved batch 431 with 66 pairs.\n",
      "Saved batch 432 with 100 pairs.\n",
      "Saved batch 433 with 100 pairs.\n",
      "Saved batch 434 with 100 pairs.\n",
      "Saved batch 435 with 100 pairs.\n",
      "Saved batch 436 with 100 pairs.\n",
      "Saved batch 437 with 100 pairs.\n",
      "Saved batch 438 with 66 pairs.\n",
      "Saved batch 439 with 100 pairs.\n",
      "Saved batch 440 with 100 pairs.\n",
      "Saved batch 441 with 100 pairs.\n",
      "Saved batch 442 with 100 pairs.\n",
      "Saved batch 443 with 100 pairs.\n",
      "Saved batch 444 with 100 pairs.\n",
      "Saved batch 445 with 66 pairs.\n",
      "Saved batch 446 with 100 pairs.\n",
      "Saved batch 447 with 100 pairs.\n",
      "Saved batch 448 with 100 pairs.\n",
      "Saved batch 449 with 100 pairs.\n",
      "Saved batch 450 with 100 pairs.\n",
      "Saved batch 451 with 100 pairs.\n",
      "Saved batch 452 with 66 pairs.\n",
      "Saved batch 453 with 100 pairs.\n",
      "Saved batch 454 with 100 pairs.\n",
      "Saved batch 455 with 100 pairs.\n",
      "Saved batch 456 with 100 pairs.\n",
      "Saved batch 457 with 100 pairs.\n",
      "Saved batch 458 with 100 pairs.\n",
      "Saved batch 459 with 66 pairs.\n",
      "Saved batch 460 with 100 pairs.\n",
      "Saved batch 461 with 100 pairs.\n",
      "Saved batch 462 with 100 pairs.\n",
      "Saved batch 463 with 100 pairs.\n",
      "Saved batch 464 with 100 pairs.\n",
      "Saved batch 465 with 100 pairs.\n",
      "Saved batch 466 with 66 pairs.\n",
      "Saved batch 467 with 100 pairs.\n",
      "Saved batch 468 with 100 pairs.\n",
      "Saved batch 469 with 100 pairs.\n",
      "Saved batch 470 with 100 pairs.\n",
      "Saved batch 471 with 100 pairs.\n",
      "Saved batch 472 with 22 pairs.\n",
      "Saved batch 473 with 100 pairs.\n",
      "Saved batch 474 with 100 pairs.\n",
      "Saved batch 475 with 100 pairs.\n",
      "Saved batch 476 with 100 pairs.\n",
      "Saved batch 477 with 100 pairs.\n",
      "Saved batch 478 with 100 pairs.\n",
      "Saved batch 479 with 66 pairs.\n",
      "Saved batch 480 with 100 pairs.\n",
      "Saved batch 481 with 100 pairs.\n",
      "Saved batch 482 with 100 pairs.\n",
      "Saved batch 483 with 100 pairs.\n",
      "Saved batch 484 with 100 pairs.\n",
      "Saved batch 485 with 100 pairs.\n",
      "Saved batch 486 with 66 pairs.\n",
      "Saved batch 487 with 100 pairs.\n",
      "Saved batch 488 with 100 pairs.\n",
      "Saved batch 489 with 100 pairs.\n",
      "Saved batch 490 with 100 pairs.\n",
      "Saved batch 491 with 100 pairs.\n",
      "Saved batch 492 with 100 pairs.\n",
      "Saved batch 493 with 66 pairs.\n",
      "Saved batch 494 with 100 pairs.\n",
      "Saved batch 495 with 100 pairs.\n",
      "Saved batch 496 with 100 pairs.\n",
      "Saved batch 497 with 100 pairs.\n",
      "Saved batch 498 with 100 pairs.\n",
      "Saved batch 499 with 100 pairs.\n",
      "Saved batch 500 with 66 pairs.\n",
      "Saved batch 501 with 100 pairs.\n",
      "Saved batch 502 with 100 pairs.\n",
      "Saved batch 503 with 100 pairs.\n",
      "Saved batch 504 with 100 pairs.\n",
      "Saved batch 505 with 100 pairs.\n",
      "Saved batch 506 with 100 pairs.\n",
      "Saved batch 507 with 66 pairs.\n",
      "Saved batch 508 with 100 pairs.\n",
      "Saved batch 509 with 100 pairs.\n",
      "Saved batch 510 with 100 pairs.\n",
      "Saved batch 511 with 100 pairs.\n",
      "Saved batch 512 with 100 pairs.\n",
      "Saved batch 513 with 100 pairs.\n",
      "Saved batch 514 with 66 pairs.\n",
      "Saved batch 515 with 100 pairs.\n",
      "Saved batch 516 with 100 pairs.\n",
      "Saved batch 517 with 100 pairs.\n",
      "Saved batch 518 with 100 pairs.\n",
      "Saved batch 519 with 100 pairs.\n",
      "Saved batch 520 with 22 pairs.\n",
      "Saved batch 521 with 100 pairs.\n",
      "Saved batch 522 with 100 pairs.\n",
      "Saved batch 523 with 100 pairs.\n",
      "Saved batch 524 with 100 pairs.\n",
      "Saved batch 525 with 100 pairs.\n",
      "Saved batch 526 with 100 pairs.\n",
      "Saved batch 527 with 66 pairs.\n",
      "Saved batch 528 with 100 pairs.\n",
      "Saved batch 529 with 100 pairs.\n",
      "Saved batch 530 with 100 pairs.\n",
      "Saved batch 531 with 100 pairs.\n",
      "Saved batch 532 with 100 pairs.\n",
      "Saved batch 533 with 100 pairs.\n",
      "Saved batch 534 with 66 pairs.\n",
      "Saved batch 535 with 100 pairs.\n",
      "Saved batch 536 with 100 pairs.\n",
      "Saved batch 537 with 100 pairs.\n",
      "Saved batch 538 with 100 pairs.\n",
      "Saved batch 539 with 100 pairs.\n",
      "Saved batch 540 with 100 pairs.\n",
      "Saved batch 541 with 66 pairs.\n",
      "Saved batch 542 with 100 pairs.\n",
      "Saved batch 543 with 100 pairs.\n",
      "Saved batch 544 with 100 pairs.\n",
      "Saved batch 545 with 100 pairs.\n",
      "Saved batch 546 with 100 pairs.\n",
      "Saved batch 547 with 100 pairs.\n",
      "Saved batch 548 with 66 pairs.\n",
      "Saved batch 549 with 100 pairs.\n",
      "Saved batch 550 with 100 pairs.\n",
      "Saved batch 551 with 100 pairs.\n",
      "Saved batch 552 with 100 pairs.\n",
      "Saved batch 553 with 100 pairs.\n",
      "Saved batch 554 with 100 pairs.\n",
      "Saved batch 555 with 66 pairs.\n",
      "Saved batch 556 with 100 pairs.\n",
      "Saved batch 557 with 100 pairs.\n",
      "Saved batch 558 with 100 pairs.\n",
      "Saved batch 559 with 100 pairs.\n",
      "Saved batch 560 with 100 pairs.\n",
      "Saved batch 561 with 100 pairs.\n",
      "Saved batch 562 with 66 pairs.\n",
      "Saved batch 563 with 100 pairs.\n",
      "Saved batch 564 with 100 pairs.\n",
      "Saved batch 565 with 100 pairs.\n",
      "Saved batch 566 with 100 pairs.\n",
      "Saved batch 567 with 100 pairs.\n",
      "Saved batch 568 with 22 pairs.\n",
      "Saved batch 569 with 100 pairs.\n",
      "Saved batch 570 with 100 pairs.\n",
      "Saved batch 571 with 100 pairs.\n",
      "Saved batch 572 with 100 pairs.\n",
      "Saved batch 573 with 100 pairs.\n",
      "Saved batch 574 with 100 pairs.\n",
      "Saved batch 575 with 66 pairs.\n",
      "Saved batch 576 with 100 pairs.\n",
      "Saved batch 577 with 100 pairs.\n",
      "Saved batch 578 with 100 pairs.\n",
      "Saved batch 579 with 100 pairs.\n",
      "Saved batch 580 with 100 pairs.\n",
      "Saved batch 581 with 100 pairs.\n",
      "Saved batch 582 with 66 pairs.\n",
      "Saved batch 583 with 100 pairs.\n",
      "Saved batch 584 with 100 pairs.\n",
      "Saved batch 585 with 100 pairs.\n",
      "Saved batch 586 with 100 pairs.\n",
      "Saved batch 587 with 100 pairs.\n",
      "Saved batch 588 with 100 pairs.\n",
      "Saved batch 589 with 66 pairs.\n",
      "Saved batch 590 with 100 pairs.\n",
      "Saved batch 591 with 100 pairs.\n",
      "Saved batch 592 with 100 pairs.\n",
      "Saved batch 593 with 100 pairs.\n",
      "Saved batch 594 with 100 pairs.\n",
      "Saved batch 595 with 100 pairs.\n",
      "Saved batch 596 with 66 pairs.\n",
      "Saved batch 597 with 100 pairs.\n",
      "Saved batch 598 with 100 pairs.\n",
      "Saved batch 599 with 100 pairs.\n",
      "Saved batch 600 with 100 pairs.\n",
      "Saved batch 601 with 100 pairs.\n",
      "Saved batch 602 with 100 pairs.\n",
      "Saved batch 603 with 66 pairs.\n",
      "Saved batch 604 with 100 pairs.\n",
      "Saved batch 605 with 100 pairs.\n",
      "Saved batch 606 with 100 pairs.\n",
      "Saved batch 607 with 100 pairs.\n",
      "Saved batch 608 with 100 pairs.\n",
      "Saved batch 609 with 100 pairs.\n",
      "Saved batch 610 with 66 pairs.\n",
      "Saved batch 611 with 100 pairs.\n",
      "Saved batch 612 with 100 pairs.\n",
      "Saved batch 613 with 100 pairs.\n",
      "Saved batch 614 with 100 pairs.\n",
      "Saved batch 615 with 100 pairs.\n",
      "Saved batch 616 with 22 pairs.\n",
      "Saved batch 617 with 100 pairs.\n",
      "Saved batch 618 with 100 pairs.\n",
      "Saved batch 619 with 100 pairs.\n",
      "Saved batch 620 with 100 pairs.\n",
      "Saved batch 621 with 100 pairs.\n",
      "Saved batch 622 with 100 pairs.\n",
      "Saved batch 623 with 66 pairs.\n",
      "Saved batch 624 with 100 pairs.\n",
      "Saved batch 625 with 100 pairs.\n",
      "Saved batch 626 with 100 pairs.\n",
      "Saved batch 627 with 100 pairs.\n",
      "Saved batch 628 with 100 pairs.\n",
      "Saved batch 629 with 100 pairs.\n",
      "Saved batch 630 with 66 pairs.\n",
      "Saved batch 631 with 100 pairs.\n",
      "Saved batch 632 with 100 pairs.\n",
      "Saved batch 633 with 100 pairs.\n",
      "Saved batch 634 with 100 pairs.\n",
      "Saved batch 635 with 100 pairs.\n",
      "Saved batch 636 with 100 pairs.\n",
      "Saved batch 637 with 66 pairs.\n",
      "Saved batch 638 with 100 pairs.\n",
      "Saved batch 639 with 100 pairs.\n",
      "Saved batch 640 with 100 pairs.\n",
      "Saved batch 641 with 100 pairs.\n",
      "Saved batch 642 with 100 pairs.\n",
      "Saved batch 643 with 100 pairs.\n",
      "Saved batch 644 with 66 pairs.\n",
      "Saved batch 645 with 100 pairs.\n",
      "Saved batch 646 with 100 pairs.\n",
      "Saved batch 647 with 100 pairs.\n",
      "Saved batch 648 with 100 pairs.\n",
      "Saved batch 649 with 100 pairs.\n",
      "Saved batch 650 with 100 pairs.\n",
      "Saved batch 651 with 66 pairs.\n",
      "Saved batch 652 with 100 pairs.\n",
      "Saved batch 653 with 100 pairs.\n",
      "Saved batch 654 with 100 pairs.\n",
      "Saved batch 655 with 100 pairs.\n",
      "Saved batch 656 with 100 pairs.\n",
      "Saved batch 657 with 100 pairs.\n",
      "Saved batch 658 with 66 pairs.\n",
      "Saved batch 659 with 100 pairs.\n",
      "Saved batch 660 with 100 pairs.\n",
      "Saved batch 661 with 100 pairs.\n",
      "Saved batch 662 with 100 pairs.\n",
      "Saved batch 663 with 100 pairs.\n",
      "Saved batch 664 with 22 pairs.\n",
      "Saved batch 665 with 100 pairs.\n",
      "Saved batch 666 with 100 pairs.\n",
      "Saved batch 667 with 100 pairs.\n",
      "Saved batch 668 with 100 pairs.\n",
      "Saved batch 669 with 100 pairs.\n",
      "Saved batch 670 with 100 pairs.\n",
      "Saved batch 671 with 66 pairs.\n",
      "Saved batch 672 with 100 pairs.\n",
      "Saved batch 673 with 100 pairs.\n",
      "Saved batch 674 with 100 pairs.\n",
      "Saved batch 675 with 100 pairs.\n",
      "Saved batch 676 with 100 pairs.\n",
      "Saved batch 677 with 100 pairs.\n",
      "Saved batch 678 with 66 pairs.\n",
      "Saved batch 679 with 100 pairs.\n",
      "Saved batch 680 with 100 pairs.\n",
      "Saved batch 681 with 100 pairs.\n",
      "Saved batch 682 with 100 pairs.\n",
      "Saved batch 683 with 100 pairs.\n",
      "Saved batch 684 with 100 pairs.\n",
      "Saved batch 685 with 66 pairs.\n",
      "Saved batch 686 with 100 pairs.\n",
      "Saved batch 687 with 100 pairs.\n",
      "Saved batch 688 with 100 pairs.\n",
      "Saved batch 689 with 100 pairs.\n",
      "Saved batch 690 with 100 pairs.\n",
      "Saved batch 691 with 100 pairs.\n",
      "Saved batch 692 with 66 pairs.\n",
      "Saved batch 693 with 100 pairs.\n",
      "NaNs or Infs found in record denoised_cleaned__record_0 or denoised_cleaned__record_21, skipping this pair.\n",
      "Saved batch 694 with 100 pairs.\n",
      "Saved batch 695 with 100 pairs.\n",
      "Saved batch 696 with 100 pairs.\n",
      "Saved batch 697 with 100 pairs.\n",
      "Saved batch 698 with 100 pairs.\n",
      "Saved batch 699 with 60 pairs.\n",
      "Saved batch 700 with 100 pairs.\n",
      "Saved batch 701 with 100 pairs.\n",
      "Saved batch 702 with 100 pairs.\n",
      "Saved batch 703 with 100 pairs.\n",
      "Saved batch 704 with 100 pairs.\n",
      "Saved batch 705 with 100 pairs.\n",
      "Saved batch 706 with 66 pairs.\n",
      "Saved batch 707 with 100 pairs.\n",
      "Saved batch 708 with 100 pairs.\n",
      "Saved batch 709 with 100 pairs.\n",
      "Saved batch 710 with 100 pairs.\n",
      "Saved batch 711 with 100 pairs.\n",
      "Saved batch 712 with 22 pairs.\n",
      "Saved batch 713 with 100 pairs.\n",
      "Saved batch 714 with 100 pairs.\n",
      "Saved batch 715 with 100 pairs.\n",
      "Saved batch 716 with 100 pairs.\n",
      "Saved batch 717 with 100 pairs.\n",
      "Saved batch 718 with 100 pairs.\n",
      "Saved batch 719 with 66 pairs.\n",
      "Saved batch 720 with 100 pairs.\n",
      "Saved batch 721 with 100 pairs.\n",
      "Saved batch 722 with 100 pairs.\n",
      "Saved batch 723 with 100 pairs.\n",
      "Saved batch 724 with 100 pairs.\n",
      "Saved batch 725 with 100 pairs.\n",
      "Saved batch 726 with 66 pairs.\n",
      "Saved batch 727 with 100 pairs.\n",
      "Saved batch 728 with 100 pairs.\n",
      "Saved batch 729 with 100 pairs.\n",
      "Saved batch 730 with 100 pairs.\n",
      "Saved batch 731 with 100 pairs.\n",
      "Saved batch 732 with 100 pairs.\n",
      "Saved batch 733 with 66 pairs.\n",
      "Saved batch 734 with 100 pairs.\n",
      "Saved batch 735 with 100 pairs.\n",
      "Saved batch 736 with 100 pairs.\n",
      "Saved batch 737 with 100 pairs.\n",
      "Saved batch 738 with 100 pairs.\n",
      "Saved batch 739 with 100 pairs.\n",
      "Saved batch 740 with 66 pairs.\n",
      "Saved batch 741 with 100 pairs.\n",
      "Saved batch 742 with 100 pairs.\n",
      "Saved batch 743 with 100 pairs.\n",
      "Saved batch 744 with 100 pairs.\n",
      "Saved batch 745 with 100 pairs.\n",
      "Saved batch 746 with 100 pairs.\n",
      "Saved batch 747 with 66 pairs.\n",
      "Saved batch 748 with 100 pairs.\n",
      "Saved batch 749 with 100 pairs.\n",
      "Saved batch 750 with 100 pairs.\n",
      "Saved batch 751 with 100 pairs.\n",
      "Saved batch 752 with 100 pairs.\n",
      "Saved batch 753 with 100 pairs.\n",
      "Saved batch 754 with 66 pairs.\n",
      "Saved batch 755 with 100 pairs.\n",
      "Saved batch 756 with 100 pairs.\n",
      "Saved batch 757 with 100 pairs.\n",
      "Saved batch 758 with 100 pairs.\n",
      "Saved batch 759 with 100 pairs.\n",
      "Saved batch 760 with 22 pairs.\n",
      "Saved batch 761 with 100 pairs.\n",
      "Saved batch 762 with 100 pairs.\n",
      "Saved batch 763 with 100 pairs.\n",
      "Saved batch 764 with 100 pairs.\n",
      "Saved batch 765 with 100 pairs.\n",
      "Saved batch 766 with 100 pairs.\n",
      "Saved batch 767 with 66 pairs.\n",
      "Saved batch 768 with 100 pairs.\n",
      "Saved batch 769 with 100 pairs.\n",
      "Saved batch 770 with 100 pairs.\n",
      "Saved batch 771 with 100 pairs.\n",
      "Saved batch 772 with 100 pairs.\n",
      "Saved batch 773 with 100 pairs.\n",
      "Saved batch 774 with 66 pairs.\n",
      "Saved batch 775 with 100 pairs.\n",
      "Saved batch 776 with 100 pairs.\n",
      "Saved batch 777 with 100 pairs.\n",
      "Saved batch 778 with 100 pairs.\n",
      "Saved batch 779 with 100 pairs.\n",
      "Saved batch 780 with 100 pairs.\n",
      "Saved batch 781 with 66 pairs.\n",
      "Saved batch 782 with 100 pairs.\n",
      "Saved batch 783 with 100 pairs.\n",
      "Saved batch 784 with 100 pairs.\n",
      "Saved batch 785 with 100 pairs.\n",
      "Saved batch 786 with 100 pairs.\n",
      "Saved batch 787 with 100 pairs.\n",
      "Saved batch 788 with 66 pairs.\n",
      "Saved batch 789 with 100 pairs.\n",
      "Saved batch 790 with 100 pairs.\n",
      "Saved batch 791 with 100 pairs.\n",
      "Saved batch 792 with 100 pairs.\n",
      "Saved batch 793 with 100 pairs.\n",
      "Saved batch 794 with 100 pairs.\n",
      "Saved batch 795 with 66 pairs.\n",
      "Saved batch 796 with 100 pairs.\n",
      "Saved batch 797 with 100 pairs.\n",
      "Saved batch 798 with 100 pairs.\n",
      "Saved batch 799 with 100 pairs.\n",
      "Saved batch 800 with 100 pairs.\n",
      "Saved batch 801 with 100 pairs.\n",
      "Saved batch 802 with 66 pairs.\n",
      "Saved batch 803 with 100 pairs.\n",
      "Saved batch 804 with 100 pairs.\n",
      "Saved batch 805 with 100 pairs.\n",
      "Saved batch 806 with 100 pairs.\n",
      "Saved batch 807 with 100 pairs.\n",
      "Saved batch 808 with 22 pairs.\n",
      "Saved batch 809 with 100 pairs.\n",
      "Saved batch 810 with 100 pairs.\n",
      "Saved batch 811 with 100 pairs.\n",
      "Saved batch 812 with 100 pairs.\n",
      "Saved batch 813 with 100 pairs.\n",
      "Saved batch 814 with 100 pairs.\n",
      "Saved batch 815 with 66 pairs.\n",
      "Saved batch 816 with 100 pairs.\n",
      "Saved batch 817 with 100 pairs.\n",
      "Saved batch 818 with 100 pairs.\n",
      "Saved batch 819 with 100 pairs.\n",
      "Saved batch 820 with 100 pairs.\n",
      "Saved batch 821 with 100 pairs.\n",
      "Saved batch 822 with 66 pairs.\n",
      "Saved batch 823 with 100 pairs.\n",
      "Saved batch 824 with 100 pairs.\n",
      "Saved batch 825 with 100 pairs.\n",
      "Saved batch 826 with 100 pairs.\n",
      "Saved batch 827 with 100 pairs.\n",
      "Saved batch 828 with 100 pairs.\n",
      "Saved batch 829 with 66 pairs.\n",
      "Saved batch 830 with 100 pairs.\n",
      "Saved batch 831 with 100 pairs.\n",
      "Saved batch 832 with 100 pairs.\n",
      "Saved batch 833 with 100 pairs.\n",
      "Saved batch 834 with 100 pairs.\n",
      "Saved batch 835 with 100 pairs.\n",
      "Saved batch 836 with 66 pairs.\n",
      "Saved batch 837 with 100 pairs.\n",
      "Saved batch 838 with 100 pairs.\n",
      "Saved batch 839 with 100 pairs.\n",
      "Saved batch 840 with 100 pairs.\n",
      "Saved batch 841 with 100 pairs.\n",
      "Saved batch 842 with 100 pairs.\n",
      "Saved batch 843 with 66 pairs.\n",
      "Saved batch 844 with 100 pairs.\n",
      "Saved batch 845 with 100 pairs.\n",
      "Saved batch 846 with 100 pairs.\n",
      "Saved batch 847 with 100 pairs.\n",
      "Saved batch 848 with 100 pairs.\n",
      "Saved batch 849 with 100 pairs.\n",
      "Saved batch 850 with 66 pairs.\n",
      "Saved batch 851 with 100 pairs.\n",
      "Saved batch 852 with 100 pairs.\n",
      "Saved batch 853 with 100 pairs.\n",
      "Saved batch 854 with 100 pairs.\n",
      "Saved batch 855 with 100 pairs.\n",
      "Saved batch 856 with 22 pairs.\n",
      "Saved batch 857 with 100 pairs.\n",
      "Saved batch 858 with 100 pairs.\n",
      "Saved batch 859 with 100 pairs.\n",
      "Saved batch 860 with 100 pairs.\n",
      "Saved batch 861 with 100 pairs.\n",
      "Saved batch 862 with 100 pairs.\n",
      "Saved batch 863 with 66 pairs.\n",
      "Saved batch 864 with 100 pairs.\n",
      "Saved batch 865 with 100 pairs.\n",
      "Saved batch 866 with 100 pairs.\n",
      "Saved batch 867 with 100 pairs.\n",
      "Saved batch 868 with 100 pairs.\n",
      "Saved batch 869 with 100 pairs.\n",
      "Saved batch 870 with 66 pairs.\n",
      "Saved batch 871 with 100 pairs.\n",
      "Saved batch 872 with 100 pairs.\n",
      "Saved batch 873 with 100 pairs.\n",
      "Saved batch 874 with 100 pairs.\n",
      "Saved batch 875 with 100 pairs.\n",
      "Saved batch 876 with 100 pairs.\n",
      "Saved batch 877 with 66 pairs.\n",
      "Saved batch 878 with 100 pairs.\n",
      "Saved batch 879 with 100 pairs.\n",
      "Saved batch 880 with 100 pairs.\n",
      "Saved batch 881 with 100 pairs.\n",
      "Saved batch 882 with 100 pairs.\n",
      "Saved batch 883 with 100 pairs.\n",
      "Saved batch 884 with 66 pairs.\n",
      "Saved batch 885 with 100 pairs.\n",
      "Saved batch 886 with 100 pairs.\n",
      "Saved batch 887 with 100 pairs.\n",
      "Saved batch 888 with 100 pairs.\n",
      "Saved batch 889 with 100 pairs.\n",
      "Saved batch 890 with 100 pairs.\n",
      "Saved batch 891 with 66 pairs.\n",
      "Saved batch 892 with 100 pairs.\n",
      "Saved batch 893 with 100 pairs.\n",
      "Saved batch 894 with 100 pairs.\n",
      "Saved batch 895 with 100 pairs.\n",
      "Saved batch 896 with 100 pairs.\n",
      "Saved batch 897 with 100 pairs.\n",
      "Saved batch 898 with 66 pairs.\n",
      "Saved batch 899 with 100 pairs.\n",
      "Saved batch 900 with 100 pairs.\n",
      "Saved batch 901 with 100 pairs.\n",
      "Saved batch 902 with 100 pairs.\n",
      "Saved batch 903 with 100 pairs.\n",
      "Saved batch 904 with 22 pairs.\n",
      "Saved batch 905 with 100 pairs.\n",
      "Saved batch 906 with 100 pairs.\n",
      "Saved batch 907 with 100 pairs.\n",
      "Saved batch 908 with 100 pairs.\n",
      "Saved batch 909 with 100 pairs.\n",
      "Saved batch 910 with 100 pairs.\n",
      "Saved batch 911 with 66 pairs.\n",
      "Saved batch 912 with 100 pairs.\n",
      "Saved batch 913 with 100 pairs.\n",
      "Saved batch 914 with 100 pairs.\n",
      "Saved batch 915 with 100 pairs.\n",
      "Saved batch 916 with 100 pairs.\n",
      "Saved batch 917 with 100 pairs.\n",
      "Saved batch 918 with 66 pairs.\n",
      "Saved batch 919 with 100 pairs.\n",
      "Saved batch 920 with 100 pairs.\n",
      "Saved batch 921 with 100 pairs.\n",
      "Saved batch 922 with 100 pairs.\n",
      "Saved batch 923 with 100 pairs.\n",
      "Saved batch 924 with 100 pairs.\n",
      "Saved batch 925 with 66 pairs.\n",
      "Saved batch 926 with 100 pairs.\n",
      "Saved batch 927 with 100 pairs.\n",
      "Saved batch 928 with 100 pairs.\n",
      "Saved batch 929 with 100 pairs.\n",
      "Saved batch 930 with 100 pairs.\n",
      "Saved batch 931 with 100 pairs.\n",
      "Saved batch 932 with 66 pairs.\n",
      "Saved batch 933 with 100 pairs.\n",
      "Saved batch 934 with 100 pairs.\n",
      "Saved batch 935 with 100 pairs.\n",
      "Saved batch 936 with 100 pairs.\n",
      "Saved batch 937 with 100 pairs.\n",
      "Saved batch 938 with 100 pairs.\n",
      "Saved batch 939 with 66 pairs.\n",
      "Saved batch 940 with 100 pairs.\n",
      "Saved batch 941 with 100 pairs.\n",
      "Saved batch 942 with 100 pairs.\n",
      "Saved batch 943 with 100 pairs.\n",
      "Saved batch 944 with 100 pairs.\n",
      "Saved batch 945 with 100 pairs.\n",
      "Saved batch 946 with 66 pairs.\n",
      "Saved batch 947 with 100 pairs.\n",
      "Saved batch 948 with 100 pairs.\n",
      "Saved batch 949 with 100 pairs.\n",
      "Saved batch 950 with 100 pairs.\n",
      "Saved batch 951 with 100 pairs.\n",
      "Saved batch 952 with 22 pairs.\n",
      "Saved batch 953 with 100 pairs.\n",
      "Saved batch 954 with 100 pairs.\n",
      "Saved batch 955 with 100 pairs.\n",
      "Saved batch 956 with 100 pairs.\n",
      "Saved batch 957 with 100 pairs.\n",
      "Saved batch 958 with 100 pairs.\n",
      "Saved batch 959 with 66 pairs.\n",
      "Saved batch 960 with 100 pairs.\n",
      "Saved batch 961 with 100 pairs.\n",
      "Saved batch 962 with 100 pairs.\n",
      "Saved batch 963 with 100 pairs.\n",
      "Saved batch 964 with 100 pairs.\n",
      "Saved batch 965 with 100 pairs.\n",
      "Saved batch 966 with 66 pairs.\n",
      "Saved batch 967 with 100 pairs.\n",
      "Saved batch 968 with 100 pairs.\n",
      "Saved batch 969 with 100 pairs.\n",
      "Saved batch 970 with 100 pairs.\n",
      "Saved batch 971 with 100 pairs.\n",
      "Saved batch 972 with 100 pairs.\n",
      "Saved batch 973 with 66 pairs.\n",
      "Saved batch 974 with 100 pairs.\n",
      "Saved batch 975 with 100 pairs.\n",
      "Saved batch 976 with 100 pairs.\n",
      "Saved batch 977 with 100 pairs.\n",
      "Saved batch 978 with 100 pairs.\n",
      "Saved batch 979 with 100 pairs.\n",
      "Saved batch 980 with 66 pairs.\n",
      "Saved batch 981 with 100 pairs.\n",
      "Saved batch 982 with 100 pairs.\n",
      "Saved batch 983 with 100 pairs.\n",
      "Saved batch 984 with 100 pairs.\n",
      "Saved batch 985 with 100 pairs.\n",
      "Saved batch 986 with 100 pairs.\n",
      "Saved batch 987 with 66 pairs.\n",
      "Saved batch 988 with 100 pairs.\n",
      "Saved batch 989 with 100 pairs.\n",
      "Saved batch 990 with 100 pairs.\n",
      "Saved batch 991 with 100 pairs.\n",
      "Saved batch 992 with 100 pairs.\n",
      "Saved batch 993 with 100 pairs.\n",
      "Saved batch 994 with 66 pairs.\n",
      "Saved batch 995 with 100 pairs.\n",
      "Saved batch 996 with 100 pairs.\n",
      "Saved batch 997 with 100 pairs.\n",
      "Saved batch 998 with 100 pairs.\n",
      "Saved batch 999 with 100 pairs.\n",
      "Reached max_batches limit: 1000\n",
      "Data sampling and batch saving completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Directory for Denoised Data\n",
    "# ---------------------------------------------------------------\n",
    "denoised_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data'\n",
    "output_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/contrastive_pairs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load All Denoised Data into GPU in Chunks\n",
    "# ---------------------------------------------------------------\n",
    "def load_data_in_chunks(denoised_dir, chunk_size=50000):\n",
    "    for filename in os.listdir(denoised_dir):\n",
    "        if filename.endswith('.fif'):\n",
    "            record_id = filename.split('.')[0]\n",
    "            file_path = os.path.join(denoised_dir, filename)\n",
    "            raw = mne.io.read_raw_fif(file_path, preload=True)\n",
    "            data = raw.get_data()\n",
    "\n",
    "            # Replace NaNs and Infs with finite values for each channel\n",
    "            for ch in range(data.shape[0]):\n",
    "                nan_mask = np.isnan(data[ch])\n",
    "                inf_mask = ~np.isfinite(data[ch])\n",
    "\n",
    "                if np.any(nan_mask):\n",
    "                    print(f\"NaNs found in {filename}, channel {ch}. Replacing with channel mean.\")\n",
    "                    data[ch, nan_mask] = np.nanmean(data[ch])\n",
    "\n",
    "                if np.any(inf_mask):\n",
    "                    print(f\"Infs found in {filename}, channel {ch}. Replacing with zeros.\")\n",
    "                    data[ch, inf_mask] = 0.0\n",
    "\n",
    "            # Check for any remaining NaNs or Infs\n",
    "            if not np.isfinite(data).all():\n",
    "                print(f\"NaNs or Infs still found in {filename} after replacement, skipping this file.\")\n",
    "                continue\n",
    "\n",
    "            # Split data into chunks to fit into GPU memory\n",
    "            for start in range(0, data.shape[1], chunk_size):\n",
    "                end = min(start + chunk_size, data.shape[1])\n",
    "                yield record_id, cp.asarray(data[:, start:end], dtype=cp.float16)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Create Contrastive Pairs in Batches\n",
    "# ---------------------------------------------------------------\n",
    "def create_contrastive_pairs(sample_length=500, step_size=450, batch_size=100, max_negatives=5, max_batches=1000):\n",
    "    record_data = list(load_data_in_chunks(denoised_dir))\n",
    "    batch_count = 0\n",
    "\n",
    "    for i, (record_a, data_a) in enumerate(record_data):\n",
    "        num_samples_a = (data_a.shape[1] - sample_length) // step_size + 1\n",
    "\n",
    "        for j, (record_b, data_b) in enumerate(record_data):\n",
    "            if i == j:\n",
    "                continue  # Skip the same subject for negative pairs\n",
    "\n",
    "            num_samples_b = (data_b.shape[1] - sample_length) // step_size + 1\n",
    "\n",
    "            pairs = []\n",
    "\n",
    "            # Create positive pairs\n",
    "            for n in range(min(num_samples_a, num_samples_b)):\n",
    "                start_a = n * step_size\n",
    "                start_b = n * step_size\n",
    "\n",
    "                # Extract EEG segments\n",
    "                segment_a = data_a[:, start_a:start_a + sample_length]\n",
    "                segment_b = data_b[:, start_b:start_b + sample_length]\n",
    "\n",
    "                # Check for NaNs or Infs in segments\n",
    "                if not cp.isfinite(segment_a).all() or not cp.isfinite(segment_b).all():\n",
    "                    print(f\"NaNs or Infs found in record {record_a} or {record_b}, skipping this pair.\")\n",
    "                    continue\n",
    "\n",
    "                # Positive pair: Same stimulus, different subjects\n",
    "                pairs.append((segment_a, segment_b))\n",
    "\n",
    "                # Select distinct negative pairs\n",
    "                negative_indices = select_distinct_negatives(segment_a, data_b, num_samples_b, step_size, sample_length, max_negatives)\n",
    "\n",
    "                for m in negative_indices:\n",
    "                    start_b_neg = m * step_size\n",
    "                    segment_b_neg = data_b[:, start_b_neg:start_b_neg + sample_length]\n",
    "\n",
    "                    # Check for NaNs or Infs in negative segments\n",
    "                    if not cp.isfinite(segment_b_neg).all():\n",
    "                        print(f\"NaNs or Infs found in negative segment from record {record_b}, skipping this pair.\")\n",
    "                        continue\n",
    "\n",
    "                    pairs.append((segment_a, segment_b_neg))\n",
    "\n",
    "                    # Save batch if batch size is reached\n",
    "                    if len(pairs) >= batch_size:\n",
    "                        save_batch(pairs, batch_count, output_dir)  # Pass output_dir here\n",
    "                        batch_count += 1\n",
    "                        pairs = []\n",
    "                        cp.get_default_memory_pool().free_all_blocks()  # Clear GPU memory\n",
    "\n",
    "                        if batch_count >= max_batches:\n",
    "                            print(f\"Reached max_batches limit: {max_batches}\")\n",
    "                            return\n",
    "\n",
    "            # Save remaining pairs in the current batch\n",
    "            if pairs and batch_count < max_batches:\n",
    "                save_batch(pairs, batch_count, output_dir)  # Pass output_dir here\n",
    "                batch_count += 1\n",
    "                cp.get_default_memory_pool().free_all_blocks()  # Clear GPU memory\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Select Distinct Negative Pairs\n",
    "# ---------------------------------------------------------------\n",
    "def select_distinct_negatives(segment_a, data_b, num_samples_b, step_size, sample_length, max_negatives):\n",
    "    distances = []\n",
    "    for m in range(num_samples_b):\n",
    "        start_b_neg = m * step_size\n",
    "        segment_b_neg = data_b[:, start_b_neg:start_b_neg + sample_length]\n",
    "\n",
    "        # Skip if segment contains NaNs or Infs\n",
    "        if not cp.isfinite(segment_b_neg).all():\n",
    "            continue\n",
    "\n",
    "        dist = euclidean(cp.asnumpy(segment_a.flatten()), cp.asnumpy(segment_b_neg.flatten()))\n",
    "        distances.append((dist, m))\n",
    "\n",
    "    # Sort by distance and select the most distinct negatives\n",
    "    distances.sort(reverse=True, key=lambda x: x[0])\n",
    "    distinct_indices = [m for _, m in distances[:max_negatives]]\n",
    "\n",
    "    return distinct_indices\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Save Batch to Disk with Gzip Compression\n",
    "# ---------------------------------------------------------------\n",
    "def save_batch(pairs, batch_count, output_dir):\n",
    "    # Convert each segment within the pairs to float16 and move to CPU\n",
    "    converted_pairs = []\n",
    "    for segment_a, segment_b in pairs:\n",
    "        segment_a_cpu = cp.asnumpy(segment_a.astype(cp.float16))\n",
    "        segment_b_cpu = cp.asnumpy(segment_b.astype(cp.float16))\n",
    "        converted_pairs.append((segment_a_cpu, segment_b_cpu))\n",
    "    \n",
    "    # Save with gzip compression\n",
    "    batch_path = os.path.join(output_dir, f'batch_{batch_count}_pairs.npy.gz')\n",
    "\n",
    "    with gzip.GzipFile(batch_path, 'w') as f:\n",
    "        np.save(f, converted_pairs, allow_pickle=True)\n",
    "\n",
    "    print(f\"Saved batch {batch_count} with {len(converted_pairs)} pairs.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Run the Data Sampling Process\n",
    "# ---------------------------------------------------------------\n",
    "print(\"Creating contrastive pairs in batches...\")\n",
    "create_contrastive_pairs()\n",
    "print(\"Data sampling and batch saving completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying batch: batch_0_pairs.npy.gz\n",
      "Number of pairs: 100\n",
      "Pair 0: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 1: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 2: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 3: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 4: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 5: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 6: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 7: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 8: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 9: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 10: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 11: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 12: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 13: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 14: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 15: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 16: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 17: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 18: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 19: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 20: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 21: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 22: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 23: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 24: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 25: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 26: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 27: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 28: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 29: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 30: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 31: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 32: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 33: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 34: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 35: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 36: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 37: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 38: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 39: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 40: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 41: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 42: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 43: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 44: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 45: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 46: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 47: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 48: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 49: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 50: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 51: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 52: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 53: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 54: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 55: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 56: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 57: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 58: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 59: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 60: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 61: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 62: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 63: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 64: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 65: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 66: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 67: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 68: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 69: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 70: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 71: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 72: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 73: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 74: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 75: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 76: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 77: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 78: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 79: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 80: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 81: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 82: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 83: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 84: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 85: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 86: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 87: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 88: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 89: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 90: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 91: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 92: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 93: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 94: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 95: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 96: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 97: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 98: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 99: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "âœ… Batch batch_0_pairs.npy.gz verification complete.\n",
      "\n",
      "Verifying batch: batch_1_pairs.npy.gz\n",
      "Number of pairs: 100\n",
      "Pair 0: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 1: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 2: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 3: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 4: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 5: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 6: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 7: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 8: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 9: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 10: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 11: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 12: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 13: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 14: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 15: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 16: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 17: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 18: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 19: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 20: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 21: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 22: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 23: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 24: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 25: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 26: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 27: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 28: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 29: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 30: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 31: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 32: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 33: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 34: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 35: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 36: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 37: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 38: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 39: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 40: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 41: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 42: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 43: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 44: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 45: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 46: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 47: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 48: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 49: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 50: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 51: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 52: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 53: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 54: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 55: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 56: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 57: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 58: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 59: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 60: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 61: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 62: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 63: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 64: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 65: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 66: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 67: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 68: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 69: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 70: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 71: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 72: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 73: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 74: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 75: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 76: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 77: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 78: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 79: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 80: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 81: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 82: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 83: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 84: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 85: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 86: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 87: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 88: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 89: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 90: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 91: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 92: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 93: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 94: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 95: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 96: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 97: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 98: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 99: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "âœ… Batch batch_1_pairs.npy.gz verification complete.\n",
      "\n",
      "Verifying batch: batch_2_pairs.npy.gz\n",
      "Number of pairs: 100\n",
      "Pair 0: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 1: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 2: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 3: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 4: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 5: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 6: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 7: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 8: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 9: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 10: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 11: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 12: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 13: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 14: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 15: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 16: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 17: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 18: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 19: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 20: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 21: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 22: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 23: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 24: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 25: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 26: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 27: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 28: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 29: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 30: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 31: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 32: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 33: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 34: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 35: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 36: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 37: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 38: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 39: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 40: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 41: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 42: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 43: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 44: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 45: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 46: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 47: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 48: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 49: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 50: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 51: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 52: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 53: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 54: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 55: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 56: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 57: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 58: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 59: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 60: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 61: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 62: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 63: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 64: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 65: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 66: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 67: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 68: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 69: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 70: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 71: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 72: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 73: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 74: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 75: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 76: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 77: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 78: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 79: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 80: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 81: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 82: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 83: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 84: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 85: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 86: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 87: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 88: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 89: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 90: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 91: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 92: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 93: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 94: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 95: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 96: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 97: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 98: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 99: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "âœ… Batch batch_2_pairs.npy.gz verification complete.\n",
      "\n",
      "Verifying batch: batch_3_pairs.npy.gz\n",
      "Number of pairs: 100\n",
      "Pair 0: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 1: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 2: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 3: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 4: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 5: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 6: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 7: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 8: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 9: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 10: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 11: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 12: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 13: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 14: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 15: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 16: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 17: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 18: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 19: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 20: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 21: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 22: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 23: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 24: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 25: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 26: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 27: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 28: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 29: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 30: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 31: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 32: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 33: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 34: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 35: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 36: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 37: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 38: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 39: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 40: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 41: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 42: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 43: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 44: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 45: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 46: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 47: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 48: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 49: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 50: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 51: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 52: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 53: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 54: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 55: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 56: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 57: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 58: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 59: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 60: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 61: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 62: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 63: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 64: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 65: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 66: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 67: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 68: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 69: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 70: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 71: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 72: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 73: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 74: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 75: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 76: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 77: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 78: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 79: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 80: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 81: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 82: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 83: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 84: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 85: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 86: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 87: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 88: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 89: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 90: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 91: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 92: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 93: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 94: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 95: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 96: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 97: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 98: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 99: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "âœ… Batch batch_3_pairs.npy.gz verification complete.\n",
      "\n",
      "Verifying batch: batch_4_pairs.npy.gz\n",
      "Number of pairs: 100\n",
      "Pair 0: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 1: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 2: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 3: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 4: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 5: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 6: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 7: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 8: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 9: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 10: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 11: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 12: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 13: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 14: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 15: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 16: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 17: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 18: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 19: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 20: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 21: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 22: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 23: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 24: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 25: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 26: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 27: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 28: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 29: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 30: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 31: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 32: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 33: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 34: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 35: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 36: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 37: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 38: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 39: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 40: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 41: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 42: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 43: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 44: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 45: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 46: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 47: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 48: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 49: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 50: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 51: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 52: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 53: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 54: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 55: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 56: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 57: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 58: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 59: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 60: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 61: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 62: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 63: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 64: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 65: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 66: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 67: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 68: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 69: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 70: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 71: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 72: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 73: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 74: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 75: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 76: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 77: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 78: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 79: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 80: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 81: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 82: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 83: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 84: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 85: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 86: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 87: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 88: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 89: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 90: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 91: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 92: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 93: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 94: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 95: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 96: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 97: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 98: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "Pair 99: Segment A Shape: (62, 500), Segment B Shape: (62, 500)\n",
      "âœ… Batch batch_4_pairs.npy.gz verification complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Verify the Saved Batches\n",
    "# ---------------------------------------------------------------\n",
    "def verify_saved_batches(output_dir):\n",
    "    batch_files = [f for f in os.listdir(output_dir) if f.endswith('_pairs.npy.gz')]\n",
    "\n",
    "    if not batch_files:\n",
    "        print(\"No batch files found in the output directory.\")\n",
    "        return\n",
    "\n",
    "    for batch_file in batch_files:\n",
    "        batch_path = os.path.join(output_dir, batch_file)\n",
    "\n",
    "        # Load the batch\n",
    "        with gzip.GzipFile(batch_path, 'rb') as f:\n",
    "            pairs = np.load(f, allow_pickle=True)\n",
    "\n",
    "        # Verify pairs\n",
    "        print(f\"\\nVerifying batch: {batch_file}\")\n",
    "        print(f\"Number of pairs: {len(pairs)}\")\n",
    "\n",
    "        # Check the shape of each pair\n",
    "        for idx, (segment_a, segment_b) in enumerate(pairs):\n",
    "            print(f\"Pair {idx}: Segment A Shape: {segment_a.shape}, Segment B Shape: {segment_b.shape}\")\n",
    "\n",
    "            # Check for NaNs or Infs in Segment A and Segment B\n",
    "            if not np.isfinite(segment_a).all():\n",
    "                print(f\"âŒ NaNs or Infs found in Segment A of pair {idx} in {batch_file}\")\n",
    "\n",
    "            if not np.isfinite(segment_b).all():\n",
    "                print(f\"âŒ NaNs or Infs found in Segment B of pair {idx} in {batch_file}\")\n",
    "\n",
    "        print(f\"âœ… Batch {batch_file} verification complete.\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Run the Verification\n",
    "# ---------------------------------------------------------------\n",
    "verify_saved_batches(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start_at  end_at            clip_id  subject_id trial_id  emotion      date\n",
      "0         0     200  10_20131130.mat_0          10  ww_eeg1        1  20131130\n",
      "1       200     400  10_20131130.mat_1          10  ww_eeg1        1  20131130\n",
      "2       400     600  10_20131130.mat_2          10  ww_eeg1        1  20131130\n",
      "3       600     800  10_20131130.mat_3          10  ww_eeg1        1  20131130\n",
      "4       800    1000  10_20131130.mat_4          10  ww_eeg1        1  20131130\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the original info.csv\n",
    "info_csv_path = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS/_record_0/info.csv'\n",
    "\n",
    "# Read the info.csv\n",
    "info_df = pd.read_csv(info_csv_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(info_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improved Contrastive Pair Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata...\n",
      "Keys in metadata_dict: ['_record_0', '_record_1', '_record_10', '_record_11', '_record_12', '_record_13', '_record_14', '_record_15', '_record_16', '_record_17', '_record_18', '_record_19', '_record_2', '_record_20', '_record_21', '_record_22', '_record_23', '_record_24', '_record_25', '_record_26', '_record_27', '_record_28', '_record_29', '_record_3', '_record_30', '_record_31', '_record_32', '_record_33', '_record_34', '_record_35', '_record_36', '_record_37', '_record_38', '_record_39', '_record_4', '_record_40', '_record_41', '_record_42', '_record_43', '_record_44', '_record_5', '_record_6', '_record_7', '_record_8', '_record_9']\n",
      "Loading denoised data...\n",
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_0.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_0.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_1.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_10.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_10.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_11.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_11.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_12.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_12.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_13.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_13.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_14.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_14.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_15.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_15.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_16.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_16.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_17.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_17.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_18.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_18.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_19.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_19.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_2.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_2.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_20.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_20.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_21.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_21.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_22.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_22.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_23.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_23.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_24.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_24.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_25.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_25.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_26.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_26.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_27.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_27.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_28.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_28.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_29.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_29.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_3.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_3.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_30.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_30.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_31.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_31.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_32.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_32.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_33.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_33.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_34.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_34.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_35.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_35.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_36.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_36.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_37.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_37.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_38.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_38.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_39.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_39.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_4.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_4.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_40.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_40.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_41.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_41.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_42.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_42.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_43.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_43.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_44.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_44.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_5.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_5.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_6.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_6.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_7.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_7.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_8.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_8.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_9.fif...\n",
      "    Range : 0 ... 339399 =      0.000 ...  3393.990 secs\n",
      "Ready.\n",
      "Reading 0 ... 339399  =      0.000 ...  3393.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahir\\AppData\\Local\\Temp\\ipykernel_9864\\1042393393.py:41: RuntimeWarning: This filename (C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data\\denoised_cleaned__record_9.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in data_dict: ['denoised_cleaned__record_0', 'denoised_cleaned__record_1', 'denoised_cleaned__record_10', 'denoised_cleaned__record_11', 'denoised_cleaned__record_12', 'denoised_cleaned__record_13', 'denoised_cleaned__record_14', 'denoised_cleaned__record_15', 'denoised_cleaned__record_16', 'denoised_cleaned__record_17', 'denoised_cleaned__record_18', 'denoised_cleaned__record_19', 'denoised_cleaned__record_2', 'denoised_cleaned__record_20', 'denoised_cleaned__record_21', 'denoised_cleaned__record_22', 'denoised_cleaned__record_23', 'denoised_cleaned__record_24', 'denoised_cleaned__record_25', 'denoised_cleaned__record_26', 'denoised_cleaned__record_27', 'denoised_cleaned__record_28', 'denoised_cleaned__record_29', 'denoised_cleaned__record_3', 'denoised_cleaned__record_30', 'denoised_cleaned__record_31', 'denoised_cleaned__record_32', 'denoised_cleaned__record_33', 'denoised_cleaned__record_34', 'denoised_cleaned__record_35', 'denoised_cleaned__record_36', 'denoised_cleaned__record_37', 'denoised_cleaned__record_38', 'denoised_cleaned__record_39', 'denoised_cleaned__record_4', 'denoised_cleaned__record_40', 'denoised_cleaned__record_41', 'denoised_cleaned__record_42', 'denoised_cleaned__record_43', 'denoised_cleaned__record_44', 'denoised_cleaned__record_5', 'denoised_cleaned__record_6', 'denoised_cleaned__record_7', 'denoised_cleaned__record_8', 'denoised_cleaned__record_9']\n",
      "Creating contrastive pairs in batches...\n",
      "Processing denoised_cleaned__record_0 with 3394 metadata entries...\n",
      "Saved batch 0 with 200 pairs.\n",
      "Saved batch 1 with 200 pairs.\n",
      "Saved batch 2 with 200 pairs.\n",
      "Saved batch 3 with 200 pairs.\n",
      "Saved batch 4 with 200 pairs.\n",
      "Saved batch 5 with 200 pairs.\n",
      "Saved batch 6 with 200 pairs.\n",
      "Saved batch 7 with 200 pairs.\n",
      "Saved batch 8 with 200 pairs.\n",
      "Saved batch 9 with 200 pairs.\n",
      "Saved batch 10 with 200 pairs.\n",
      "Saved batch 11 with 200 pairs.\n",
      "Saved batch 12 with 200 pairs.\n",
      "Saved batch 13 with 200 pairs.\n",
      "Saved batch 14 with 200 pairs.\n",
      "Saved batch 15 with 200 pairs.\n",
      "Saved batch 16 with 200 pairs.\n",
      "Saved batch 17 with 200 pairs.\n",
      "Saved batch 18 with 200 pairs.\n",
      "Saved batch 19 with 200 pairs.\n",
      "Saved batch 20 with 200 pairs.\n",
      "Saved batch 21 with 200 pairs.\n",
      "Saved batch 22 with 200 pairs.\n",
      "Saved batch 23 with 200 pairs.\n",
      "Saved batch 24 with 200 pairs.\n",
      "Saved batch 25 with 200 pairs.\n",
      "Saved batch 26 with 200 pairs.\n",
      "Saved batch 27 with 200 pairs.\n",
      "Saved batch 28 with 200 pairs.\n",
      "Saved batch 29 with 200 pairs.\n",
      "Saved batch 30 with 200 pairs.\n",
      "Saved batch 31 with 200 pairs.\n",
      "Saved batch 32 with 200 pairs.\n",
      "Saved batch 33 with 200 pairs.\n",
      "Saved batch 34 with 200 pairs.\n",
      "Saved batch 35 with 200 pairs.\n",
      "Saved batch 36 with 200 pairs.\n",
      "Saved batch 37 with 200 pairs.\n",
      "Saved batch 38 with 200 pairs.\n",
      "Saved batch 39 with 200 pairs.\n",
      "Saved batch 40 with 200 pairs.\n",
      "Saved batch 41 with 200 pairs.\n",
      "Saved batch 42 with 200 pairs.\n",
      "Saved batch 43 with 200 pairs.\n",
      "Saved batch 44 with 200 pairs.\n",
      "Saved batch 45 with 200 pairs.\n",
      "Saved batch 46 with 200 pairs.\n",
      "Saved batch 47 with 200 pairs.\n",
      "Saved batch 48 with 200 pairs.\n",
      "Saved batch 49 with 200 pairs.\n",
      "Saved batch 50 with 200 pairs.\n",
      "Saved batch 51 with 200 pairs.\n",
      "Saved batch 52 with 200 pairs.\n",
      "Saved batch 53 with 200 pairs.\n",
      "Saved batch 54 with 200 pairs.\n",
      "Saved batch 55 with 200 pairs.\n",
      "Saved batch 56 with 200 pairs.\n",
      "Saved batch 57 with 200 pairs.\n",
      "Saved batch 58 with 200 pairs.\n",
      "Saved batch 59 with 200 pairs.\n",
      "Saved batch 60 with 200 pairs.\n",
      "Saved batch 61 with 200 pairs.\n",
      "Saved batch 62 with 200 pairs.\n",
      "Saved batch 63 with 200 pairs.\n",
      "Saved batch 64 with 200 pairs.\n",
      "Saved batch 65 with 200 pairs.\n",
      "Saved batch 66 with 200 pairs.\n",
      "Saved batch 67 with 200 pairs.\n",
      "Saved batch 68 with 200 pairs.\n",
      "Saved batch 69 with 200 pairs.\n",
      "Saved batch 70 with 200 pairs.\n",
      "Saved batch 71 with 200 pairs.\n",
      "Saved batch 72 with 200 pairs.\n",
      "Saved batch 73 with 200 pairs.\n",
      "Saved batch 74 with 200 pairs.\n",
      "Saved batch 75 with 200 pairs.\n",
      "Saved batch 76 with 200 pairs.\n",
      "Saved batch 77 with 200 pairs.\n",
      "Saved batch 78 with 200 pairs.\n",
      "Saved batch 79 with 200 pairs.\n",
      "Saved batch 80 with 200 pairs.\n",
      "Saved batch 81 with 200 pairs.\n",
      "Saved batch 82 with 200 pairs.\n",
      "Saved batch 83 with 200 pairs.\n",
      "Saved batch 84 with 200 pairs.\n",
      "Saved batch 85 with 200 pairs.\n",
      "Saved batch 86 with 200 pairs.\n",
      "Saved batch 87 with 200 pairs.\n",
      "Saved batch 88 with 200 pairs.\n",
      "Saved batch 89 with 200 pairs.\n",
      "Saved batch 90 with 200 pairs.\n",
      "Saved batch 91 with 200 pairs.\n",
      "Saved batch 92 with 200 pairs.\n",
      "Saved batch 93 with 200 pairs.\n",
      "Saved batch 94 with 200 pairs.\n",
      "Saved batch 95 with 200 pairs.\n",
      "Saved batch 96 with 200 pairs.\n",
      "Saved batch 97 with 200 pairs.\n",
      "Saved batch 98 with 200 pairs.\n",
      "Saved batch 99 with 200 pairs.\n",
      "Saved batch 100 with 200 pairs.\n",
      "Saved batch 101 with 200 pairs.\n",
      "Saved batch 102 with 200 pairs.\n",
      "Saved batch 103 with 200 pairs.\n",
      "Saved batch 104 with 200 pairs.\n",
      "Saved batch 105 with 200 pairs.\n",
      "Saved batch 106 with 200 pairs.\n",
      "Saved batch 107 with 200 pairs.\n",
      "Saved batch 108 with 200 pairs.\n",
      "Saved batch 109 with 200 pairs.\n",
      "Saved batch 110 with 200 pairs.\n",
      "Saved batch 111 with 200 pairs.\n",
      "Saved batch 112 with 200 pairs.\n",
      "Saved batch 113 with 200 pairs.\n",
      "Saved batch 114 with 200 pairs.\n",
      "Saved batch 115 with 200 pairs.\n",
      "Saved batch 116 with 200 pairs.\n",
      "Saved batch 117 with 200 pairs.\n",
      "Saved batch 118 with 200 pairs.\n",
      "Saved batch 119 with 200 pairs.\n",
      "Saved batch 120 with 200 pairs.\n",
      "Saved batch 121 with 200 pairs.\n",
      "Saved batch 122 with 200 pairs.\n",
      "Saved batch 123 with 200 pairs.\n",
      "Saved batch 124 with 200 pairs.\n",
      "Saved batch 125 with 200 pairs.\n",
      "Saved batch 126 with 200 pairs.\n",
      "Saved batch 127 with 200 pairs.\n",
      "Saved batch 128 with 200 pairs.\n",
      "Saved batch 129 with 200 pairs.\n",
      "Saved batch 130 with 200 pairs.\n",
      "Saved batch 131 with 200 pairs.\n",
      "Saved batch 132 with 200 pairs.\n",
      "Saved batch 133 with 200 pairs.\n",
      "Saved batch 134 with 200 pairs.\n",
      "Saved batch 135 with 200 pairs.\n",
      "Saved batch 136 with 200 pairs.\n",
      "Saved batch 137 with 200 pairs.\n",
      "Saved batch 138 with 200 pairs.\n",
      "Saved batch 139 with 200 pairs.\n",
      "Saved batch 140 with 200 pairs.\n",
      "Saved batch 141 with 200 pairs.\n",
      "Saved batch 142 with 200 pairs.\n",
      "Saved batch 143 with 200 pairs.\n",
      "Saved batch 144 with 200 pairs.\n",
      "Saved batch 145 with 200 pairs.\n",
      "Saved batch 146 with 200 pairs.\n",
      "Saved batch 147 with 200 pairs.\n",
      "Saved batch 148 with 200 pairs.\n",
      "Saved batch 149 with 200 pairs.\n",
      "Saved batch 150 with 200 pairs.\n",
      "Saved batch 151 with 200 pairs.\n",
      "Saved batch 152 with 200 pairs.\n",
      "Saved batch 153 with 200 pairs.\n",
      "Saved batch 154 with 200 pairs.\n",
      "Saved batch 155 with 200 pairs.\n",
      "Saved batch 156 with 200 pairs.\n",
      "Saved batch 157 with 200 pairs.\n",
      "Saved batch 158 with 200 pairs.\n",
      "Saved batch 159 with 200 pairs.\n",
      "Saved batch 160 with 200 pairs.\n",
      "Saved batch 161 with 200 pairs.\n",
      "Saved batch 162 with 200 pairs.\n",
      "Saved batch 163 with 200 pairs.\n",
      "Saved batch 164 with 200 pairs.\n",
      "Saved batch 165 with 200 pairs.\n",
      "Saved batch 166 with 200 pairs.\n",
      "Saved batch 167 with 200 pairs.\n",
      "Saved batch 168 with 200 pairs.\n",
      "Saved batch 169 with 200 pairs.\n",
      "Saved batch 170 with 200 pairs.\n",
      "Saved batch 171 with 200 pairs.\n",
      "Saved batch 172 with 200 pairs.\n",
      "Saved batch 173 with 200 pairs.\n",
      "Saved batch 174 with 200 pairs.\n",
      "Saved batch 175 with 200 pairs.\n",
      "Saved batch 176 with 200 pairs.\n",
      "Saved batch 177 with 200 pairs.\n",
      "Saved batch 178 with 200 pairs.\n",
      "Saved batch 179 with 200 pairs.\n",
      "Saved batch 180 with 200 pairs.\n",
      "Saved batch 181 with 200 pairs.\n",
      "Saved batch 182 with 200 pairs.\n",
      "Saved batch 183 with 200 pairs.\n",
      "Saved batch 184 with 200 pairs.\n",
      "Saved batch 185 with 200 pairs.\n",
      "Saved batch 186 with 200 pairs.\n",
      "Saved batch 187 with 200 pairs.\n",
      "Saved batch 188 with 200 pairs.\n",
      "Saved batch 189 with 200 pairs.\n",
      "Saved batch 190 with 200 pairs.\n",
      "Saved batch 191 with 200 pairs.\n",
      "Saved batch 192 with 200 pairs.\n",
      "Saved batch 193 with 200 pairs.\n",
      "Saved batch 194 with 200 pairs.\n",
      "Saved batch 195 with 200 pairs.\n",
      "Saved batch 196 with 200 pairs.\n",
      "Saved batch 197 with 200 pairs.\n",
      "Saved batch 198 with 200 pairs.\n",
      "Saved batch 199 with 200 pairs.\n",
      "Saved batch 200 with 200 pairs.\n",
      "Saved batch 201 with 200 pairs.\n",
      "Saved batch 202 with 200 pairs.\n",
      "Saved batch 203 with 200 pairs.\n",
      "Saved batch 204 with 200 pairs.\n",
      "Saved batch 205 with 200 pairs.\n",
      "Saved batch 206 with 200 pairs.\n",
      "Saved batch 207 with 200 pairs.\n",
      "Saved batch 208 with 200 pairs.\n",
      "Saved batch 209 with 200 pairs.\n",
      "Saved batch 210 with 200 pairs.\n",
      "Saved batch 211 with 200 pairs.\n",
      "Saved batch 212 with 200 pairs.\n",
      "Saved batch 213 with 200 pairs.\n",
      "Saved batch 214 with 200 pairs.\n",
      "Saved batch 215 with 200 pairs.\n",
      "Saved batch 216 with 200 pairs.\n",
      "Saved batch 217 with 200 pairs.\n",
      "Saved batch 218 with 200 pairs.\n",
      "Saved batch 219 with 200 pairs.\n",
      "Saved batch 220 with 200 pairs.\n",
      "Saved batch 221 with 200 pairs.\n",
      "Saved batch 222 with 200 pairs.\n",
      "Saved batch 223 with 200 pairs.\n",
      "Saved batch 224 with 200 pairs.\n",
      "Saved batch 225 with 200 pairs.\n",
      "Saved batch 226 with 200 pairs.\n",
      "Saved batch 227 with 200 pairs.\n",
      "Saved batch 228 with 200 pairs.\n",
      "Saved batch 229 with 200 pairs.\n",
      "Saved batch 230 with 200 pairs.\n",
      "Saved batch 231 with 200 pairs.\n",
      "Saved batch 232 with 200 pairs.\n",
      "Saved batch 233 with 200 pairs.\n",
      "Saved batch 234 with 200 pairs.\n",
      "Saved batch 235 with 200 pairs.\n",
      "Saved batch 236 with 200 pairs.\n",
      "Saved batch 237 with 200 pairs.\n",
      "Saved batch 238 with 200 pairs.\n",
      "Saved batch 239 with 200 pairs.\n",
      "Saved batch 240 with 200 pairs.\n",
      "Saved batch 241 with 200 pairs.\n",
      "Saved batch 242 with 200 pairs.\n",
      "Saved batch 243 with 200 pairs.\n",
      "Saved batch 244 with 200 pairs.\n",
      "Saved batch 245 with 200 pairs.\n",
      "Saved batch 246 with 200 pairs.\n",
      "Saved batch 247 with 200 pairs.\n",
      "Saved batch 248 with 200 pairs.\n",
      "Saved batch 249 with 200 pairs.\n",
      "Saved batch 250 with 200 pairs.\n",
      "Saved batch 251 with 200 pairs.\n",
      "Saved batch 252 with 200 pairs.\n",
      "Saved batch 253 with 200 pairs.\n",
      "Saved batch 254 with 200 pairs.\n",
      "Saved batch 255 with 200 pairs.\n",
      "Saved batch 256 with 200 pairs.\n",
      "Saved batch 257 with 200 pairs.\n",
      "Saved batch 258 with 200 pairs.\n",
      "Saved batch 259 with 200 pairs.\n",
      "Saved batch 260 with 200 pairs.\n",
      "Saved batch 261 with 200 pairs.\n",
      "Saved batch 262 with 200 pairs.\n",
      "Saved batch 263 with 200 pairs.\n",
      "Saved batch 264 with 200 pairs.\n",
      "Saved batch 265 with 200 pairs.\n",
      "Saved batch 266 with 200 pairs.\n",
      "Saved batch 267 with 200 pairs.\n",
      "Saved batch 268 with 200 pairs.\n",
      "Saved batch 269 with 200 pairs.\n",
      "Saved batch 270 with 200 pairs.\n",
      "Saved batch 271 with 200 pairs.\n",
      "Saved batch 272 with 200 pairs.\n",
      "Saved batch 273 with 200 pairs.\n",
      "Saved batch 274 with 200 pairs.\n",
      "Saved batch 275 with 200 pairs.\n",
      "Saved batch 276 with 200 pairs.\n",
      "Saved batch 277 with 200 pairs.\n",
      "Saved batch 278 with 200 pairs.\n",
      "Saved batch 279 with 200 pairs.\n",
      "Saved batch 280 with 200 pairs.\n",
      "Saved batch 281 with 200 pairs.\n",
      "Saved batch 282 with 200 pairs.\n",
      "Saved batch 283 with 200 pairs.\n",
      "Saved batch 284 with 200 pairs.\n",
      "Saved batch 285 with 200 pairs.\n",
      "Saved batch 286 with 200 pairs.\n",
      "Saved batch 287 with 200 pairs.\n",
      "Saved batch 288 with 200 pairs.\n",
      "Saved batch 289 with 200 pairs.\n",
      "Saved batch 290 with 200 pairs.\n",
      "Saved batch 291 with 200 pairs.\n",
      "Saved batch 292 with 200 pairs.\n",
      "Saved batch 293 with 200 pairs.\n",
      "Saved batch 294 with 200 pairs.\n",
      "Saved batch 295 with 200 pairs.\n",
      "Saved batch 296 with 200 pairs.\n",
      "Saved batch 297 with 200 pairs.\n",
      "Saved batch 298 with 200 pairs.\n",
      "Saved batch 299 with 200 pairs.\n",
      "Saved batch 300 with 200 pairs.\n",
      "Saved batch 301 with 200 pairs.\n",
      "Saved batch 302 with 200 pairs.\n",
      "Saved batch 303 with 200 pairs.\n",
      "Saved batch 304 with 200 pairs.\n",
      "Saved batch 305 with 200 pairs.\n",
      "Saved batch 306 with 200 pairs.\n",
      "Saved batch 307 with 200 pairs.\n",
      "Saved batch 308 with 200 pairs.\n",
      "Saved batch 309 with 200 pairs.\n",
      "Saved batch 310 with 200 pairs.\n",
      "Saved batch 311 with 200 pairs.\n",
      "Saved batch 312 with 200 pairs.\n",
      "Saved batch 313 with 200 pairs.\n",
      "Saved batch 314 with 200 pairs.\n",
      "Saved batch 315 with 200 pairs.\n",
      "Saved batch 316 with 200 pairs.\n",
      "Saved batch 317 with 200 pairs.\n",
      "Saved batch 318 with 200 pairs.\n",
      "Saved batch 319 with 200 pairs.\n",
      "Saved batch 320 with 200 pairs.\n",
      "Saved batch 321 with 200 pairs.\n",
      "Saved batch 322 with 200 pairs.\n",
      "Saved batch 323 with 200 pairs.\n",
      "Saved batch 324 with 200 pairs.\n",
      "Saved batch 325 with 200 pairs.\n",
      "Saved batch 326 with 200 pairs.\n",
      "Saved batch 327 with 200 pairs.\n",
      "Saved batch 328 with 200 pairs.\n",
      "Saved batch 329 with 200 pairs.\n",
      "Saved batch 330 with 200 pairs.\n",
      "Saved batch 331 with 200 pairs.\n",
      "Saved batch 332 with 200 pairs.\n",
      "Saved batch 333 with 200 pairs.\n",
      "Saved batch 334 with 200 pairs.\n",
      "Saved batch 335 with 200 pairs.\n",
      "Saved batch 336 with 200 pairs.\n",
      "Saved batch 337 with 200 pairs.\n",
      "Saved batch 338 with 200 pairs.\n",
      "Saved batch 339 with 200 pairs.\n",
      "Saved batch 340 with 200 pairs.\n",
      "Saved batch 341 with 200 pairs.\n",
      "Saved batch 342 with 200 pairs.\n",
      "Saved batch 343 with 200 pairs.\n",
      "Saved batch 344 with 200 pairs.\n",
      "Saved batch 345 with 200 pairs.\n",
      "Saved batch 346 with 200 pairs.\n",
      "Saved batch 347 with 200 pairs.\n",
      "Saved batch 348 with 200 pairs.\n",
      "Saved batch 349 with 200 pairs.\n",
      "Saved batch 350 with 200 pairs.\n",
      "Saved batch 351 with 200 pairs.\n",
      "Saved batch 352 with 200 pairs.\n",
      "Saved batch 353 with 200 pairs.\n",
      "Saved batch 354 with 200 pairs.\n",
      "Saved batch 355 with 200 pairs.\n",
      "Saved batch 356 with 200 pairs.\n",
      "Saved batch 357 with 200 pairs.\n",
      "Saved batch 358 with 200 pairs.\n",
      "Saved batch 359 with 200 pairs.\n",
      "Saved batch 360 with 200 pairs.\n",
      "Saved batch 361 with 200 pairs.\n",
      "Saved batch 362 with 200 pairs.\n",
      "Saved batch 363 with 200 pairs.\n",
      "Saved batch 364 with 200 pairs.\n",
      "Saved batch 365 with 200 pairs.\n",
      "Saved batch 366 with 200 pairs.\n",
      "Saved batch 367 with 200 pairs.\n",
      "Saved batch 368 with 200 pairs.\n",
      "Saved batch 369 with 200 pairs.\n",
      "Saved batch 370 with 200 pairs.\n",
      "Saved batch 371 with 200 pairs.\n",
      "Saved batch 372 with 200 pairs.\n",
      "Saved batch 373 with 200 pairs.\n",
      "Saved batch 374 with 200 pairs.\n",
      "Saved batch 375 with 200 pairs.\n",
      "Saved batch 376 with 200 pairs.\n",
      "Saved batch 377 with 200 pairs.\n",
      "Saved batch 378 with 200 pairs.\n",
      "Saved batch 379 with 200 pairs.\n",
      "Saved batch 380 with 200 pairs.\n",
      "Saved batch 381 with 200 pairs.\n",
      "Saved batch 382 with 200 pairs.\n",
      "Saved batch 383 with 200 pairs.\n",
      "Saved batch 384 with 200 pairs.\n",
      "Saved batch 385 with 200 pairs.\n",
      "Saved batch 386 with 200 pairs.\n",
      "Saved batch 387 with 200 pairs.\n",
      "Saved batch 388 with 200 pairs.\n",
      "Saved batch 389 with 200 pairs.\n",
      "Saved batch 390 with 200 pairs.\n",
      "Saved batch 391 with 200 pairs.\n",
      "Saved batch 392 with 200 pairs.\n",
      "Saved batch 393 with 200 pairs.\n",
      "Saved batch 394 with 200 pairs.\n",
      "Saved batch 395 with 200 pairs.\n",
      "Saved batch 396 with 200 pairs.\n",
      "Saved batch 397 with 200 pairs.\n",
      "Saved batch 398 with 200 pairs.\n",
      "Saved batch 399 with 200 pairs.\n",
      "Saved batch 400 with 200 pairs.\n",
      "Saved batch 401 with 200 pairs.\n",
      "Saved batch 402 with 200 pairs.\n",
      "Saved batch 403 with 200 pairs.\n",
      "Saved batch 404 with 200 pairs.\n",
      "Saved batch 405 with 200 pairs.\n",
      "Saved batch 406 with 200 pairs.\n",
      "Saved batch 407 with 200 pairs.\n",
      "Saved batch 408 with 200 pairs.\n",
      "Saved batch 409 with 200 pairs.\n",
      "Saved batch 410 with 200 pairs.\n",
      "Saved batch 411 with 200 pairs.\n",
      "Saved batch 412 with 200 pairs.\n",
      "Saved batch 413 with 200 pairs.\n",
      "Saved batch 414 with 200 pairs.\n",
      "Saved batch 415 with 200 pairs.\n",
      "Saved batch 416 with 200 pairs.\n",
      "Saved batch 417 with 200 pairs.\n",
      "Saved batch 418 with 200 pairs.\n",
      "Saved batch 419 with 200 pairs.\n",
      "Saved batch 420 with 200 pairs.\n",
      "Saved batch 421 with 200 pairs.\n",
      "Saved batch 422 with 200 pairs.\n",
      "Saved batch 423 with 200 pairs.\n",
      "Saved batch 424 with 200 pairs.\n",
      "Saved batch 425 with 200 pairs.\n",
      "Saved batch 426 with 200 pairs.\n",
      "Saved batch 427 with 200 pairs.\n",
      "Saved batch 428 with 200 pairs.\n",
      "Saved batch 429 with 200 pairs.\n",
      "Saved batch 430 with 200 pairs.\n",
      "Saved batch 431 with 200 pairs.\n",
      "Saved batch 432 with 200 pairs.\n",
      "Saved batch 433 with 200 pairs.\n",
      "Saved batch 434 with 200 pairs.\n",
      "Saved batch 435 with 200 pairs.\n",
      "Saved batch 436 with 200 pairs.\n",
      "Saved batch 437 with 200 pairs.\n",
      "Saved batch 438 with 200 pairs.\n",
      "Saved batch 439 with 200 pairs.\n",
      "Saved batch 440 with 200 pairs.\n",
      "Saved batch 441 with 200 pairs.\n",
      "Saved batch 442 with 200 pairs.\n",
      "Saved batch 443 with 200 pairs.\n",
      "Saved batch 444 with 200 pairs.\n",
      "Saved batch 445 with 200 pairs.\n",
      "Saved batch 446 with 200 pairs.\n",
      "Saved batch 447 with 200 pairs.\n",
      "Saved batch 448 with 200 pairs.\n",
      "Saved batch 449 with 200 pairs.\n",
      "Saved batch 450 with 200 pairs.\n",
      "Saved batch 451 with 200 pairs.\n",
      "Saved batch 452 with 200 pairs.\n",
      "Saved batch 453 with 200 pairs.\n",
      "Saved batch 454 with 200 pairs.\n",
      "Saved batch 455 with 200 pairs.\n",
      "Saved batch 456 with 200 pairs.\n",
      "Saved batch 457 with 200 pairs.\n",
      "Saved batch 458 with 200 pairs.\n",
      "Saved batch 459 with 200 pairs.\n",
      "Saved batch 460 with 200 pairs.\n",
      "Saved batch 461 with 200 pairs.\n",
      "Saved batch 462 with 200 pairs.\n",
      "Saved batch 463 with 200 pairs.\n",
      "Saved batch 464 with 200 pairs.\n",
      "Saved batch 465 with 200 pairs.\n",
      "Saved batch 466 with 200 pairs.\n",
      "Saved batch 467 with 200 pairs.\n",
      "Saved batch 468 with 200 pairs.\n",
      "Saved batch 469 with 200 pairs.\n",
      "Saved batch 470 with 200 pairs.\n",
      "Saved batch 471 with 200 pairs.\n",
      "Saved batch 472 with 200 pairs.\n",
      "Saved batch 473 with 200 pairs.\n",
      "Saved batch 474 with 200 pairs.\n",
      "Saved batch 475 with 200 pairs.\n",
      "Saved batch 476 with 200 pairs.\n",
      "Saved batch 477 with 200 pairs.\n",
      "Saved batch 478 with 200 pairs.\n",
      "Saved batch 479 with 200 pairs.\n",
      "Saved batch 480 with 200 pairs.\n",
      "Saved batch 481 with 200 pairs.\n",
      "Saved batch 482 with 200 pairs.\n",
      "Saved batch 483 with 200 pairs.\n",
      "Saved batch 484 with 200 pairs.\n",
      "Saved batch 485 with 200 pairs.\n",
      "Saved batch 486 with 200 pairs.\n",
      "Saved batch 487 with 200 pairs.\n",
      "Saved batch 488 with 200 pairs.\n",
      "Saved batch 489 with 200 pairs.\n",
      "Saved batch 490 with 200 pairs.\n",
      "Saved batch 491 with 200 pairs.\n",
      "Saved batch 492 with 200 pairs.\n",
      "Saved batch 493 with 200 pairs.\n",
      "Saved batch 494 with 200 pairs.\n",
      "Saved batch 495 with 200 pairs.\n",
      "Saved batch 496 with 200 pairs.\n",
      "Saved batch 497 with 200 pairs.\n",
      "Saved batch 498 with 200 pairs.\n",
      "Saved batch 499 with 200 pairs.\n",
      "Saved batch 500 with 200 pairs.\n",
      "Saved batch 501 with 200 pairs.\n",
      "Saved batch 502 with 200 pairs.\n",
      "Saved batch 503 with 200 pairs.\n",
      "Saved batch 504 with 200 pairs.\n",
      "Saved batch 505 with 200 pairs.\n",
      "Saved batch 506 with 200 pairs.\n",
      "Saved batch 507 with 200 pairs.\n",
      "Saved batch 508 with 200 pairs.\n",
      "Saved batch 509 with 200 pairs.\n",
      "Saved batch 510 with 200 pairs.\n",
      "Saved batch 511 with 200 pairs.\n",
      "Saved batch 512 with 200 pairs.\n",
      "Saved batch 513 with 200 pairs.\n",
      "Saved batch 514 with 200 pairs.\n",
      "Saved batch 515 with 200 pairs.\n",
      "Saved batch 516 with 200 pairs.\n",
      "Saved batch 517 with 200 pairs.\n",
      "Saved batch 518 with 200 pairs.\n",
      "Saved batch 519 with 200 pairs.\n",
      "Saved batch 520 with 200 pairs.\n",
      "Saved batch 521 with 200 pairs.\n",
      "Saved batch 522 with 200 pairs.\n",
      "Saved batch 523 with 200 pairs.\n",
      "Saved batch 524 with 200 pairs.\n",
      "Saved batch 525 with 200 pairs.\n",
      "Saved batch 526 with 200 pairs.\n",
      "Saved batch 527 with 200 pairs.\n",
      "Saved batch 528 with 200 pairs.\n",
      "Saved batch 529 with 200 pairs.\n",
      "Saved batch 530 with 200 pairs.\n",
      "Saved batch 531 with 200 pairs.\n",
      "Saved batch 532 with 200 pairs.\n",
      "Saved batch 533 with 200 pairs.\n",
      "Saved batch 534 with 200 pairs.\n",
      "Saved batch 535 with 200 pairs.\n",
      "Saved batch 536 with 200 pairs.\n",
      "Saved batch 537 with 200 pairs.\n",
      "Saved batch 538 with 200 pairs.\n",
      "Saved batch 539 with 200 pairs.\n",
      "Saved batch 540 with 200 pairs.\n",
      "Saved batch 541 with 200 pairs.\n",
      "Saved batch 542 with 200 pairs.\n",
      "Saved batch 543 with 200 pairs.\n",
      "Saved batch 544 with 200 pairs.\n",
      "Saved batch 545 with 200 pairs.\n",
      "Saved batch 546 with 200 pairs.\n",
      "Saved batch 547 with 200 pairs.\n",
      "Saved batch 548 with 200 pairs.\n",
      "Saved batch 549 with 200 pairs.\n",
      "Saved batch 550 with 200 pairs.\n",
      "Saved batch 551 with 200 pairs.\n",
      "Saved batch 552 with 200 pairs.\n",
      "Saved batch 553 with 200 pairs.\n",
      "Saved batch 554 with 200 pairs.\n",
      "Saved batch 555 with 200 pairs.\n",
      "Saved batch 556 with 200 pairs.\n",
      "Saved batch 557 with 200 pairs.\n",
      "Saved batch 558 with 200 pairs.\n",
      "Saved batch 559 with 200 pairs.\n",
      "Saved batch 560 with 200 pairs.\n",
      "Saved batch 561 with 200 pairs.\n",
      "Saved batch 562 with 200 pairs.\n",
      "Saved batch 563 with 200 pairs.\n",
      "Saved batch 564 with 200 pairs.\n",
      "Saved batch 565 with 200 pairs.\n",
      "Saved batch 566 with 200 pairs.\n",
      "Saved batch 567 with 200 pairs.\n",
      "Saved batch 568 with 200 pairs.\n",
      "Saved batch 569 with 200 pairs.\n",
      "Saved batch 570 with 200 pairs.\n",
      "Saved batch 571 with 200 pairs.\n",
      "Saved batch 572 with 200 pairs.\n",
      "Saved batch 573 with 200 pairs.\n",
      "Saved batch 574 with 200 pairs.\n",
      "Saved batch 575 with 200 pairs.\n",
      "Saved batch 576 with 200 pairs.\n",
      "Saved batch 577 with 200 pairs.\n",
      "Saved batch 578 with 200 pairs.\n",
      "Saved batch 579 with 200 pairs.\n",
      "Saved batch 580 with 200 pairs.\n",
      "Saved batch 581 with 200 pairs.\n",
      "Saved batch 582 with 200 pairs.\n",
      "Saved batch 583 with 200 pairs.\n",
      "Saved batch 584 with 200 pairs.\n",
      "Saved batch 585 with 200 pairs.\n",
      "Saved batch 586 with 200 pairs.\n",
      "Saved batch 587 with 200 pairs.\n",
      "Saved batch 588 with 200 pairs.\n",
      "Saved batch 589 with 200 pairs.\n",
      "Saved batch 590 with 200 pairs.\n",
      "Saved batch 591 with 200 pairs.\n",
      "Saved batch 592 with 200 pairs.\n",
      "Saved batch 593 with 200 pairs.\n",
      "Saved batch 594 with 200 pairs.\n",
      "Saved batch 595 with 200 pairs.\n",
      "Saved batch 596 with 200 pairs.\n",
      "Saved batch 597 with 200 pairs.\n",
      "Saved batch 598 with 200 pairs.\n",
      "Saved batch 599 with 200 pairs.\n",
      "Saved batch 600 with 200 pairs.\n",
      "Saved batch 601 with 200 pairs.\n",
      "Saved batch 602 with 200 pairs.\n",
      "Saved batch 603 with 200 pairs.\n",
      "Saved batch 604 with 200 pairs.\n",
      "Saved batch 605 with 200 pairs.\n",
      "Saved batch 606 with 200 pairs.\n",
      "Saved batch 607 with 200 pairs.\n",
      "Saved batch 608 with 200 pairs.\n",
      "Saved batch 609 with 200 pairs.\n",
      "Saved batch 610 with 200 pairs.\n",
      "Saved batch 611 with 200 pairs.\n",
      "Saved batch 612 with 200 pairs.\n",
      "Saved batch 613 with 200 pairs.\n",
      "Saved batch 614 with 200 pairs.\n",
      "Saved batch 615 with 200 pairs.\n",
      "Saved batch 616 with 200 pairs.\n",
      "Saved batch 617 with 200 pairs.\n",
      "Saved batch 618 with 200 pairs.\n",
      "Saved batch 619 with 200 pairs.\n",
      "Saved batch 620 with 200 pairs.\n",
      "Saved batch 621 with 200 pairs.\n",
      "Saved batch 622 with 200 pairs.\n",
      "Saved batch 623 with 200 pairs.\n",
      "Saved batch 624 with 200 pairs.\n",
      "Saved batch 625 with 200 pairs.\n",
      "Saved batch 626 with 200 pairs.\n",
      "Saved batch 627 with 200 pairs.\n",
      "Saved batch 628 with 200 pairs.\n",
      "Saved batch 629 with 200 pairs.\n",
      "Saved batch 630 with 200 pairs.\n",
      "Saved batch 631 with 200 pairs.\n",
      "Saved batch 632 with 200 pairs.\n",
      "Saved batch 633 with 200 pairs.\n",
      "Saved batch 634 with 200 pairs.\n",
      "Saved batch 635 with 200 pairs.\n",
      "Saved batch 636 with 200 pairs.\n",
      "Saved batch 637 with 200 pairs.\n",
      "Saved batch 638 with 200 pairs.\n",
      "Saved batch 639 with 200 pairs.\n",
      "Saved batch 640 with 200 pairs.\n",
      "Saved batch 641 with 200 pairs.\n",
      "Saved batch 642 with 200 pairs.\n",
      "Saved batch 643 with 200 pairs.\n",
      "Saved batch 644 with 200 pairs.\n",
      "Saved batch 645 with 200 pairs.\n",
      "Saved batch 646 with 200 pairs.\n",
      "Saved batch 647 with 200 pairs.\n",
      "Saved batch 648 with 200 pairs.\n",
      "Saved batch 649 with 200 pairs.\n",
      "Saved batch 650 with 200 pairs.\n",
      "Saved batch 651 with 200 pairs.\n",
      "Saved batch 652 with 200 pairs.\n",
      "Saved batch 653 with 200 pairs.\n",
      "Saved batch 654 with 200 pairs.\n",
      "Saved batch 655 with 200 pairs.\n",
      "Saved batch 656 with 200 pairs.\n",
      "Saved batch 657 with 200 pairs.\n",
      "Saved batch 658 with 200 pairs.\n",
      "Saved batch 659 with 200 pairs.\n",
      "Saved batch 660 with 200 pairs.\n",
      "Saved batch 661 with 200 pairs.\n",
      "Saved batch 662 with 200 pairs.\n",
      "Saved batch 663 with 200 pairs.\n",
      "Saved batch 664 with 200 pairs.\n",
      "Saved batch 665 with 200 pairs.\n",
      "Saved batch 666 with 200 pairs.\n",
      "Saved batch 667 with 200 pairs.\n",
      "Saved batch 668 with 200 pairs.\n",
      "Saved batch 669 with 200 pairs.\n",
      "Saved batch 670 with 200 pairs.\n",
      "Saved batch 671 with 200 pairs.\n",
      "Saved batch 672 with 200 pairs.\n",
      "Saved batch 673 with 200 pairs.\n",
      "Saved batch 674 with 200 pairs.\n",
      "Saved batch 675 with 200 pairs.\n",
      "Saved batch 676 with 200 pairs.\n",
      "Saved batch 677 with 200 pairs.\n",
      "Saved batch 678 with 200 pairs.\n",
      "Saved batch 679 with 200 pairs.\n",
      "Saved batch 680 with 200 pairs.\n",
      "Saved batch 681 with 200 pairs.\n",
      "Saved batch 682 with 200 pairs.\n",
      "Saved batch 683 with 200 pairs.\n",
      "Saved batch 684 with 200 pairs.\n",
      "Saved batch 685 with 200 pairs.\n",
      "Saved batch 686 with 200 pairs.\n",
      "Saved batch 687 with 200 pairs.\n",
      "Saved batch 688 with 200 pairs.\n",
      "Saved batch 689 with 200 pairs.\n",
      "Saved batch 690 with 200 pairs.\n",
      "Saved batch 691 with 200 pairs.\n",
      "Saved batch 692 with 200 pairs.\n",
      "Saved batch 693 with 200 pairs.\n",
      "Saved batch 694 with 200 pairs.\n",
      "Saved batch 695 with 200 pairs.\n",
      "Saved batch 696 with 200 pairs.\n",
      "Saved batch 697 with 200 pairs.\n",
      "Saved batch 698 with 200 pairs.\n",
      "Saved batch 699 with 200 pairs.\n",
      "Saved batch 700 with 200 pairs.\n",
      "Saved batch 701 with 200 pairs.\n",
      "Saved batch 702 with 200 pairs.\n",
      "Saved batch 703 with 200 pairs.\n",
      "Saved batch 704 with 200 pairs.\n",
      "Saved batch 705 with 200 pairs.\n",
      "Saved batch 706 with 200 pairs.\n",
      "Saved batch 707 with 200 pairs.\n",
      "Saved batch 708 with 200 pairs.\n",
      "Saved batch 709 with 200 pairs.\n",
      "Saved batch 710 with 200 pairs.\n",
      "Saved batch 711 with 200 pairs.\n",
      "Saved batch 712 with 200 pairs.\n",
      "Saved batch 713 with 200 pairs.\n",
      "Saved batch 714 with 200 pairs.\n",
      "Saved batch 715 with 200 pairs.\n",
      "Saved batch 716 with 200 pairs.\n",
      "Saved batch 717 with 200 pairs.\n",
      "Saved batch 718 with 200 pairs.\n",
      "Saved batch 719 with 200 pairs.\n",
      "Saved batch 720 with 200 pairs.\n",
      "Saved batch 721 with 200 pairs.\n",
      "Saved batch 722 with 200 pairs.\n",
      "Saved batch 723 with 200 pairs.\n",
      "Saved batch 724 with 200 pairs.\n",
      "Saved batch 725 with 200 pairs.\n",
      "Saved batch 726 with 200 pairs.\n",
      "Saved batch 727 with 200 pairs.\n",
      "Saved batch 728 with 200 pairs.\n",
      "Saved batch 729 with 200 pairs.\n",
      "Saved batch 730 with 200 pairs.\n",
      "Saved batch 731 with 200 pairs.\n",
      "Saved batch 732 with 200 pairs.\n",
      "Saved batch 733 with 200 pairs.\n",
      "Saved batch 734 with 200 pairs.\n",
      "Saved batch 735 with 200 pairs.\n",
      "Saved batch 736 with 200 pairs.\n",
      "Saved batch 737 with 200 pairs.\n",
      "Saved batch 738 with 200 pairs.\n",
      "Saved batch 739 with 200 pairs.\n",
      "Saved batch 740 with 200 pairs.\n",
      "Saved batch 741 with 200 pairs.\n",
      "Saved batch 742 with 200 pairs.\n",
      "Saved batch 743 with 200 pairs.\n",
      "Saved batch 744 with 200 pairs.\n",
      "Saved batch 745 with 200 pairs.\n",
      "Saved batch 746 with 200 pairs.\n",
      "Saved batch 747 with 200 pairs.\n",
      "Saved batch 748 with 200 pairs.\n",
      "Saved batch 749 with 200 pairs.\n",
      "Saved batch 750 with 200 pairs.\n",
      "Saved batch 751 with 200 pairs.\n",
      "Saved batch 752 with 200 pairs.\n",
      "Saved batch 753 with 200 pairs.\n",
      "Saved batch 754 with 200 pairs.\n",
      "Saved batch 755 with 200 pairs.\n",
      "Saved batch 756 with 200 pairs.\n",
      "Saved batch 757 with 200 pairs.\n",
      "Saved batch 758 with 200 pairs.\n",
      "Saved batch 759 with 200 pairs.\n",
      "Saved batch 760 with 200 pairs.\n",
      "Saved batch 761 with 200 pairs.\n",
      "Saved batch 762 with 200 pairs.\n",
      "Saved batch 763 with 200 pairs.\n",
      "Saved batch 764 with 200 pairs.\n",
      "Saved batch 765 with 200 pairs.\n",
      "Saved batch 766 with 200 pairs.\n",
      "Saved batch 767 with 200 pairs.\n",
      "Saved batch 768 with 200 pairs.\n",
      "Saved batch 769 with 200 pairs.\n",
      "Saved batch 770 with 200 pairs.\n",
      "Saved batch 771 with 200 pairs.\n",
      "Saved batch 772 with 200 pairs.\n",
      "Saved batch 773 with 200 pairs.\n",
      "Saved batch 774 with 200 pairs.\n",
      "Saved batch 775 with 200 pairs.\n",
      "Saved batch 776 with 200 pairs.\n",
      "Saved batch 777 with 200 pairs.\n",
      "Saved batch 778 with 200 pairs.\n",
      "Saved batch 779 with 200 pairs.\n",
      "Saved batch 780 with 200 pairs.\n",
      "Saved batch 781 with 200 pairs.\n",
      "Saved batch 782 with 200 pairs.\n",
      "Saved batch 783 with 200 pairs.\n",
      "Saved batch 784 with 200 pairs.\n",
      "Saved batch 785 with 200 pairs.\n",
      "Saved batch 786 with 200 pairs.\n",
      "Saved batch 787 with 200 pairs.\n",
      "Saved batch 788 with 200 pairs.\n",
      "Saved batch 789 with 200 pairs.\n",
      "Saved batch 790 with 200 pairs.\n",
      "Saved batch 791 with 200 pairs.\n",
      "Saved batch 792 with 200 pairs.\n",
      "Saved batch 793 with 200 pairs.\n",
      "Saved batch 794 with 200 pairs.\n",
      "Saved batch 795 with 200 pairs.\n",
      "Saved batch 796 with 200 pairs.\n",
      "Saved batch 797 with 200 pairs.\n",
      "Saved batch 798 with 200 pairs.\n",
      "Saved batch 799 with 200 pairs.\n",
      "Saved batch 800 with 200 pairs.\n",
      "Saved batch 801 with 200 pairs.\n",
      "Saved batch 802 with 200 pairs.\n",
      "Saved batch 803 with 200 pairs.\n",
      "Saved batch 804 with 200 pairs.\n",
      "Saved batch 805 with 200 pairs.\n",
      "Saved batch 806 with 200 pairs.\n",
      "Saved batch 807 with 200 pairs.\n",
      "Saved batch 808 with 200 pairs.\n",
      "Saved batch 809 with 200 pairs.\n",
      "Saved batch 810 with 200 pairs.\n",
      "Saved batch 811 with 200 pairs.\n",
      "Saved batch 812 with 200 pairs.\n",
      "Saved batch 813 with 200 pairs.\n",
      "Saved batch 814 with 200 pairs.\n",
      "Saved batch 815 with 200 pairs.\n",
      "Saved batch 816 with 200 pairs.\n",
      "Saved batch 817 with 200 pairs.\n",
      "Saved batch 818 with 200 pairs.\n",
      "Saved batch 819 with 200 pairs.\n",
      "Saved batch 820 with 200 pairs.\n",
      "Saved batch 821 with 200 pairs.\n",
      "Saved batch 822 with 200 pairs.\n",
      "Saved batch 823 with 200 pairs.\n",
      "Saved batch 824 with 200 pairs.\n",
      "Saved batch 825 with 200 pairs.\n",
      "Saved batch 826 with 200 pairs.\n",
      "Saved batch 827 with 200 pairs.\n",
      "Saved batch 828 with 200 pairs.\n",
      "Saved batch 829 with 200 pairs.\n",
      "Saved batch 830 with 200 pairs.\n",
      "Saved batch 831 with 200 pairs.\n",
      "Saved batch 832 with 200 pairs.\n",
      "Saved batch 833 with 200 pairs.\n",
      "Saved batch 834 with 200 pairs.\n",
      "Saved batch 835 with 200 pairs.\n",
      "Saved batch 836 with 200 pairs.\n",
      "Saved batch 837 with 200 pairs.\n",
      "Saved batch 838 with 200 pairs.\n",
      "Saved batch 839 with 200 pairs.\n",
      "Saved batch 840 with 200 pairs.\n",
      "Saved batch 841 with 200 pairs.\n",
      "Saved batch 842 with 200 pairs.\n",
      "Saved batch 843 with 200 pairs.\n",
      "Saved batch 844 with 200 pairs.\n",
      "Saved batch 845 with 200 pairs.\n",
      "Saved batch 846 with 200 pairs.\n",
      "Saved batch 847 with 200 pairs.\n",
      "Saved batch 848 with 200 pairs.\n",
      "Saved batch 849 with 200 pairs.\n",
      "Saved batch 850 with 200 pairs.\n",
      "Saved batch 851 with 200 pairs.\n",
      "Saved batch 852 with 200 pairs.\n",
      "Saved batch 853 with 200 pairs.\n",
      "Saved batch 854 with 200 pairs.\n",
      "Saved batch 855 with 200 pairs.\n",
      "Saved batch 856 with 200 pairs.\n",
      "Saved batch 857 with 200 pairs.\n",
      "Saved batch 858 with 200 pairs.\n",
      "Saved batch 859 with 200 pairs.\n",
      "Saved batch 860 with 200 pairs.\n",
      "Saved batch 861 with 200 pairs.\n",
      "Saved batch 862 with 200 pairs.\n",
      "Saved batch 863 with 200 pairs.\n",
      "Saved batch 864 with 200 pairs.\n",
      "Saved batch 865 with 200 pairs.\n",
      "Saved batch 866 with 200 pairs.\n",
      "Saved batch 867 with 200 pairs.\n",
      "Saved batch 868 with 200 pairs.\n",
      "Saved batch 869 with 200 pairs.\n",
      "Saved batch 870 with 200 pairs.\n",
      "Saved batch 871 with 200 pairs.\n",
      "Saved batch 872 with 200 pairs.\n",
      "Saved batch 873 with 200 pairs.\n",
      "Saved batch 874 with 200 pairs.\n",
      "Saved batch 875 with 200 pairs.\n",
      "Saved batch 876 with 200 pairs.\n",
      "Saved batch 877 with 200 pairs.\n",
      "Saved batch 878 with 200 pairs.\n",
      "Saved batch 879 with 200 pairs.\n",
      "Saved batch 880 with 200 pairs.\n",
      "Saved batch 881 with 200 pairs.\n",
      "Saved batch 882 with 200 pairs.\n",
      "Saved batch 883 with 200 pairs.\n",
      "Saved batch 884 with 200 pairs.\n",
      "Saved batch 885 with 200 pairs.\n",
      "Saved batch 886 with 200 pairs.\n",
      "Saved batch 887 with 200 pairs.\n",
      "Saved batch 888 with 200 pairs.\n",
      "Saved batch 889 with 200 pairs.\n",
      "Saved batch 890 with 200 pairs.\n",
      "Saved batch 891 with 200 pairs.\n",
      "Saved batch 892 with 200 pairs.\n",
      "Saved batch 893 with 200 pairs.\n",
      "Saved batch 894 with 200 pairs.\n",
      "Saved batch 895 with 200 pairs.\n",
      "Saved batch 896 with 200 pairs.\n",
      "Saved batch 897 with 200 pairs.\n",
      "Saved batch 898 with 200 pairs.\n",
      "Saved batch 899 with 200 pairs.\n",
      "Saved batch 900 with 200 pairs.\n",
      "Saved batch 901 with 200 pairs.\n",
      "Saved batch 902 with 200 pairs.\n",
      "Saved batch 903 with 200 pairs.\n",
      "Saved batch 904 with 200 pairs.\n",
      "Saved batch 905 with 200 pairs.\n",
      "Saved batch 906 with 200 pairs.\n",
      "Saved batch 907 with 200 pairs.\n",
      "Saved batch 908 with 200 pairs.\n",
      "Saved batch 909 with 200 pairs.\n",
      "Saved batch 910 with 200 pairs.\n",
      "Saved batch 911 with 200 pairs.\n",
      "Saved batch 912 with 200 pairs.\n",
      "Saved batch 913 with 200 pairs.\n",
      "Saved batch 914 with 200 pairs.\n",
      "Saved batch 915 with 200 pairs.\n",
      "Saved batch 916 with 200 pairs.\n",
      "Saved batch 917 with 200 pairs.\n",
      "Saved batch 918 with 200 pairs.\n",
      "Saved batch 919 with 200 pairs.\n",
      "Saved batch 920 with 200 pairs.\n",
      "Saved batch 921 with 200 pairs.\n",
      "Saved batch 922 with 200 pairs.\n",
      "Saved batch 923 with 200 pairs.\n",
      "Saved batch 924 with 200 pairs.\n",
      "Saved batch 925 with 200 pairs.\n",
      "Saved batch 926 with 200 pairs.\n",
      "Saved batch 927 with 200 pairs.\n",
      "Saved batch 928 with 200 pairs.\n",
      "Saved batch 929 with 200 pairs.\n",
      "Saved batch 930 with 200 pairs.\n",
      "Saved batch 931 with 200 pairs.\n",
      "Saved batch 932 with 200 pairs.\n",
      "Saved batch 933 with 200 pairs.\n",
      "Saved batch 934 with 200 pairs.\n",
      "Saved batch 935 with 200 pairs.\n",
      "Saved batch 936 with 200 pairs.\n",
      "Saved batch 937 with 200 pairs.\n",
      "Saved batch 938 with 200 pairs.\n",
      "Saved batch 939 with 200 pairs.\n",
      "Saved batch 940 with 200 pairs.\n",
      "Saved batch 941 with 200 pairs.\n",
      "Saved batch 942 with 200 pairs.\n",
      "Saved batch 943 with 200 pairs.\n",
      "Saved batch 944 with 200 pairs.\n",
      "Saved batch 945 with 200 pairs.\n",
      "Saved batch 946 with 200 pairs.\n",
      "Saved batch 947 with 200 pairs.\n",
      "Saved batch 948 with 200 pairs.\n",
      "Saved batch 949 with 200 pairs.\n",
      "Saved batch 950 with 200 pairs.\n",
      "Saved batch 951 with 200 pairs.\n",
      "Saved batch 952 with 200 pairs.\n",
      "Saved batch 953 with 200 pairs.\n",
      "Saved batch 954 with 200 pairs.\n",
      "Saved batch 955 with 200 pairs.\n",
      "Saved batch 956 with 200 pairs.\n",
      "Saved batch 957 with 200 pairs.\n",
      "Saved batch 958 with 200 pairs.\n",
      "Saved batch 959 with 200 pairs.\n",
      "Saved batch 960 with 200 pairs.\n",
      "Saved batch 961 with 200 pairs.\n",
      "Saved batch 962 with 200 pairs.\n",
      "Saved batch 963 with 200 pairs.\n",
      "Saved batch 964 with 200 pairs.\n",
      "Saved batch 965 with 200 pairs.\n",
      "Saved batch 966 with 200 pairs.\n",
      "Saved batch 967 with 200 pairs.\n",
      "Saved batch 968 with 200 pairs.\n",
      "Saved batch 969 with 200 pairs.\n",
      "Saved batch 970 with 200 pairs.\n",
      "Saved batch 971 with 200 pairs.\n",
      "Saved batch 972 with 200 pairs.\n",
      "Saved batch 973 with 200 pairs.\n",
      "Saved batch 974 with 200 pairs.\n",
      "Saved batch 975 with 200 pairs.\n",
      "Saved batch 976 with 200 pairs.\n",
      "Saved batch 977 with 200 pairs.\n",
      "Saved batch 978 with 200 pairs.\n",
      "Saved batch 979 with 200 pairs.\n",
      "Saved batch 980 with 200 pairs.\n",
      "Saved batch 981 with 200 pairs.\n",
      "Saved batch 982 with 200 pairs.\n",
      "Saved batch 983 with 200 pairs.\n",
      "Saved batch 984 with 200 pairs.\n",
      "Saved batch 985 with 200 pairs.\n",
      "Saved batch 986 with 200 pairs.\n",
      "Saved batch 987 with 200 pairs.\n",
      "Saved batch 988 with 200 pairs.\n",
      "Saved batch 989 with 200 pairs.\n",
      "Saved batch 990 with 200 pairs.\n",
      "Saved batch 991 with 200 pairs.\n",
      "Saved batch 992 with 200 pairs.\n",
      "Saved batch 993 with 200 pairs.\n",
      "Saved batch 994 with 200 pairs.\n",
      "Saved batch 995 with 200 pairs.\n",
      "Saved batch 996 with 200 pairs.\n",
      "Saved batch 997 with 200 pairs.\n",
      "Saved batch 998 with 200 pairs.\n",
      "Saved batch 999 with 200 pairs.\n",
      "Reached max_batches limit: 1000\n",
      "Data sampling and batch saving completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mne\n",
    "import cupy as cp\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Directories for Denoised Data and Metadata\n",
    "# ---------------------------------------------------------------\n",
    "denoised_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/denoised_data'\n",
    "torcheeg_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS'\n",
    "output_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/contrastive_pairs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load Metadata from .torcheeg Directory\n",
    "# ---------------------------------------------------------------\n",
    "def load_metadata(torcheeg_dir):\n",
    "    metadata_dict = {}\n",
    "    for record_folder in os.listdir(torcheeg_dir):\n",
    "        folder_path = os.path.join(torcheeg_dir, record_folder)\n",
    "        info_path = os.path.join(folder_path, 'info.csv')\n",
    "        if os.path.exists(info_path):\n",
    "            metadata_dict[record_folder] = pd.read_csv(info_path)\n",
    "    return metadata_dict\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load Denoised EEG Data into GPU with Robust Normalization\n",
    "# ---------------------------------------------------------------\n",
    "def load_data_in_chunks(denoised_dir, chunk_size=50000):\n",
    "    data_dict = {}\n",
    "    threshold = 1e-6  # Variance threshold for excluding low-variance channels\n",
    "\n",
    "    for filename in os.listdir(denoised_dir):\n",
    "        if filename.endswith('.fif'):\n",
    "            record_id = filename.split('.')[0]\n",
    "            file_path = os.path.join(denoised_dir, filename)\n",
    "            raw = mne.io.read_raw_fif(file_path, preload=True)\n",
    "            data = raw.get_data()\n",
    "\n",
    "            # Replace NaNs and Infs with finite values for each channel\n",
    "            for ch in range(data.shape[0]):\n",
    "                nan_mask = np.isnan(data[ch])\n",
    "                inf_mask = ~np.isfinite(data[ch])\n",
    "                if np.any(nan_mask):\n",
    "                    data[ch, nan_mask] = np.nanmean(data[ch])\n",
    "                if np.any(inf_mask):\n",
    "                    data[ch, inf_mask] = 0.0\n",
    "\n",
    "            # Exclude low-variance channels\n",
    "            variances = np.var(data, axis=1)\n",
    "            valid_channels = variances > threshold\n",
    "            data = data[valid_channels]\n",
    "\n",
    "            # Robust z-score normalization per channel\n",
    "            scaler = StandardScaler()\n",
    "            data = scaler.fit_transform(data.T).T  # Normalize across each channel\n",
    "\n",
    "            data_dict[record_id] = cp.asarray(data, dtype=cp.float16)\n",
    "    return data_dict\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Compute Differential Entropy (DE) Features\n",
    "# ---------------------------------------------------------------\n",
    "def differential_entropy(segment):\n",
    "    return 0.5 * np.log(2 * np.pi * np.e * np.var(segment, axis=1, keepdims=True))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Create Contrastive Pairs (Positive and Negative)\n",
    "# ---------------------------------------------------------------\n",
    "def create_contrastive_pairs(data_dict, metadata_dict, sample_length=2000, step_size=1000, batch_size=200, max_batches=1000):\n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "    batch_count = 0\n",
    "    processed_records = 0\n",
    "\n",
    "    max_records = 10\n",
    "\n",
    "    for record_id, data in data_dict.items():\n",
    "        if processed_records >= max_records:\n",
    "            break\n",
    "\n",
    "        meta_key = '_' + record_id.replace('denoised_cleaned__', '')\n",
    "\n",
    "        if meta_key not in metadata_dict:\n",
    "            print(f\"No metadata found for {record_id}\")\n",
    "            continue\n",
    "\n",
    "        meta = metadata_dict[meta_key]\n",
    "        print(f\"Processing {record_id} with {len(meta)} metadata entries...\")\n",
    "\n",
    "        num_segments = len(meta)\n",
    "\n",
    "        # Generate all possible pairs\n",
    "        for i in range(num_segments):\n",
    "            for j in range(num_segments):\n",
    "                if i == j:\n",
    "                    continue  # Skip self-pairs\n",
    "\n",
    "                start_a = meta.loc[i, 'start_at']\n",
    "                start_b = meta.loc[j, 'start_at']\n",
    "\n",
    "                # Extract EEG segments\n",
    "                segment_a = data[:, start_a:start_a + sample_length]\n",
    "                segment_b = data[:, start_b:start_b + sample_length]\n",
    "\n",
    "                # Ensure segments have the correct length\n",
    "                if segment_a.shape[1] == sample_length and segment_b.shape[1] == sample_length:\n",
    "                    # Compute Differential Entropy (DE) features\n",
    "                    segment_a_de = differential_entropy(segment_a)\n",
    "                    segment_b_de = differential_entropy(segment_b)\n",
    "\n",
    "                    # Label pairs as positive (1) or negative (0) based on metadata\n",
    "                    label_a = meta.loc[i, 'emotion']\n",
    "                    label_b = meta.loc[j, 'emotion']\n",
    "\n",
    "                    if label_a == label_b:\n",
    "                        positive_pairs.append((segment_a_de, segment_b_de, 1))\n",
    "                    else:\n",
    "                        negative_pairs.append((segment_a_de, segment_b_de, 0))\n",
    "\n",
    "                # Save batch if we have enough pairs\n",
    "                if len(positive_pairs) >= batch_size // 2 and len(negative_pairs) >= batch_size // 2:\n",
    "                    pairs = positive_pairs[:batch_size // 2] + negative_pairs[:batch_size // 2]\n",
    "                    save_batch(pairs, batch_count, output_dir)\n",
    "                    batch_count += 1\n",
    "                    positive_pairs = []\n",
    "                    negative_pairs = []\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "                    if batch_count >= max_batches:\n",
    "                        print(f\"Reached max_batches limit: {max_batches}\")\n",
    "                        return\n",
    "\n",
    "        processed_records += 1\n",
    "\n",
    "    # Save any remaining pairs\n",
    "    if positive_pairs or negative_pairs:\n",
    "        pairs = positive_pairs + negative_pairs\n",
    "        save_batch(pairs, batch_count, output_dir)\n",
    "        print(f\"Final batch saved. Total batches: {batch_count}\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Save Batch to Disk with Gzip Compression\n",
    "# ---------------------------------------------------------------\n",
    "def save_batch(pairs, batch_count, output_dir):\n",
    "    batch_path = os.path.join(output_dir, f'batch_{batch_count}_pairs.pkl.gz')\n",
    "\n",
    "    # Convert segments to CPU arrays and ensure they are flattened\n",
    "    converted_pairs = []\n",
    "    for segment_a, segment_b, label in pairs:\n",
    "        segment_a_cpu = cp.asnumpy(segment_a).flatten()\n",
    "        segment_b_cpu = cp.asnumpy(segment_b).flatten()\n",
    "        converted_pairs.append((segment_a_cpu, segment_b_cpu, label))\n",
    "\n",
    "    # Save using pickle with gzip compression\n",
    "    with gzip.open(batch_path, 'wb') as f:\n",
    "        pickle.dump(converted_pairs, f)\n",
    "\n",
    "    print(f\"Saved batch {batch_count} with {len(converted_pairs)} pairs.\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Run the Data Sampling Process\n",
    "# ---------------------------------------------------------------\n",
    "print(\"Loading metadata...\")\n",
    "metadata_dict = load_metadata(torcheeg_dir)\n",
    "print(\"Keys in metadata_dict:\", list(metadata_dict.keys()))\n",
    "\n",
    "print(\"Loading denoised data...\")\n",
    "data_dict = load_data_in_chunks(denoised_dir)\n",
    "print(\"Keys in data_dict:\", list(data_dict.keys()))\n",
    "\n",
    "print(\"Creating contrastive pairs in batches...\")\n",
    "create_contrastive_pairs(data_dict, metadata_dict)\n",
    "print(\"Data sampling and batch saving completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "def load_saved_pairs(batch_file):\n",
    "    with gzip.open(batch_file, 'rb') as f:\n",
    "        pairs = pickle.load(f)\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 200\n",
      "Average length of Segment A: 62.0\n",
      "Average length of Segment B: 62.0\n",
      "Number of Positive Pairs: 100\n",
      "Number of Negative Pairs: 100\n",
      "Average Cosine Similarity: 0.00522705078125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def evaluate_pairs(pairs):\n",
    "    print(f\"Total pairs: {len(pairs)}\")\n",
    "    \n",
    "    lengths_a = []\n",
    "    lengths_b = []\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    similarities = []\n",
    "\n",
    "    for segment_a, segment_b, label in pairs:\n",
    "        # Check the lengths of each segment\n",
    "        lengths_a.append(len(segment_a))\n",
    "        lengths_b.append(len(segment_b))\n",
    "\n",
    "        # Track label distribution\n",
    "        if label == 1:\n",
    "            positive_count += 1\n",
    "        elif label == 0:\n",
    "            negative_count += 1\n",
    "\n",
    "        # Compute similarity (e.g., Euclidean or Cosine)\n",
    "        similarity = cosine(segment_a, segment_b)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    # Summary statistics\n",
    "    print(f\"Average length of Segment A: {np.mean(lengths_a)}\")\n",
    "    print(f\"Average length of Segment B: {np.mean(lengths_b)}\")\n",
    "    print(f\"Number of Positive Pairs: {positive_count}\")\n",
    "    print(f\"Number of Negative Pairs: {negative_count}\")\n",
    "    print(f\"Average Cosine Similarity: {np.mean(similarities)}\")\n",
    "\n",
    "# Path to your saved batch file\n",
    "batch_file = r'C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\contrastive_pairs\\batch_1_pairs.pkl.gz'\n",
    "\n",
    "# Load the pairs\n",
    "pairs = load_saved_pairs(batch_file)\n",
    "\n",
    "# Evaluate the pairs\n",
    "evaluate_pairs(pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments A Shape: torch.Size([200, 62])\n",
      "Segments B Shape: torch.Size([200, 62])\n",
      "Labels Shape: torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Directory Containing Contrastive Pairs\n",
    "# ---------------------------------------------------------------\n",
    "contrastive_pairs_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/contrastive_pairs'\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load a Batch of Contrastive Pairs\n",
    "# ---------------------------------------------------------------\n",
    "def load_contrastive_batch(batch_file, device='cpu'):\n",
    "    with gzip.open(batch_file, 'rb') as f:\n",
    "        pairs = pickle.load(f)  # Load the pickled pairs\n",
    "\n",
    "    # Unpack the pairs into two separate tensors: segments_a, segments_b, and labels\n",
    "    segments_a = [torch.tensor(pair[0], dtype=torch.float32) for pair in pairs]\n",
    "    segments_b = [torch.tensor(pair[1], dtype=torch.float32) for pair in pairs]\n",
    "    labels = [torch.tensor(pair[2], dtype=torch.float32) for pair in pairs]\n",
    "\n",
    "    # Stack into tensors and move to the specified device\n",
    "    segments_a = torch.stack(segments_a).to(device)  # Shape: [batch_size, num_channels * num_features]\n",
    "    segments_b = torch.stack(segments_b).to(device)\n",
    "    labels = torch.stack(labels).to(device)          # Shape: [batch_size]\n",
    "\n",
    "    return segments_a, segments_b, labels\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load a Sample Batch\n",
    "# ---------------------------------------------------------------\n",
    "batch_file = os.path.join(contrastive_pairs_dir, 'batch_0_pairs.pkl.gz')\n",
    "segments_a, segments_b, labels = load_contrastive_batch(batch_file)\n",
    "\n",
    "print(f\"Segments A Shape: {segments_a.shape}\")  # Example: [batch_size, num_channels * num_features]\n",
    "print(f\"Segments B Shape: {segments_b.shape}\")  # Example: [batch_size, num_channels * num_features]\n",
    "print(f\"Labels Shape: {labels.shape}\")          # Example: [batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input A Shape: torch.Size([8, 62, 200])\n",
      "Input B Shape: torch.Size([8, 62, 200])\n",
      "Output A Shape: torch.Size([8, 16, 200])\n",
      "Output B Shape: torch.Size([8, 16, 200])\n",
      "Output Mean: 0.0067\n",
      "Output Std: 0.1632\n",
      "Output Min: -0.4256\n",
      "Output Max: 0.3615\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkYAAAHHCAYAAABa2ZeMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGN0lEQVR4nO3deXxM9/7H8XeQxJJNkEQssaX25ZYiRSmpiFAtrlpqTasLWustumi5LUUt7dXq7YLeVm2XVqmt9mqqpZZaqqKWKkmsieUKSb6/P5zMz0iQTJZJeD0fj3k8nHO+c87nO5NJ3r7ne864GGOMAAAAoALOLgAAACCvIBgBAABYCEYAAAAWghEAAICFYAQAAGAhGAEAAFgIRgAAABaCEQAAgIVgBAAAYCEYIVu9/vrrcnFxyZVjtWjRQi1atLAtb9iwQS4uLlq0aFGuHL9Pnz6qUKFCrhzLURcvXtRTTz2lgIAAubi4aPDgwc4uCZKOHDkiFxcXzZ4929mlIBN43+4NBCPc0uzZs+Xi4mJ7FC5cWIGBgQoLC9O7776rCxcuZMtxTpw4oddff107d+7Mlv1lp7xcW0a89dZbmj17tp577jn95z//Uc+ePW/ZtkKFCmne7+DgYI0YMUJnz57NxaozLvUP1a0eEyZMcHaJecaZM2c0YsQIVa1aVYULF5avr6/CwsK0bNmyLO137ty5mjZtWvYUeQeZ+Tw++uijKlq06G1/T/Xo0UNubm46c+ZMNlaJ/K6QswtA3jd27FhVrFhR165dU0xMjDZs2KDBgwdrypQpWrp0qerUqWNr+8orr2jkyJGZ2v+JEyf0xhtvqEKFCqpXr16Gn7d69epMHccRt6vto48+UkpKSo7XkBXr1q1T48aNNWbMmAy1r1evnoYNGyZJunLlirZv365p06Zp48aN+umnn3Ky1Czp1q2b2rZtm2b93/72NydUk/ccOHBArVq10qlTp9S3b181aNBA58+f1xdffKH27dtr+PDhmjRpkkP7njt3rvbs2ZMro5GZ+V3Ro0cPffPNN1qyZIl69eqVZvvly5f19ddfq02bNipRokQOVYz8iGCEOwoPD1eDBg1sy6NGjdK6devUrl07Pfroo9q/f7+KFCkiSSpUqJAKFcrZH6vLly+raNGicnNzy9Hj3Imrq6tTj58RcXFxqlGjRobblylTRk8++aRt+amnnpKHh4cmT56sgwcPKjg4OCfKzLL777/fru57zaVLl1SsWLF0t127dk2dO3fWuXPntGnTJjVq1Mi2bciQIerRo4cmT56sBg0a6IknnsitknPco48+Kk9PT82dOzfdYPT111/r0qVL6tGjhxOqQ17GqTQ4pGXLlnr11Vd19OhRff7557b16c0xWrNmjZo2bSofHx95eHioatWqGj16tKTr84IeeOABSVLfvn1tp0BSz+G3aNFCtWrV0vbt2/XQQw+paNGitufePMcoVXJyskaPHq2AgAAVK1ZMjz76qP7880+7NhUqVFCfPn3SPPfGfd6ptvTmGF26dEnDhg1TuXLl5O7urqpVq2ry5Mkyxti1c3Fx0cCBA/XVV1+pVq1acnd3V82aNbVy5cr0X/CbxMXFKTIyUv7+/ipcuLDq1q2rOXPm2Lanzrc6fPiwli9fbqv9yJEjGdr/jQICAiTJLvDu3r1bffr0UaVKlVS4cGEFBASoX79+aU5JXLhwQYMHD1aFChXk7u4uPz8/PfLII/rll1/s2m3dulVt2rSRt7e3ihYtqubNm2vLli2ZrvV2KlSooHbt2un7779Xw4YNVbhwYVWqVEmfffZZmrbnz5/XkCFDbHWXLVtWvXr10unTp21t7vQe3LivPn36yNvbWz4+Purdu7fOnz+fbo2//fabOnfuLF9fXxUuXFgNGjTQ0qVL7dqknuLeuHGjnn/+efn5+als2bK37Pd///tf7dmzRyNHjrQLRZJUsGBBffjhh/Lx8dHrr7+e5hg3/7yk/lxt2LBB0vXPy/Lly3X06FHbz1jqZyK17fz583Pl83izIkWKqGPHjlq7dq3i4uLSbJ87d648PT316KOP6uzZsxo+fLhq164tDw8PeXl5KTw8XLt27Ur/Rb1FjTdK7/dDSkqKpk2bppo1a6pw4cLy9/fXM888o3Pnztm127Ztm8LCwlSyZEkVKVJEFStWVL9+/e5YC7IHI0ZwWM+ePTV69GitXr1aTz/9dLpt9u7dq3bt2qlOnToaO3as3N3dFR0dbfujV716dY0dO1avvfaa+vfvr2bNmkmSHnzwQds+zpw5o/DwcHXt2lVPPvmk/P39b1vXm2++KRcXF7300kuKi4vTtGnTFBoaqp07d9pGtjIiI7XdyBijRx99VOvXr1dkZKTq1aunVatWacSIEfrrr780depUu/bff/+9Fi9erOeff16enp5699131alTJx07duy2Q/v/+9//1KJFC0VHR2vgwIGqWLGiFi5cqD59+uj8+fN68cUXVb16df3nP//RkCFDVLZsWdvpsVKlSt22z9euXbP98b9y5Yp27NihKVOm6KGHHlLFihVt7dasWaM//vhDffv2VUBAgPbu3at///vf2rt3r3788UdbOH722We1aNEiDRw4UDVq1NCZM2f0/fffa//+/br//vslXT/dFx4ervr162vMmDEqUKCAZs2apZYtW2rz5s1q2LDhbWuWro8i3hhaUvn4+NgFuujoaHXu3FmRkZHq3bu3Pv30U/Xp00f169dXzZo1JV2fsN6sWTPt379f/fr10/3336/Tp09r6dKlOn78uEqWLJmh90C6/jPRoUMHff/993r22WdVvXp1LVmyRL17905T6969e9WkSROVKVNGI0eOVLFixbRgwQI99thj+u9//6vHH3/crv3zzz+vUqVK6bXXXtOlS5du+dp88803kpTuqIkkeXt7q0OHDpozZ46io6NVpUqVO7za/+/ll19WfHy8jh8/bvv59vDwsGvjrM+jdP102pw5c7RgwQINHDjQtv7s2bNatWqVunXrpiJFimjv3r366quv9Pe//10VK1ZUbGysPvzwQzVv3lz79u1TYGBghuu8nWeeeUazZ89W37599cILL+jw4cP617/+pR07dmjLli1ydXVVXFycWrdurVKlSmnkyJHy8fHRkSNHtHjx4mypARlggFuYNWuWkWR+/vnnW7bx9vY2f/vb32zLY8aMMTf+WE2dOtVIMqdOnbrlPn7++WcjycyaNSvNtubNmxtJZubMmelua968uW15/fr1RpIpU6aMSUhIsK1fsGCBkWSmT59uWxcUFGR69+59x33errbevXuboKAg2/JXX31lJJl//vOfdu06d+5sXFxcTHR0tG2dJOPm5ma3bteuXUaSee+999Ic60bTpk0zksznn39uW3f16lUTEhJiPDw87PoeFBRkIiIibru/G9tKSvNo0qSJOX36tF3by5cvp3n+l19+aSSZTZs22dZ5e3ubAQMG3PKYKSkpJjg42ISFhZmUlBS7/VesWNE88sgjt6358OHD6dac+oiKikrTvxvri4uLM+7u7mbYsGG2da+99pqRZBYvXpxuvcZk/D1I/ZmYOHGirV1SUpJp1qxZmp+rVq1amdq1a5srV67YHe/BBx80wcHBtnWpn8umTZuapKSk274+xhhTr1494+3tfds2U6ZMMZLM0qVL7Y5x+PBhu3apn7H169fb1kVERNh9Dm5um1ufx/QkJSWZ0qVLm5CQELv1M2fONJLMqlWrjDHGXLlyxSQnJ9u1OXz4sHF3dzdjx461W3fz8W+uMdXNvx82b95sJJkvvvjCrt3KlSvt1i9ZsuSOv3eRsziVhizx8PC47VUfPj4+kq6fz3d0orK7u7v69u2b4fa9evWSp6enbblz584qXbq0vv32W4eOn1HffvutChYsqBdeeMFu/bBhw2SM0YoVK+zWh4aGqnLlyrblOnXqyMvLS3/88ccdjxMQEKBu3brZ1rm6uuqFF17QxYsXtXHjRof70KhRI61Zs0Zr1qzRsmXL9Oabb2rv3r169NFH9b///c/W7sb/6V+5ckWnT59W48aNJcnuNJmPj4+2bt2qEydOpHu8nTt36uDBg+revbvOnDmj06dP6/Tp07p06ZJatWqlTZs2Zejnpn///ra6b3zcPL+qRo0atpEG6foIWtWqVe1e8//+97+qW7dumhEaSbaRsIy+B99++60KFSqk5557ztauYMGCGjRokN1+z549q3Xr1qlLly66cOGC7XU4c+aMwsLCdPDgQf311192z3n66adVsGDBO742Fy5csPs8pCd1e0JCwh33l1nO+jxK11/rrl27Kioqyu604Ny5c+Xv769WrVpJuv47pkCB638Ok5OTdebMGdtp/5tP+zpq4cKF8vb21iOPPGJ7f0+fPq369evLw8ND69evl/T/vzOXLVuma9euZcuxkTkEI2TJxYsXb/tL94knnlCTJk301FNPyd/fX127dtWCBQsyFZLKlCmTqYnWN08QdnFxUZUqVRyaX5MZR48eVWBgYJrXo3r16rbtNypfvnyafRQvXjzNfIP0jhMcHGz7RX6n42RGyZIlFRoaqtDQUEVERGj06NH6+OOP9cMPP+jjjz+2tTt79qxefPFF+fv7q0iRIipVqpTtVFt8fLyt3cSJE7Vnzx6VK1dODRs21Ouvv24XQg4ePChJ6t27t0qVKmX3+Pjjj5WYmGi3v1sJDg621X3jw8vLy65dRl7zQ4cOqVatWrc9Xkbfg6NHj6p06dJpTi9VrVrVbjk6OlrGGL366qtpXofUKwpvnidz46nN2/H09LzjrTVSt98pQDnCWZ/HVKmTq+fOnStJOn78uDZv3qyuXbvagmVKSoqmTp2q4OBgubu7q2TJkipVqpR2796doZ+/jDh48KDi4+Pl5+eX5j2+ePGi7f1t3ry5OnXqpDfeeEMlS5ZUhw4dNGvWLCUmJmZLHbgz5hjBYcePH1d8fPxt5yQUKVJEmzZt0vr167V8+XKtXLlS8+fPV8uWLbV69eoM/Y83M/MQMupWN6FMTk7OUE3Z4VbHMTdN1Ha21P9Vb9q0yTbS0aVLF/3www8aMWKE6tWrJw8PD6WkpKhNmzZ2obdLly5q1qyZlixZotWrV2vSpEl6++23tXjxYoWHh9vaTpo06ZaXX98cKrIir77mqa/D8OHDFRYWlm6bmz9nGf1cVK9eXTt37tSxY8fSDYbS9cn0kmwjbLf7fOSEnPw81q9fX9WqVdOXX36p0aNH68svv5Qxxu5qtLfeekuvvvqq+vXrp3HjxsnX11cFChTQ4MGD7/ifOBcXl3R/fm5+rVJSUuTn56cvvvgi3f2kzv9LvUntjz/+qG+++UarVq1Sv3799M477+jHH3/M1s8D0kcwgsP+85//SNItf5GnKlCggFq1aqVWrVppypQpeuutt/Tyyy9r/fr1Cg0NzfY7ZaeOQqQyxig6OtrufkvFixdP98qgo0ePqlKlSrblzNQWFBSk7777Ls2pi99++822PTsEBQVp9+7dSklJsRuxyO7jpEpKSpJ0fXRQks6dO6e1a9fqjTfe0GuvvWZrd/Prnqp06dJ6/vnn9fzzzysuLk7333+/3nzzTYWHh9tOJXp5eSk0NDRb63ZU5cqVtWfPntu2yeh7EBQUpLVr1+rixYt2f9AOHDhgt7/UnzlXV9dsfx3atWunL7/8Up999pleeeWVNNsTEhL09ddfq1q1arbwVbx4cUlK8xlJbzTyTp8RZ30eb9SjRw+9+uqr2r17t+bOnavg4GDbFW6StGjRIj388MP65JNP7J53/vx5lSxZ8rb7Ll68eLqnv29+rSpXrqzvvvtOTZo0yVCobdy4sRo3bqw333xTc+fOVY8ePTRv3jw99dRTd3wusoZTaXDIunXrNG7cOFWsWPG29wFJ747JqSMDqUPDqfdfudUlzJn12Wef2Z06WLRokU6ePKnw8HDbusqVK+vHH3/U1atXbeuWLVuW5jLizNTWtm1bJScn61//+pfd+qlTp8rFxcXu+FnRtm1bxcTEaP78+bZ1SUlJeu+99+Th4aHmzZtny3FSpV7VVLduXUn/P+py8/+Sb777cXJycprTEH5+fgoMDLS99/Xr11flypU1efJkW/C60alTp7KlD5nRqVMn7dq1S0uWLEmzLbXPGX0P2rZtq6SkJH3wwQe2dsnJyXrvvffs9uvn56cWLVroww8/1MmTJ9McNyuvQ+fOnVWjRg1NmDBB27Zts9uWkpKi5557TufOnbO7CWhqYN20aZNd3f/+97/T7L9YsWK3Pd3krM/jjVJ/R7322mvauXNnmt9ZBQsWTPPzvHDhwjTzutJTuXJl/fbbb3bv0a5du9LcbqJLly5KTk7WuHHj0uwjKSnJ1qdz586lqeXm35nIWYwY4Y5WrFih3377TUlJSYqNjdW6deu0Zs0aBQUFaenSpSpcuPAtnzt27Fht2rRJERERCgoKUlxcnN5//32VLVtWTZs2lXT9F4uPj49mzpwpT09PFStWTI0aNcrwHIqb+fr6qmnTpurbt69iY2M1bdo0ValSxe6WAk899ZQWLVqkNm3aqEuXLjp06JA+//xzu8nQma2tffv2evjhh/Xyyy/ryJEjqlu3rlavXq2vv/5agwcPTrNvR/Xv318ffvih+vTpo+3bt6tChQpatGiRtmzZomnTpmVpnshff/1luy/V1atXtWvXLn344YcqWbKk7TSal5eXHnroIU2cOFHXrl1TmTJltHr1ah0+fNhuXxcuXFDZsmXVuXNn1a1bVx4eHvruu+/0888/65133pF0fTTx448/Vnh4uGrWrKm+ffuqTJky+uuvv7R+/Xp5eXnZgtnt/PLLL3b300pVuXJlhYSEZOo1GDFihBYtWqS///3v6tevn+rXr6+zZ89q6dKlmjlzpurWrZvh96B9+/Zq0qSJRo4cqSNHjqhGjRpavHhxukFixowZatq0qWrXrq2nn35alSpVUmxsrKKionT8+PEM3VMnPW5ublq0aJFatWpl+1yk3vl67ty5+uWXXzRs2DB17drV9pyaNWuqcePGGjVqlM6ePStfX1/NmzfPNnp4o/r162v+/PkaOnSoHnjgAXl4eKh9+/a27c76PN6oYsWKevDBB/X1119LUppg1K5dO40dO1Z9+/bVgw8+qF9//VVffPGF3WjVrfTr109TpkxRWFiYIiMjFRcXp5kzZ6pmzZp2k9mbN2+uZ555RuPHj9fOnTvVunVrubq66uDBg1q4cKGmT5+uzp07a86cOXr//ff1+OOPq3Llyrpw4YI++ugjeXl5pXt3d+QA51wMh/wg9ZLd1Iebm5sJCAgwjzzyiJk+fbrdJbipbr5cf+3ataZDhw4mMDDQuLm5mcDAQNOtWzfz+++/2z3v66+/NjVq1DCFChWyuxy2efPmpmbNmunWd6vL9b/88kszatQo4+fnZ4oUKWIiIiLM0aNH0zz/nXfeMWXKlDHu7u6mSZMmZtu2beleenur2m6+HNcYYy5cuGCGDBliAgMDjaurqwkODjaTJk2yuxTdmOuX66d3GfutLlu+WWxsrOnbt68pWbKkcXNzM7Vr1073EuasXK5foEAB4+fnZ7p162Z3WwFjjDl+/Lh5/PHHjY+Pj/H29jZ///vfzYkTJ4wkM2bMGGOMMYmJiWbEiBGmbt26xtPT0xQrVszUrVvXvP/++2mOvWPHDtOxY0dTokQJ4+7uboKCgkyXLl3M2rVrb1vznS7Xv/G1vNVrkd57fubMGTNw4EBTpkwZ4+bmZsqWLWt69+5td9uCjL4HZ86cMT179jReXl7G29vb9OzZ0+zYsSPdy84PHTpkevXqZQICAoyrq6spU6aMadeunVm0aJGtTUZuo5GeuLg4M3ToUFOlShXj7u5ufHx8TGhoqO0S/ZsdOnTIhIaGGnd3d+Pv729Gjx5t1qxZk+Zy/YsXL5ru3bsbHx8fI8n2mcjtz+OdzJgxw0gyDRs2TLPtypUrZtiwYaZ06dKmSJEipkmTJiYqKirN8dO7XN8YYz7//HNTqVIl4+bmZurVq2dWrVqV7u8HY4z597//berXr2+KFCliPD09Te3atc0//vEPc+LECWOMMb/88ovp1q2bKV++vHF3dzd+fn6mXbt2Ztu2bRnqJ7LOxZg8NtMTAJDvbdiwQQ8//LAWLlyozp07O7scIMOYYwQAAGAhGAEAAFgIRgAAABbmGAEAAFgYMQIAALAQjAAAACzc4FHX7/564sQJeXp6ZvvXUwAAgJxhjNGFCxcUGBiY5kudHUUwknTixAmVK1fO2WUAAAAH/Pnnnypbtmy27ItgJNlu3//nn3/Ky8vLydUAAICMSEhIULly5bL0VUg3Ixjp/7+x2cvLi2AEAEA+k53TYJh8DQAAYCEYAQAAWAhGAAAAFoIRAACAhWAEAABgIRgBAABYCEYAAAAWpwajDz74QHXq1LHdPygkJEQrVqywbb9y5YoGDBigEiVKyMPDQ506dVJsbKzdPo4dO6aIiAgVLVpUfn5+GjFihJKSknK7KwAA4C7g1GBUtmxZTZgwQdu3b9e2bdvUsmVLdejQQXv37pUkDRkyRN98840WLlyojRs36sSJE+rYsaPt+cnJyYqIiNDVq1f1ww8/aM6cOZo9e7Zee+01Z3UJAADkYy7GGOPsIm7k6+urSZMmqXPnzipVqpTmzp2rzp07S5J+++03Va9eXVFRUWrcuLFWrFihdu3a6cSJE/L395ckzZw5Uy+99JJOnTolNze3DB0zISFB3t7eio+P587XAADkEznx9zvPzDFKTk7WvHnzdOnSJYWEhGj79u26du2aQkNDbW2qVaum8uXLKyoqSpIUFRWl2rVr20KRJIWFhSkhIcE26pSexMREJSQk2D0AAACcHox+/fVXeXh4yN3dXc8++6yWLFmiGjVqKCYmRm5ubvLx8bFr7+/vr5iYGElSTEyMXShK3Z667VbGjx8vb29v26NcuXLZ2ykAAJAvOT0YVa1aVTt37tTWrVv13HPPqXfv3tq3b1+OHnPUqFGKj4+3Pf78888cPR4AAMgfCjm7ADc3N1WpUkWSVL9+ff3888+aPn26nnjiCV29elXnz5+3GzWKjY1VQECAJCkgIEA//fST3f5Sr1pLbZMed3d3ubu7Z3NPAABAfuf0EaObpaSkKDExUfXr15erq6vWrl1r23bgwAEdO3ZMISEhkqSQkBD9+uuviouLs7VZs2aNvLy8VKNGjVyvHQAA5G9OHTEaNWqUwsPDVb58eV24cEFz587Vhg0btGrVKnl7eysyMlJDhw6Vr6+vvLy8NGjQIIWEhKhx48aSpNatW6tGjRrq2bOnJk6cqJiYGL3yyisaMGAAI0LAPaLCyOV3bHNkQkQuVALgbuDUYBQXF6devXrp5MmT8vb2Vp06dbRq1So98sgjkqSpU6eqQIEC6tSpkxITExUWFqb333/f9vyCBQtq2bJleu655xQSEqJixYqpd+/eGjt2rLO6BAAA8rE8dx8jZ+A+RkD+xYgRcO+6q+9jBAAA4GwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMBCMAIAALA4NRiNHz9eDzzwgDw9PeXn56fHHntMBw4csGvTokULubi42D2effZZuzbHjh1TRESEihYtKj8/P40YMUJJSUm52RUAAHAXKOTMg2/cuFEDBgzQAw88oKSkJI0ePVqtW7fWvn37VKxYMVu7p59+WmPHjrUtFy1a1Pbv5ORkRUREKCAgQD/88INOnjypXr16ydXVVW+99Vau9gcAAORvTg1GK1eutFuePXu2/Pz8tH37dj300EO29UWLFlVAQEC6+1i9erX27dun7777Tv7+/qpXr57GjRunl156Sa+//rrc3NxytA8AAODukafmGMXHx0uSfH197dZ/8cUXKlmypGrVqqVRo0bp8uXLtm1RUVGqXbu2/P39bevCwsKUkJCgvXv3pnucxMREJSQk2D0AAACcOmJ0o5SUFA0ePFhNmjRRrVq1bOu7d++uoKAgBQYGavfu3XrppZd04MABLV68WJIUExNjF4ok2ZZjYmLSPdb48eP1xhtv5FBPAABAfpVngtGAAQO0Z88eff/993br+/fvb/t37dq1Vbp0abVq1UqHDh1S5cqVHTrWqFGjNHToUNtyQkKCypUr51jhAADgrpEnTqUNHDhQy5Yt0/r161W2bNnbtm3UqJEkKTo6WpIUEBCg2NhYuzapy7eal+Tu7i4vLy+7BwAAgFNHjIwxGjRokJYsWaINGzaoYsWKd3zOzp07JUmlS5eWJIWEhOjNN99UXFyc/Pz8JElr1qyRl5eXatSokWO1A8h5FUYud3YJAO4xTg1GAwYM0Ny5c/X111/L09PTNifI29tbRYoU0aFDhzR37ly1bdtWJUqU0O7duzVkyBA99NBDqlOnjiSpdevWqlGjhnr27KmJEycqJiZGr7zyigYMGCB3d3dndg8AAOQzTj2V9sEHHyg+Pl4tWrRQ6dKlbY/58+dLktzc3PTdd9+pdevWqlatmoYNG6ZOnTrpm2++se2jYMGCWrZsmQoWLKiQkBA9+eST6tWrl919jwAAADLC6afSbqdcuXLauHHjHfcTFBSkb7/9NrvKAgAA96g8MfkaAAAgLyAYAQAAWAhGAAAAFoIRAACAhWAEAABgIRgBAABYCEYAAAAWghEAAICFYAQAAGAhGAEAAFic+pUgAJAbKoxcfsc2RyZE5EIlAPI6RowAAAAsjBgBALJFdo3MMcIHZ2LECAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALN3gEAOSajNy8EXAmRowAAAAsBCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACw8CWyAIA74stfca9gxAgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMDi1GA0fvx4PfDAA/L09JSfn58ee+wxHThwwK7NlStXNGDAAJUoUUIeHh7q1KmTYmNj7docO3ZMERERKlq0qPz8/DRixAglJSXlZlcAAMBdoJAzD75x40YNGDBADzzwgJKSkjR69Gi1bt1a+/btU7FixSRJQ4YM0fLly7Vw4UJ5e3tr4MCB6tixo7Zs2SJJSk5OVkREhAICAvTDDz/o5MmT6tWrl1xdXfXWW285s3sAbqPCyOXOLgEA0nAxxhhnF5Hq1KlT8vPz08aNG/XQQw8pPj5epUqV0ty5c9W5c2dJ0m+//abq1asrKipKjRs31ooVK9SuXTudOHFC/v7+kqSZM2fqpZde0qlTp+Tm5nbH4yYkJMjb21vx8fHy8vLK0T4CuC6vBaMjEyKcXUKexvuFvCgn/n7nqTlG8fHxkiRfX19J0vbt23Xt2jWFhoba2lSrVk3ly5dXVFSUJCkqKkq1a9e2hSJJCgsLU0JCgvbu3ZuL1QMAgPzOqafSbpSSkqLBgwerSZMmqlWrliQpJiZGbm5u8vHxsWvr7++vmJgYW5sbQ1Hq9tRt6UlMTFRiYqJtOSEhIbu6AQAA8rE8M2I0YMAA7dmzR/PmzcvxY40fP17e3t62R7ly5XL8mAAAIO/LE8Fo4MCBWrZsmdavX6+yZcva1gcEBOjq1as6f/68XfvY2FgFBATY2tx8lVrqcmqbm40aNUrx8fG2x59//pmNvQEAAPmVU4ORMUYDBw7UkiVLtG7dOlWsWNFue/369eXq6qq1a9fa1h04cEDHjh1TSEiIJCkkJES//vqr4uLibG3WrFkjLy8v1ahRI93juru7y8vLy+4BAADg1DlGAwYM0Ny5c/X111/L09PTNifI29tbRYoUkbe3tyIjIzV06FD5+vrKy8tLgwYNUkhIiBo3bixJat26tWrUqKGePXtq4sSJiomJ0SuvvKIBAwbI3d3dmd0DAAD5jFOD0QcffCBJatGihd36WbNmqU+fPpKkqVOnqkCBAurUqZMSExMVFham999/39a2YMGCWrZsmZ577jmFhISoWLFi6t27t8aOHZtb3QAAAHcJpwajjNxCqXDhwpoxY4ZmzJhxyzZBQUH69ttvs7M0AABwD8oTk68BAADyAoIRAACAhWAEAABgIRgBAABYCEYAAAAWghEAAICFYAQAAGAhGAEAAFiceoNHAMgrKoxcfsc2RyZE5EIlAJyJESMAAAALwQgAAMBCMAIAALAQjAAAACwOBaM//vgju+sAAABwOoeCUZUqVfTwww/r888/15UrV7K7JgAAAKdwKBj98ssvqlOnjoYOHaqAgAA988wz+umnn7K7NgAAgFzlUDCqV6+epk+frhMnTujTTz/VyZMn1bRpU9WqVUtTpkzRqVOnsrtOAACAHJelydeFChVSx44dtXDhQr399tuKjo7W8OHDVa5cOfXq1UsnT57MrjoBAAByXJaC0bZt2/T888+rdOnSmjJlioYPH65Dhw5pzZo1OnHihDp06JBddQIAAOQ4h74SZMqUKZo1a5YOHDigtm3b6rPPPlPbtm1VoMD1nFWxYkXNnj1bFSpUyM5aAQAAcpRDweiDDz5Qv3791KdPH5UuXTrdNn5+fvrkk0+yVBwAAEBucigYHTx48I5t3Nzc1Lt3b0d2DwAA4BQOBaNZs2bJw8NDf//73+3WL1y4UJcvXyYQAQByVIWRy+/Y5siEiFyoBHcbhyZfjx8/XiVLlkyz3s/PT2+99VaWiwIAAHAGh4LRsWPHVLFixTTrg4KCdOzYsSwXBQAA4AwOBSM/Pz/t3r07zfpdu3apRIkSWS4KAADAGRwKRt26ddMLL7yg9evXKzk5WcnJyVq3bp1efPFFde3aNbtrBAAAyBUOTb4eN26cjhw5olatWqlQoeu7SElJUa9evZhjBAAA8i2HgpGbm5vmz5+vcePGadeuXSpSpIhq166toKCg7K4PAAAg1zgUjFLdd999uu+++7KrFgAAAKdyKBglJydr9uzZWrt2reLi4pSSkmK3fd26ddlSHAAAQG5yKBi9+OKLmj17tiIiIlSrVi25uLhkd10AAAC5zqFgNG/ePC1YsEBt27bN7noAAACcxqHL9d3c3FSlSpXsrgUAAMCpHApGw4YN0/Tp02WMye56AAAAnMahU2nff/+91q9frxUrVqhmzZpydXW127548eJsKQ4AACA3ORSMfHx89Pjjj2d3LQAAAE7lUDCaNWtWdtcBAADgdA7f4DEpKUkbNmzQoUOH1L17d3l6eurEiRPy8vKSh4dHdtYIAMhBFUYud3YJQJ7hUDA6evSo2rRpo2PHjikxMVGPPPKIPD099fbbbysxMVEzZ87M7joBAABynENXpb344otq0KCBzp07pyJFitjWP/7441q7dm22FQcAAJCbHBox2rx5s3744Qe5ubnZra9QoYL++uuvbCkMAAAgtzk0YpSSkqLk5OQ0648fPy5PT88sFwUAAOAMDgWj1q1ba9q0abZlFxcXXbx4UWPGjOFrQgAAQL7l0Km0d955R2FhYapRo4auXLmi7t276+DBgypZsqS+/PLL7K4RAAAgVzgUjMqWLatdu3Zp3rx52r17ty5evKjIyEj16NHDbjI2AABAfuLwfYwKFSqkJ598MjtrAQAAcCqHgtFnn3122+29evVyqBgAAABncigYvfjii3bL165d0+XLl+Xm5qaiRYsSjAAAQL7kUDA6d+5cmnUHDx7Uc889pxEjRmR4P5s2bdKkSZO0fft2nTx5UkuWLNFjjz1m296nTx/NmTPH7jlhYWFauXKlbfns2bMaNGiQvvnmGxUoUECdOnXS9OnT+VoSANkuI1+dcWRCRC5UAiCnOHS5fnqCg4M1YcKENKNJt3Pp0iXVrVtXM2bMuGWbNm3a6OTJk7bHzVe99ejRQ3v37tWaNWu0bNkybdq0Sf3793e4HwAA4N7l8OTrdHdWqJBOnDiR4fbh4eEKDw+/bRt3d3cFBASku23//v1auXKlfv75ZzVo0ECS9N5776lt27aaPHmyAgMDM148AAC45zkUjJYuXWq3bIzRyZMn9a9//UtNmjTJlsJSbdiwQX5+fipevLhatmypf/7znypRooQkKSoqSj4+PrZQJEmhoaEqUKCAtm7dqscffzzdfSYmJioxMdG2nJCQkK01AwCA/MmhYHTjPCDp+p2vS5UqpZYtW+qdd97JjrokXT+N1rFjR1WsWFGHDh3S6NGjFR4erqioKBUsWFAxMTHy8/Oze06hQoXk6+urmJiYW+53/PjxeuONN7KtTgAAcHdwKBilpKRkdx3p6tq1q+3ftWvXVp06dVS5cmVt2LBBrVq1cni/o0aN0tChQ23LCQkJKleuXJZqBQDkLUyWhyOybfJ1bqhUqZJKliyp6OhoSVJAQIDi4uLs2iQlJens2bO3nJckXZ+35OXlZfcAAABwaMToxtGWO5kyZYojh0jX8ePHdebMGZUuXVqSFBISovPnz2v79u2qX7++JGndunVKSUlRo0aNsu24AADg3uBQMNqxY4d27Niha9euqWrVqpKk33//XQULFtT9999va+fi4nLb/Vy8eNE2+iNJhw8f1s6dO+Xr6ytfX1+98cYb6tSpkwICAnTo0CH94x//UJUqVRQWFiZJql69utq0aaOnn35aM2fO1LVr1zRw4EB17dqVK9IAAECmORSM2rdvL09PT82ZM0fFixeXdP2mj3379lWzZs00bNiwDO1n27Ztevjhh23LqSNRvXv31gcffKDdu3drzpw5On/+vAIDA9W6dWuNGzdO7u7utud88cUXGjhwoFq1amW7weO7777rSLcAAMA9zsUYYzL7pDJlymj16tWqWbOm3fo9e/aodevWmbqXUV6QkJAgb29vxcfHM98IyCUZmRibH+XHybx363uREfnx/cL/y4m/3w6NGCUkJOjUqVNp1p86dUoXLlzIclEAgOxxL4cewBEOBaPHH39cffv21TvvvKOGDRtKkrZu3aoRI0aoY8eO2VoggPyHP8YA8iuHgtHMmTM1fPhwde/eXdeuXbu+o0KFFBkZqUmTJmVrgQAAALnFoWBUtGhRvf/++5o0aZIOHTokSapcubKKFSuWrcUBAADkpizd4DH1G++Dg4NVrFgxOTCPGwAAIM9wKBidOXNGrVq10n333ae2bdvq5MmTkqTIyMgMX6oPAACQ1zgUjIYMGSJXV1cdO3ZMRYsWta1/4okntHLlymwrDgAAIDc5NMdo9erVWrVqlcqWLWu3Pjg4WEePHs2WwgAAAHKbQyNGly5dshspSnX27Fm7u1IDAADkJw4Fo2bNmumzzz6zLbu4uCglJUUTJ060+4oPAACA/MShU2kTJ05Uq1attG3bNl29elX/+Mc/tHfvXp09e1ZbtmzJ7hoBAAByhUMjRrVq1dLvv/+upk2bqkOHDrp06ZI6duyoHTt2qHLlytldIwAAQK7I9IjRtWvX1KZNG82cOVMvv/xyTtQEIJMy8hUcfFkmANxZpkeMXF1dtXv37pyoBQAAwKkcOpX25JNP6pNPPsnuWgAAAJzKocnXSUlJ+vTTT/Xdd9+pfv36ab4jbcqUKdlSHAAAQG7KVDD6448/VKFCBe3Zs0f333+/JOn333+3a+Pi4pJ91QEAAOSiTAWj4OBgnTx5UuvXr5d0/StA3n33Xfn7++dIcQAAALkpU3OMjDF2yytWrNClS5eytSAAAABncWjydaqbgxIAAEB+lqlg5OLikmYOEXOKAADA3SJTc4yMMerTp4/ti2KvXLmiZ599Ns1VaYsXL86+CgEAAHJJpoJR79697ZaffPLJbC0GAADAmTIVjGbNmpVTdQAAADhdliZfAwAA3E0IRgAAABaCEQAAgIVgBAAAYCEYAQAAWAhGAAAAFoIRAACAJVP3MQIA3F6Fkcvv2ObIhIhcqASAIxgxAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMDCDR4BZEpGbmAIAPkVI0YAAAAWghEAAICFU2kAkE9xWjPr+G473IwRIwAAAAvBCAAAwEIwAgAAsDDHCLhHMJcCAO7MqSNGmzZtUvv27RUYGCgXFxd99dVXdtuNMXrttddUunRpFSlSRKGhoTp48KBdm7Nnz6pHjx7y8vKSj4+PIiMjdfHixVzsBQAAuFs4NRhdunRJdevW1YwZM9LdPnHiRL377ruaOXOmtm7dqmLFiiksLExXrlyxtenRo4f27t2rNWvWaNmyZdq0aZP69++fW10AAAB3EaeeSgsPD1d4eHi624wxmjZtml555RV16NBBkvTZZ5/J399fX331lbp27ar9+/dr5cqV+vnnn9WgQQNJ0nvvvae2bdtq8uTJCgwMzLW+AACA/C/PTr4+fPiwYmJiFBoaalvn7e2tRo0aKSoqSpIUFRUlHx8fWyiSpNDQUBUoUEBbt2695b4TExOVkJBg9wAAAMizwSgmJkaS5O/vb7fe39/fti0mJkZ+fn522wsVKiRfX19bm/SMHz9e3t7etke5cuWyuXoAAJAf5dlglJNGjRql+Ph42+PPP/90dkkAACAPyLPBKCAgQJIUGxtrtz42Nta2LSAgQHFxcXbbk5KSdPbsWVub9Li7u8vLy8vuAQAAkGeDUcWKFRUQEKC1a9fa1iUkJGjr1q0KCQmRJIWEhOj8+fPavn27rc26deuUkpKiRo0a5XrNAAAgf3PqVWkXL15UdHS0bfnw4cPauXOnfH19Vb58eQ0ePFj//Oc/FRwcrIoVK+rVV19VYGCgHnvsMUlS9erV1aZNGz399NOaOXOmrl27poEDB6pr165ckQYAADLNqcFo27Ztevjhh23LQ4cOlST17t1bs2fP1j/+8Q9dunRJ/fv31/nz59W0aVOtXLlShQsXtj3niy++0MCBA9WqVSsVKFBAnTp10rvvvpvrfQGA7JSRO5UDyH4uxhjj7CKcLSEhQd7e3oqPj2e+EfKl7PojmpGvBOEPNu41fFVO3pUTf7/z7BwjAACA3EYwAgAAsBCMAAAALE6dfA3g9pjPAwC5i2AE5ICMBBomdAJA3sOpNAAAAAvBCAAAwMKpNMBJmD8EAHkPI0YAAAAWRowA2DCKBeBex4gRAACAhWAEAABgIRgBAABYCEYAAAAWghEAAICFYAQAAGAhGAEAAFgIRgAAABaCEQAAgIVgBAAAYCEYAQAAWAhGAAAAFoIRAACAhWAEAABgIRgBAABYCEYAAACWQs4uAACAvKzCyOV3bHNkQkQuVILcwIgRAACAhWAEAABg4VQaAABZxOm2uwcjRgAAABaCEQAAgIVgBAAAYCEYAQAAWAhGAAAAFoIRAACAhWAEAABgIRgBAABYCEYAAAAWghEAAICFYAQAAGAhGAEAAFj4ElncFfgCRwBAdmDECAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADAkqeD0euvvy4XFxe7R7Vq1Wzbr1y5ogEDBqhEiRLy8PBQp06dFBsb68SKAQBAfpbnL9evWbOmvvvuO9tyoUL/X/KQIUO0fPlyLVy4UN7e3ho4cKA6duyoLVu2OKPUewqXxwMA7kZ5PhgVKlRIAQEBadbHx8frk08+0dy5c9WyZUtJ0qxZs1S9enX9+OOPaty4cW6XCgAA8rk8fSpNkg4ePKjAwEBVqlRJPXr00LFjxyRJ27dv17Vr1xQaGmprW61aNZUvX15RUVG33WdiYqISEhLsHgAAAHk6GDVq1EizZ8/WypUr9cEHH+jw4cNq1qyZLly4oJiYGLm5ucnHx8fuOf7+/oqJibntfsePHy9vb2/bo1y5cjnYCwAAkF/k6VNp4eHhtn/XqVNHjRo1UlBQkBYsWKAiRYo4vN9Ro0Zp6NChtuWEhATCEQAAyNvB6GY+Pj667777FB0drUceeURXr17V+fPn7UaNYmNj052TdCN3d3e5u7vncLXZi8nOAADkvHwVjC5evKhDhw6pZ8+eql+/vlxdXbV27Vp16tRJknTgwAEdO3ZMISEhTq4UEmEOAJD/5OlgNHz4cLVv315BQUE6ceKExowZo4IFC6pbt27y9vZWZGSkhg4dKl9fX3l5eWnQoEEKCQnhijQAAOCQPB2Mjh8/rm7duunMmTMqVaqUmjZtqh9//FGlSpWSJE2dOlUFChRQp06dlJiYqLCwML3//vtOrhoAAORXeToYzZs377bbCxcurBkzZmjGjBm5VBEAAI5hekH+kKcv1wcAAMhNeXrECJnD/0ZyR0ZeZwBA/kQwAgDgLsN/lB1HMAIAIB9h1DpnMccIAADAwogRnIrhXgBAXsKIEQAAgIVgBAAAYCEYAQAAWAhGAAAAFiZf5wFcegkAQN7AiBEAAICFYAQAAGAhGAEAAFiYYwQAwD2IG+ymj2AE3ICJ8ABwbyMY4Z5B6AGQ1/F7yvmYYwQAAGBhxAh5Hv+DAgDkFkaMAAAALIwYIQ1GaAAA9ypGjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALXwlyj+HrPgAAGZWRvxlHJkTkQiW5hxEjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwMJXguQwvoIDAID8gxEjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAADLXXNV2owZMzRp0iTFxMSobt26eu+999SwYUNnlwUAwF0tI1dfH5kQkQuVZI+7YsRo/vz5Gjp0qMaMGaNffvlFdevWVVhYmOLi4pxdGgAAyEfuimA0ZcoUPf300+rbt69q1KihmTNnqmjRovr000+dXRoAAMhH8n0wunr1qrZv367Q0FDbugIFCig0NFRRUVFOrAwAAOQ3+X6O0enTp5WcnCx/f3+79f7+/vrtt9/SfU5iYqISExNty/Hx8ZKkhISEbK8vJfFytu8TAID8JCf+vt64X2NMtu0z3wcjR4wfP15vvPFGmvXlypVzQjUAANzdvKfl7P4vXLggb2/vbNlXvg9GJUuWVMGCBRUbG2u3PjY2VgEBAek+Z9SoURo6dKhtOSUlRWfPnlWJEiXk4uKSo/VmVEJCgsqVK6c///xTXl5ezi4nR9DHu8e90E/6ePe4F/p5L/Vx3759CgwMzLb95vtg5Obmpvr162vt2rV67LHHJF0POmvXrtXAgQPTfY67u7vc3d3t1vn4+ORwpY7x8vK6a3+oU9HHu8e90E/6ePe4F/p5L/SxTJkyKlAg+6ZM5/tgJElDhw5V79691aBBAzVs2FDTpk3TpUuX1LdvX2eXBgAA8pG7Ihg98cQTOnXqlF577TXFxMSoXr16WrlyZZoJ2QAAALdzVwQjSRo4cOAtT53lR+7u7hozZkyaU353E/p497gX+kkf7x73Qj/po+NcTHZe4wYAAJCP5fsbPAIAAGQXghEAAICFYAQAAGAhGAEAAFgIRnnI2bNn1aNHD3l5ecnHx0eRkZG6ePFihp5rjFF4eLhcXFz01Vdf5WyhWeBIH5955hlVrlxZRYoUUalSpdShQ4dbfg9eXpDZPp49e1aDBg1S1apVVaRIEZUvX14vvPCC7Tv88iJH3sd///vfatGihby8vOTi4qLz58/nTrGZMGPGDFWoUEGFCxdWo0aN9NNPP922/cKFC1WtWjUVLlxYtWvX1rfffptLlTouM33cu3evOnXqpAoVKsjFxUXTpk3LvUKzKDP9/Oijj9SsWTMVL15cxYsXV2ho6B3f+7wgM31cvHixGjRoIB8fHxUrVkz16tXTf/7zn1ys1jGZ/UymmjdvnlxcXGw3fs4UgzyjTZs2pm7duubHH380mzdvNlWqVDHdunXL0HOnTJliwsPDjSSzZMmSnC00Cxzp44cffmg2btxoDh8+bLZv327at29vypUrZ5KSknKp6szJbB9//fVX07FjR7N06VITHR1t1q5da4KDg02nTp1yserMceR9nDp1qhk/frwZP368kWTOnTuXO8Vm0Lx584ybm5v59NNPzd69e83TTz9tfHx8TGxsbLrtt2zZYgoWLGgmTpxo9u3bZ1555RXj6upqfv3111yuPOMy28effvrJDB8+3Hz55ZcmICDATJ06NXcLdlBm+9m9e3czY8YMs2PHDrN//37Tp08f4+3tbY4fP57LlWdcZvu4fv16s3jxYrNv3z4THR1tpk2bZgoWLGhWrlyZy5VnXGb7mOrw4cOmTJkyplmzZqZDhw6ZPi7BKI/Yt2+fkWR+/vln27oVK1YYFxcX89dff932uTt27DBlypQxJ0+ezNPBKCt9vNGuXbuMJBMdHZ0TZWZJdvVxwYIFxs3NzVy7di0nysySrPZx/fr1eTIYNWzY0AwYMMC2nJycbAIDA8348ePTbd+lSxcTERFht65Ro0bmmWeeydE6syKzfbxRUFBQvglGWemnMcYkJSUZT09PM2fOnJwqMcuy2kdjjPnb3/5mXnnllZwoL1s40sekpCTz4IMPmo8//tj07t3boWDEqbQ8IioqSj4+PmrQoIFtXWhoqAoUKKCtW7fe8nmXL19W9+7dNWPGjFt+aW5e4Wgfb3Tp0iXNmjVLFStWVLly5XKqVIdlRx8lKT4+Xl5eXipUKO/dgzW7+piXXL16Vdu3b1doaKhtXYECBRQaGqqoqKh0nxMVFWXXXpLCwsJu2d7ZHOljfpQd/bx8+bKuXbsmX1/fnCozS7LaR2OM1q5dqwMHDuihhx7KyVId5mgfx44dKz8/P0VGRjp8bIJRHhETEyM/Pz+7dYUKFZKvr69iYmJu+bwhQ4bowQcfVIcOHXK6xCxztI+S9P7778vDw0MeHh5asWKF1qxZIzc3t5ws1yFZ6WOq06dPa9y4cerfv39OlJhl2dHHvOb06dNKTk5O8zVC/v7+t+xTTExMpto7myN9zI+yo58vvfSSAgMD0wTfvMLRPsbHx8vDw0Nubm6KiIjQe++9p0ceeSSny3WII338/vvv9cknn+ijjz7K0rEJRjls5MiRcnFxue3D0YnES5cu1bp165w+ITIn+5iqR48e2rFjhzZu3Kj77rtPXbp00ZUrV7KpB3eWG32UpISEBEVERKhGjRp6/fXXs154JuRWH4G8bMKECZo3b56WLFmiwoULO7ucbOXp6amdO3fq559/1ptvvqmhQ4dqw4YNzi4rW1y4cEE9e/bURx99pJIlS2ZpX3lvnP4uM2zYMPXp0+e2bSpVqqSAgADFxcXZrU9KStLZs2dveYps3bp1OnTokHx8fOzWd+rUSc2aNcu1H/ic7GMqb29veXt7Kzg4WI0bN1bx4sW1ZMkSdevWLavlZ0hu9PHChQtq06aNPD09tWTJErm6uma17EzJjT7mVSVLllTBggUVGxtrtz42NvaWfQoICMhUe2dzpI/5UVb6OXnyZE2YMEHfffed6tSpk5NlZomjfSxQoICqVKkiSapXr57279+v8ePHq0WLFjlZrkMy28dDhw7pyJEjat++vW1dSkqKpOsj2gcOHFDlypUzdnAH5kMhB6ROaN22bZtt3apVq247ofXkyZPm119/tXtIMtOnTzd//PFHbpWeYY70MT1XrlwxRYoUMbNmzcqBKrPG0T7Gx8ebxo0bm+bNm5tLly7lRqkOy+r7mJcnXw8cONC2nJycbMqUKXPbydft2rWzWxcSEpLnJ19npo83ym+TrzPbz7ffftt4eXmZqKio3Cgxy7LyXqbq27evad68eQ5Ulz0y08f//e9/af4edujQwbRs2dL8+uuvJjExMcPHJRjlIW3atDF/+9vfzNatW833339vgoOD7S6BPn78uKlatarZunXrLfehPHxVmjGZ7+OhQ4fMW2+9ZbZt22aOHj1qtmzZYtq3b298fX3veMmms2S2j/Hx8aZRo0amdu3aJjo62pw8edL2yMu3JMjsz+rJkyfNjh07zEcffWQkmU2bNpkdO3aYM2fOOKMLacybN8+4u7ub2bNnm3379pn+/fsbHx8fExMTY4wxpmfPnmbkyJG29lu2bDGFChUykydPNvv37zdjxozJF5frZ6aPiYmJZseOHWbHjh2mdOnSZvjw4WbHjh3m4MGDzupChmS2nxMmTDBubm5m0aJFdp+/CxcuOKsLd5TZPr711ltm9erV5tChQ2bfvn1m8uTJplChQuajjz5yVhfuKLN9vJmjV6URjPKQM2fOmG7duhkPDw/j5eVl+vbta/fBPHz4sJFk1q9ff8t95PVglNk+/vXXXyY8PNz4+fkZV1dXU7ZsWdO9e3fz22+/OakHd5bZPqaOoKT3OHz4sHM6cQeO/KyOGTMm3T7mpZG/9957z5QvX964ubmZhg0bmh9//NG2rXnz5qZ379527RcsWGDuu+8+4+bmZmrWrGmWL1+eyxVnXmb6mPo+3vzIy6MMqTLTz6CgoHT7OWbMmNwvPBMy08eXX37ZVKlSxRQuXNgUL17chISEmHnz5jmh6szJ7GfyRo4GIxdjjMnYSTcAAIC7G1elAQAAWAhGAAAAFoIRAACAhWAEAABgIRgBAABYCEYAAAAWghEAAICFYATgrtWiRQsNHjzY2WUAyEcIRgDypPbt26tNmzbpbtu8ebNcXFy0e/fuXK4KwN2OYAQgT4qMjNSaNWt0/PjxNNtmzZqlBg0a5OlvQAeQPxGMAORJ7dq1U6lSpTR79my79RcvXtTChQv12GOPqVu3bipTpoyKFi2q2rVr68svv7ztPl1cXPTVV1/ZrfPx8bE7xp9//qkuXbrIx8dHvr6+6tChg44cOZI9nQKQ5xGMAORJhQoVUq9evTR79mzd+JWOCxcuVHJysp588knVr19fy5cv1549e9S/f3/17NlTP/30k8PHvHbtmsLCwuTp6anNmzdry5Yt8vDwUJs2bXT16tXs6BaAPI5gBCDP6tevnw4dOqSNGzfa1s2aNUudOnVSUFCQhg8frnr16qlSpUoaNGiQ2rRpowULFjh8vPnz5yslJUUff/yxateurerVq2vWrFk6duyYNmzYkA09ApDXEYwA5FnVqlXTgw8+qE8//VSSFB0drc2bNysyMlLJyckaN26cateuLV9fX3l4eGjVqlU6duyYw8fbtWuXoqOj5enpKQ8PD3l4eMjX11dXrlzRoUOHsqtbAPKwQs4uAABuJzIyUoMGDdKMGTM0a9YsVa5cWc2bN9fbb7+t6dOna9q0aapdu7aKFSumwYMH3/aUl4uLi91pOen66bNUFy9eVP369fXFF1+keW6pUqWyr1MA8iyCEYA8rUuXLnrxxRc1d+5cffbZZ3ruuefk4uKiLVu2qEOHDnryySclSSkpKfr9999Vo0aNW+6rVKlSOnnypG354MGDunz5sm35/vvv1/z58+Xn5ycvL6+c6xSAPItTaQDyNA8PDz3xxBMaNWqUTp48qT59+kiSgoODtWbNGv3www/av3+/nnnmGcXGxt52Xy1bttS//vUv7dixQ9u2bdOzzz4rV1dX2/YePXqoZMmS6tChgzZv3qzDhw9rw4YNeuGFF9K9bQCAuw/BCECeFxkZqXPnziksLEyBgYGSpFdeeUX333+/wsLC1KJFCwUEBOixxx677X7eeecdlStXTs2aNVP37t01fPhwFS1a1La9aNGi2rRpk8qXL6+OHTuqevXqioyM1JUrVxhBAu4RLubmE+4AAAD3KEaMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsPwfA4TOh/xDp0kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "class BaseEncoder(nn.Module):\n",
    "    def __init__(self, num_channels=62, spatial_filters=16, temporal_filters=16, temporal_kernel_size=48):\n",
    "        super(BaseEncoder, self).__init__()\n",
    "\n",
    "        # Spatial Convolution\n",
    "        self.spatial_conv = nn.Conv1d(\n",
    "            in_channels=num_channels,\n",
    "            out_channels=spatial_filters,\n",
    "            kernel_size=1\n",
    "        )\n",
    "\n",
    "        # Temporal Convolution\n",
    "        self.temporal_kernel_size = temporal_kernel_size\n",
    "        self.temporal_conv = nn.Conv1d(\n",
    "            in_channels=spatial_filters,\n",
    "            out_channels=temporal_filters,\n",
    "            kernel_size=temporal_kernel_size\n",
    "        )\n",
    "\n",
    "        # Batch Normalization (if you had this in your original code)\n",
    "        self.batch_norm = nn.BatchNorm1d(temporal_filters)\n",
    "\n",
    "        # Dropout (if you had this in your original code)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Activation Function\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "        # Additional Temporal Convolution Layer (if applicable)\n",
    "        self.extra_temporal_conv = nn.Conv1d(\n",
    "            in_channels=temporal_filters,\n",
    "            out_channels=temporal_filters,\n",
    "            kernel_size=3,\n",
    "            padding=1  # To maintain the length\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, num_timepoints]\n",
    "\n",
    "        # Spatial Convolution\n",
    "        x = self.spatial_conv(x)  # Shape: [batch_size, spatial_filters, num_timepoints]\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Apply asymmetric padding manually before temporal convolution\n",
    "        left_pad = (self.temporal_kernel_size - 1) // 2\n",
    "        right_pad = self.temporal_kernel_size // 2\n",
    "        x = F.pad(x, (left_pad, right_pad))  # Apply padding: (left, right)\n",
    "\n",
    "        # Temporal Convolution\n",
    "        x = self.temporal_conv(x)  # Shape: [batch_size, temporal_filters, num_timepoints]\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Batch Normalization\n",
    "        x = self.batch_norm(x)\n",
    "\n",
    "        # Dropout\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Additional Temporal Convolution (if applicable)\n",
    "        x = self.extra_temporal_conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x  # Final output shape: [batch_size, temporal_filters, num_timepoints]\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Reshape Function for DE Features\n",
    "# ---------------------------------------------------------------\n",
    "def reshape_for_encoder(segment, num_channels=62):\n",
    "    \"\"\"\n",
    "    Reshape flattened differential entropy features to [batch_size, num_channels, num_timepoints].\n",
    "    \"\"\"\n",
    "    batch_size = segment.shape[0]\n",
    "    num_timepoints = segment.shape[1] // num_channels\n",
    "    return segment.view(batch_size, num_channels, num_timepoints)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Test the Base Encoder\n",
    "# ---------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example input tensors\n",
    "    batch_size = 8\n",
    "    num_channels = 62\n",
    "    num_timepoints = 200  # Adjust this based on your DE feature extraction length\n",
    "\n",
    "    # Create dummy DE features with shape: [batch_size, num_channels * num_timepoints]\n",
    "    segments_a = torch.rand((batch_size, num_channels * num_timepoints))\n",
    "    segments_b = torch.rand((batch_size, num_channels * num_timepoints))\n",
    "\n",
    "    # Reshape DE features to [batch_size, num_channels, num_timepoints]\n",
    "    segments_a_reshaped = reshape_for_encoder(segments_a, num_channels)\n",
    "    segments_b_reshaped = reshape_for_encoder(segments_b, num_channels)\n",
    "\n",
    "    # Initialize the Base Encoder\n",
    "    base_encoder = BaseEncoder(num_channels=num_channels)\n",
    "\n",
    "    # Forward pass for segments_a and segments_b\n",
    "    output_a = base_encoder(segments_a_reshaped)\n",
    "    output_b = base_encoder(segments_b_reshaped)\n",
    "\n",
    "    print(f\"Input A Shape: {segments_a_reshaped.shape}\")  # Expected: [batch_size, num_channels, num_timepoints]\n",
    "    print(f\"Input B Shape: {segments_b_reshaped.shape}\")  # Expected: [batch_size, num_channels, num_timepoints]\n",
    "    print(f\"Output A Shape: {output_a.shape}\")            # Expected: [batch_size, temporal_filters, num_timepoints]\n",
    "    print(f\"Output B Shape: {output_b.shape}\")            # Expected: [batch_size, temporal_filters, num_timepoints]\n",
    "            # Calculate statistics\n",
    "    print(f\"Output Mean: {output.mean().item():.4f}\")\n",
    "    print(f\"Output Std: {output.std().item():.4f}\")\n",
    "    print(f\"Output Min: {output.min().item():.4f}\")\n",
    "    print(f\"Output Max: {output.max().item():.4f}\")\n",
    "\n",
    "    # Plot the distribution of output values\n",
    "    plt.hist(output.detach().cpu().numpy().flatten(), bins=50)\n",
    "    plt.title(\"Distribution of Base Encoder Output Values\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded A Shape: torch.Size([8, 16, 200])\n",
      "Encoded B Shape: torch.Size([8, 16, 200])\n",
      "Projected A Shape: torch.Size([8, 640])\n",
      "Projected B Shape: torch.Size([8, 640])\n",
      "Loss: 0.0067\n",
      "Gradients for Base Encoder:\n",
      "spatial_conv.weight: grad norm = 0.0077\n",
      "spatial_conv.bias: grad norm = 0.0012\n",
      "temporal_conv.weight: grad norm = 0.0253\n",
      "temporal_conv.bias: grad norm = 0.0001\n",
      "batch_norm.weight: grad norm = 0.0031\n",
      "batch_norm.bias: grad norm = 0.0008\n",
      "extra_temporal_conv.weight: grad norm = 0.0123\n",
      "extra_temporal_conv.bias: grad norm = 0.0009\n",
      "\n",
      "Gradients for Projector:\n",
      "spatial_conv.weight: grad norm = 0.0064\n",
      "spatial_conv.bias: grad norm = 0.0017\n",
      "temporal_conv.weight: grad norm = 0.0099\n",
      "temporal_conv.bias: grad norm = 0.0015\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABD+klEQVR4nO3deXQUVf7+8adDFgjZCGQhLGEXUBYFhcgiSiRARJA4CrIbBf0CLoCjjIwgjiCiAqKCOso2ItuIjiA7CIqIgiyyiMCAAUnCJgnBIWS5vz886Z9NAiSdTrpTvF/n9Dn0rdtVn5t0yJNbt6ptxhgjAAAAi/JydwEAAAAlibADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADjzZu3DjZbLZSOVaHDh3UoUMH+/Mvv/xSNptNS5YsKZXjDxw4ULVq1SqVYzkrIyNDjzzyiCIjI2Wz2fTUU0+5uyTNnj1bNptNR48edXcp8EBl4ecKJY+wg1KT90sp71G+fHlFRUUpLi5Ob775ps6fP++S45w4cULjxo3Tzp07XbI/V/Lk2gpjwoQJmj17th5//HHNmzdP/fr1u2LfWrVqOXy/w8PD1a5dOy1durQUKy6+b775RuPGjdO5c+dK/djLli1T586dVblyZZUvX14NGjTQqFGjdObMGaf3Wdrvwfnz52vq1KnX7PfDDz/IZrNpzJgxV+xz8OBB2Ww2jRgxwoUV4rpggFIya9YsI8mMHz/ezJs3z3z44YdmwoQJplOnTsZms5no6Giza9cuh9dkZWWZ//3vf0U6zvfff28kmVmzZhXpdZmZmSYzM9P+fMOGDUaSWbx4cZH242xtly5dMhcvXnTZsUpCq1atTJs2bQrVNzo62jRv3tzMmzfPzJs3z0yaNMnUqVPHSDIzZsxwWU3Z2dnmf//7n8nNzXXZPv9s8uTJRpI5cuRIiez/SkaOHGkkmWbNmplJkyaZ999/3zz++OPGz8/PVKtWzfz0009O7dfZnw9nxcfHm+jo6EL1bdiwoalTp84Vt48bN85IMtu3by/08QcMGFDo48O6vN2WsnDd6tKli1q2bGl/Pnr0aK1fv1733HOP7r33Xu3fv18VKlSQJHl7e8vbu2Tfpr///rv8/f3l6+tbose5Fh8fH7cevzBOnjypxo0bF7p/tWrV1LdvX/vz/v37q169epoyZYoee+yxAl+TnZ2t3NzcQn8/ypUrp3LlyhW6Jk9gjNHFixft7/PLffzxx3r99df14IMP6qOPPnIY38CBA3XnnXfqL3/5i3744YcS//koTX369NHf//53ffvtt2rdunW+7R9//LEaNmyoW265xQ3VoUxzd9rC9SNvZuf7778vcPuECROMJPPee+/Z28aOHWsuf5uuXr3atGnTxgQHB5uKFSuaBg0amNGjRxtj/v9szOWPvL9i77jjDnPjjTeabdu2mXbt2pkKFSqYJ5980r7tjjvusB8nb18LFiwwo0ePNhEREcbf399069bNJCUlOdQUHR1tBgwYkG9Mf97ntWor6C/QjIwMM2LECFO9enXj6+trGjRoYCZPnpxvFkOSGTp0qFm6dKm58cYbja+vr2ncuLFZsWJFgV/ry6WmppqHH37YhIeHGz8/P9O0aVMze/bsfF+Lyx9Xm+2Ijo428fHx+dpbtmxpfHx8jDHGHDlyxEgykydPNlOmTDF16tQxXl5eZseOHcYYY9atW2fatm1r/P39TXBwsLn33nvNvn37HPaX9766vJYvvvjC/tqAgADTtWtXs2fPnnz17N+/3/zlL38xVapUMeXLlzcNGjQwf/vb34wx///9d6VxZ2VlmfHjx5s6deoYX19fEx0dbUaPHp1vhi7va7Fy5UrTokUL4+fnZ6ZMmXLFr90NN9xgKlWqZNLS0grc/uKLLxpJ5uOPP3Y4RnHfg3/++YiJiTHly5c3tWrVyjcTd6Wved7+N2zYYN/f5ce62izLf//7XyPJDB8+PN+2bdu2GUnmpZdeMsYY8+mnn5quXbuaqlWrGl9fX1OnTh0zfvx4k52d7fC6y3+uLq8xT9578fIZr/3795uEhARTqVIl4+fnZ1q0aGE+++wzhz6XLl0y48aNM/Xq1TN+fn4mNDTUtGnTxqxevfqKY0Xpss6fBCjz+vXrp7/97W9avXq1Hn300QL77N27V/fcc4+aNm2q8ePHy8/PT4cOHdLmzZslSY0aNdL48eP1wgsvaPDgwWrXrp0k6fbbb7fv48yZM+rSpYt69eqlvn37KiIi4qp1vfzyy7LZbHr22Wd18uRJTZ06VbGxsdq5c+cV/zIvSGFq+zNjjO69915t2LBBiYmJat68uVatWqVnnnlGv/76q6ZMmeLQ/+uvv9Ynn3yi//u//1NgYKDefPNNJSQkKCkpSZUrV75iXf/73//UoUMHHTp0SMOGDVPt2rW1ePFiDRw4UOfOndOTTz6pRo0aad68eXr66adVvXp1jRw5UpIUFhZW6PFLUlZWlo4dO5avnlmzZunixYsaPHiw/Pz8FBoaqrVr16pLly6qU6eOxo0bp//973+aPn262rRpox9++OGqi07nzZunAQMGKC4uTpMmTdLvv/+uGTNmqG3bttqxY4f9tbt371a7du3k4+OjwYMHq1atWjp8+LA+//xzvfzyy+rZs6d+/vlnffzxx5oyZYqqVKniMO5HHnlEc+bM0f3336+RI0dq69atmjhxovbv359vbdKBAwfUu3dvDRkyRI8++qhuuOGGAms/ePCgDhw4oIEDByooKKjAPv3799fYsWO1bNky9erVqzBfekmFew/+9ttv6tq1qx544AH17t1bixYt0uOPPy5fX189/PDDhT6WJD3//PNKS0vT8ePH7e/XgICAK/avXbu2br/9di1atEhTpkxxmNGaP3++JOmhhx6S9McawICAAI0YMUIBAQFav369XnjhBaWnp2vy5MlFqvNK9u7dqzZt2qhatWp67rnnVLFiRS1atEg9evTQv//9b913332S/riQYuLEiXrkkUd02223KT09Xdu2bdMPP/ygu+++2yW1oJjcnbZw/bjWzI4xxgQHB5ubb77Z/vzymZ0pU6YYSebUqVNX3MfV1iTk/aU5c+bMArcVNLNTrVo1k56ebm9ftGiRkWSmTZtmbyvMX9XXqu3yv0A//fRTI8n84x//cOh3//33G5vNZg4dOmRvk2R8fX0d2nbt2mUkmenTp+c71p9NnTrVSDL/+te/7G2XLl0yMTExJiAgwGHsV5qtKUh0dLTp1KmTOXXqlDl16pTZtWuX6dWrl8Nf7nl/TQcFBZmTJ086vL558+YmPDzcnDlzxmFMXl5epn///va2y2cZzp8/b0JCQsyjjz7qsL+UlBQTHBzs0N6+fXsTGBhofvnlF4e+f545u9KanZ07dxpJ5pFHHnFoHzVqlJFk1q9f7/C1kGRWrlx5rS+b/ft+tZkfY4wJCgoyt9xyi8MxivsezPv5eP311+1tmZmZ9u/FpUuXjDGFn9kxpmhrdowx5u233zaSzKpVq+xtOTk5plq1aiYmJsbe9vvvv+d77ZAhQ4y/v7/DzFpxZnY6duxomjRp4rC/3Nxcc/vtt5v69evb25o1a1bonwu4B1djwaMEBARc9aqskJAQSdJnn32m3Nxcp47h5+enQYMGFbp///79FRgYaH9+//33q2rVqvriiy+cOn5hffHFFypXrpyeeOIJh/aRI0fKGKMVK1Y4tMfGxqpu3br2502bNlVQUJD++9//XvM4kZGR6t27t73Nx8dHTzzxhDIyMrRx40anx7B69WqFhYUpLCxMzZo10+LFi9WvXz9NmjTJoV9CQoLDLFFycrJ27typgQMHKjQ01GFMd99991W/9mvWrNG5c+fUu3dvnT592v4oV66cWrVqpQ0bNkiSTp06pU2bNunhhx9WzZo1HfZRmNsd5NVw+ZVBebNey5cvd2ivXbu24uLirrnfvPf/n99zBQkMDFR6evo191dU3t7eGjJkiP25r6+vhgwZopMnT2r79u0uP97lHnzwQfn4+NhnciRp48aN+vXXX9WnTx97259nVc+fP6/Tp0+rXbt2+v333/XTTz8Vu46zZ89q/fr1euCBB+z7P336tM6cOaO4uDgdPHhQv/76q6Q//l/au3evDh48WOzjomQQduBRMjIyrvqf/IMPPqg2bdrokUceUUREhHr16qVFixYVKfhUq1atSIuR69ev7/DcZrOpXr16JX5fl19++UVRUVH5vh6NGjWyb/+zy39hS1KlSpX022+/XfM49evXl5eX438HVzpOUbRq1Upr1qzR2rVr9c033+j06dOaO3duvtN/tWvXzleTpAJP9TRq1EinT5/WhQsXCjxm3i+cu+66yx608h6rV6/WyZMnJckeAm+66SanxvbLL7/Iy8tL9erVc2iPjIxUSEhIvq/b5WO8krzv97VuxXD+/PlrBiJnREVFqWLFig5tDRo0kKRSuZdR5cqVFRcXp6VLl+rixYuS/jiF5e3trQceeMDeb+/evbrvvvsUHBysoKAghYWF2RfDp6WlFbuOQ4cOyRijv//97/neR2PHjpUk+3tp/PjxOnfunBo0aKAmTZromWee0e7du4tdA1yHNTvwGMePH1daWlq+Xx5/VqFCBW3atEkbNmzQ8uXLtXLlSi1cuFB33XWXVq9eXaircoqyzqawrjQTkJOTU2pXCl3pOMaYUjl+QapUqaLY2Nhr9nPl9yQv+M6bN0+RkZH5trv66qXC3vSysGPMC5lX+2X5yy+/KD093eHKuNJ8D17tWK7Qt29fLVu2TMuWLdO9996rf//73+rUqZN99u/cuXO64447FBQUpPHjx6tu3boqX768fvjhBz377LNX/eOnsLXn7WPUqFFXnJHL+7+qffv2Onz4sD777DOtXr1a//znPzVlyhTNnDlTjzzySJHHD9cj7MBjzJs3T5KuOdXv5eWljh07qmPHjnrjjTc0YcIEPf/889qwYYNiY2Ndfsfly6emjTE6dOiQmjZtam+rVKlSgTed++WXX1SnTh3786LUFh0drbVr1+b7Cz5vij46OrrQ+7rWcXbv3q3c3FyH2R1XH6eoNUl/LOq93E8//aQqVarkm33Ik3cqLzw8/KpBK+/7smfPnqvWcqXvWXR0tHJzc3Xw4EF7QJGk1NRUnTt3zumvW4MGDdSgQQN9+umnmjZtWoGzN3PnzpUk3XPPPfY2V70HT5w4oQsXLjh8fX/++WdJsi/srlSpkiTlO15Bs4DO/Dzee++9CgwM1Pz58+Xj46PffvvN4RTWl19+qTNnzuiTTz5R+/bt7e1Hjhy55r4LW3ve18zHx6dQgT00NFSDBg3SoEGDlJGRofbt22vcuHGEHQ/BaSx4hPXr1+ull15S7dq1Hf5Tu9zZs2fztTVv3lySlJmZKUn2/6RddcfbuXPnOpxSWLJkiZKTk9WlSxd7W926dfXtt9/q0qVL9rZly5bp2LFjDvsqSm1du3ZVTk6O3nrrLYf2KVOmyGazORy/OLp27aqUlBQtXLjQ3padna3p06crICBAd9xxh0uOUxRVq1ZV8+bNNWfOHIev1Z49e7R69Wp17dr1iq+Ni4tTUFCQJkyYoKysrHzbT506JemPK6rat2+vDz/8UElJSQ59/jwbdqXvWV4Nl98d+I033pAkxcfHX32QV/HCCy/ot99+02OPPZZvxmH79u2aNGmSbrrpJiUkJNjbXfUezM7O1rvvvmt/funSJb377rsKCwtTixYt7MeSpE2bNtn75eTk6L333su3v4oVKxb5tFKFChV033336YsvvtCMGTNUsWJFde/e3b49b6bqz9+nS5cu6Z133rnmvqOjo1WuXDmH2iXle214eLg6dOigd999V8nJyfn2k/c+kpTvjtYBAQGqV6+e/f8kuB8zOyh1K1as0E8//aTs7GylpqZq/fr1WrNmjaKjo/Wf//xH5cuXv+Jrx48fr02bNik+Pl7R0dE6efKk3nnnHVWvXl1t27aV9Md/xCEhIZo5c6YCAwNVsWJFtWrVqtBrJi4XGhqqtm3batCgQUpNTdXUqVNVr149h8vjH3nkES1ZskSdO3fWAw88oMOHD+tf//qXw4LhotbWrVs33XnnnXr++ed19OhRNWvWTKtXr9Znn32mp556Kt++nTV48GC9++67GjhwoLZv365atWppyZIl2rx5s6ZOnVoi60IKY/LkyerSpYtiYmKUmJhov/Q8ODhY48aNu+LrgoKCNGPGDPXr10+33HKLevXqpbCwMCUlJWn58uVq06aNPUC++eabatu2rW655RYNHjxYtWvX1tGjR7V8+XL7xynk/YJ//vnn1atXL/n4+Khbt25q1qyZBgwYoPfee89+WuW7777TnDlz1KNHD915551Oj71Pnz76/vvvNW3aNO3bt099+vRRpUqV9MMPP+jDDz9U5cqVtWTJEocbUbrqPRgVFaVJkybp6NGjatCggRYuXKidO3fqvffesx/vxhtvVOvWrTV69GidPXtWoaGhWrBggbKzs/ONpUWLFlq4cKFGjBihW2+9VQEBAerWrds1vwZ9+/bV3LlztWrVKvXp08dhpun2229XpUqVNGDAAD3xxBOy2WyaN29eoU7ZBgcH6y9/+YumT58um82munXratmyZfb1N3/29ttvq23btmrSpIkeffRR1alTR6mpqdqyZYuOHz+uXbt2SZIaN26sDh06qEWLFgoNDdW2bdu0ZMkSDRs27Jr1oJS48UowXGfyLlfNe/j6+prIyEhz9913m2nTpjlc4pzn8kvP161bZ7p3726ioqKMr6+viYqKMr179zY///yzw+s+++wz07hxY+Pt7V3gTdMKcqVLzz/++GMzevRoEx4ebipUqGDi4+PzXapsjDGvv/66qVatmvHz8zNt2rQx27Zty7fPq9VW0E0Fz58/b55++mkTFRVlfHx8TP369a96U8HLXely5MulpqaaQYMGmSpVqhhfX1/TpEmTAi9NLuql59fq++ebChZk7dq1pk2bNqZChQomKCjIdOvWrdA3FdywYYOJi4szwcHBpnz58qZu3bpm4MCBZtu2bQ799uzZY+677z4TEhJiypcvb2644Qbz97//3aHPSy+9ZKpVq2a8vLzy3VTwxRdfNLVr1zY+Pj6mRo0aV72pYFF9+umn5u6777bf0K5evXpm5MiRV7z1QnHfgwXdVDA6Otq89dZb+Y51+PBhExsba/z8/ExERIT529/+ZtasWZPvsu6MjAzz0EMPmZCQkGveVPDPsrOzTdWqVY0k88UXX+TbvnnzZtO6dWtToUIFExUVZf7617+aVatW5Tt+QT9Xp06dMgkJCcbf399UqlTJDBkyxOzZs6fAS/IPHz5s+vfvbyIjI42Pj4+pVq2aueeee8ySJUvsff7xj3+Y2267zYSEhJgKFSqYhg0bmpdfftl+qT7cz2aMG1cvAkAxffDBB3rkkUd07NgxVa9e3d3llGkdOnTQ6dOnr7mOCShrWLMDoExLTk6WzWZzuB8PAPwZa3YAlEmpqalasmSJZs6cqZiYGPn7+7u7JAAeipkdAGXS/v379cwzz6hevXqaPXu2u8sB4MFYswMAACyNmR0AAGBphB0AAGBpLFDWH5+BcuLECQUGBrr8owYAAEDJMMbo/PnzioqKyvdhxn9G2NEfnwVTo0YNd5cBAACccK37bBF2JPvt8I8dO6agoCA3VwMAAAojPT1dNWrUuObH2hB29P8/lTcoKIiwAwBAGXOtJSgsUAYAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJbm7e4CAJQttZ5bfs0+R1+JL4VKAKBwmNkBAACWRtgBAACWRtgBAACWRtgBAACWxgJlAHaFWXwMAGUNMzsAAMDSCDsAAMDSCDsAAMDS3Bp2ZsyYoaZNmyooKEhBQUGKiYnRihUr7NsvXryooUOHqnLlygoICFBCQoJSU1Md9pGUlKT4+Hj5+/srPDxczzzzjLKzs0t7KAAAwEO5NexUr15dr7zyirZv365t27bprrvuUvfu3bV3715J0tNPP63PP/9cixcv1saNG3XixAn17NnT/vqcnBzFx8fr0qVL+uabbzRnzhzNnj1bL7zwgruGBAAAPIzNGGPcXcSfhYaGavLkybr//vsVFham+fPn6/7775ck/fTTT2rUqJG2bNmi1q1ba8WKFbrnnnt04sQJRURESJJmzpypZ599VqdOnZKvr2+hjpmenq7g4GClpaUpKCioxMYGeLrSvBqLj5QAUFyF/f3tMWt2cnJytGDBAl24cEExMTHavn27srKyFBsba+/TsGFD1axZU1u2bJEkbdmyRU2aNLEHHUmKi4tTenq6fXaoIJmZmUpPT3d4AAAAa3J72Pnxxx8VEBAgPz8/PfbYY1q6dKkaN26slJQU+fr6KiQkxKF/RESEUlJSJEkpKSkOQSdve962K5k4caKCg4Ptjxo1arh2UAAAwGO4PezccMMN2rlzp7Zu3arHH39cAwYM0L59+0r0mKNHj1ZaWpr9cezYsRI9HgAAcB+330HZ19dX9erVkyS1aNFC33//vaZNm6YHH3xQly5d0rlz5xxmd1JTUxUZGSlJioyM1Hfffeewv7yrtfL6FMTPz09+fn4uHgkAAPBEbp/ZuVxubq4yMzPVokUL+fj4aN26dfZtBw4cUFJSkmJiYiRJMTEx+vHHH3Xy5El7nzVr1igoKEiNGzcu9doBAIDncevMzujRo9WlSxfVrFlT58+f1/z58/Xll19q1apVCg4OVmJiokaMGKHQ0FAFBQVp+PDhiomJUevWrSVJnTp1UuPGjdWvXz+9+uqrSklJ0ZgxYzR06FBmbgAAgCQ3h52TJ0+qf//+Sk5OVnBwsJo2bapVq1bp7rvvliRNmTJFXl5eSkhIUGZmpuLi4vTOO+/YX1+uXDktW7ZMjz/+uGJiYlSxYkUNGDBA48ePd9eQAI/Fh3wCuF553H123IH77OB64Glhh/vsACiuMnefHQAAgJJA2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJbm1s/GAuAanvZREADgSZjZAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlsZ9dgB4rMLcP+joK/GlUAmAsoyZHQAAYGmEHQAAYGmcxgLgFnzEBYDSwswOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNG93FwDgymo9t9zdJQBAmcfMDgAAsDTCDgAAsDTCDgAAsDS3hp2JEyfq1ltvVWBgoMLDw9WjRw8dOHDAoU+HDh1ks9kcHo899phDn6SkJMXHx8vf31/h4eF65plnlJ2dXZpDAQAAHsqtC5Q3btyooUOH6tZbb1V2drb+9re/qVOnTtq3b58qVqxo7/foo49q/Pjx9uf+/v72f+fk5Cg+Pl6RkZH65ptvlJycrP79+8vHx0cTJkwo1fEAAADP49aws3LlSofns2fPVnh4uLZv36727dvb2/39/RUZGVngPlavXq19+/Zp7dq1ioiIUPPmzfXSSy/p2Wef1bhx4+Tr61uiYwAAAJ7No9bspKWlSZJCQ0Md2j/66CNVqVJFN910k0aPHq3ff//dvm3Lli1q0qSJIiIi7G1xcXFKT0/X3r17S6dwAADgsTzmPju5ubl66qmn1KZNG91000329oceekjR0dGKiorS7t279eyzz+rAgQP65JNPJEkpKSkOQUeS/XlKSkqBx8rMzFRmZqb9eXp6uquHAwAAPITHhJ2hQ4dqz549+vrrrx3aBw8ebP93kyZNVLVqVXXs2FGHDx9W3bp1nTrWxIkT9eKLLxarXgAAUDZ4xGmsYcOGadmyZdqwYYOqV69+1b6tWrWSJB06dEiSFBkZqdTUVIc+ec+vtM5n9OjRSktLsz+OHTtW3CEAAAAP5dawY4zRsGHDtHTpUq1fv161a9e+5mt27twpSapataokKSYmRj/++KNOnjxp77NmzRoFBQWpcePGBe7Dz89PQUFBDg8AAGBNbj2NNXToUM2fP1+fffaZAgMD7WtsgoODVaFCBR0+fFjz589X165dVblyZe3evVtPP/202rdvr6ZNm0qSOnXqpMaNG6tfv3569dVXlZKSojFjxmjo0KHy8/Nz5/AAAIAHcOvMzowZM5SWlqYOHTqoatWq9sfChQslSb6+vlq7dq06deqkhg0bauTIkUpISNDnn39u30e5cuW0bNkylStXTjExMerbt6/69+/vcF8eAABw/XLrzI4x5qrba9SooY0bN15zP9HR0friiy9cVRYAALAQj1igDAAAUFIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNK83V0AABRHreeWX7PP0VfiS6ESAJ6KmR0AAGBpzOwAblKYGQkAQPExswMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACzN290FAEBJq/Xc8mv2OfpKfClUAsAdmNkBAACWRtgBAACW5tawM3HiRN16660KDAxUeHi4evTooQMHDjj0uXjxooYOHarKlSsrICBACQkJSk1NdeiTlJSk+Ph4+fv7Kzw8XM8884yys7NLcygAAMBDuTXsbNy4UUOHDtW3336rNWvWKCsrS506ddKFCxfsfZ5++ml9/vnnWrx4sTZu3KgTJ06oZ8+e9u05OTmKj4/XpUuX9M0332jOnDmaPXu2XnjhBXcMCQAAeBibMca4u4g8p06dUnh4uDZu3Kj27dsrLS1NYWFhmj9/vu6//35J0k8//aRGjRppy5Ytat26tVasWKF77rlHJ06cUEREhCRp5syZevbZZ3Xq1Cn5+vpe87jp6ekKDg5WWlqagoKCSnSMQJ7CLJpF6WGBMlD2FPb3t0et2UlLS5MkhYaGSpK2b9+urKwsxcbG2vs0bNhQNWvW1JYtWyRJW7ZsUZMmTexBR5Li4uKUnp6uvXv3FniczMxMpaenOzwAAIA1eUzYyc3N1VNPPaU2bdropptukiSlpKTI19dXISEhDn0jIiKUkpJi7/PnoJO3PW9bQSZOnKjg4GD7o0aNGi4eDQAA8BQeE3aGDh2qPXv2aMGCBSV+rNGjRystLc3+OHbsWIkfEwAAuIdH3FRw2LBhWrZsmTZt2qTq1avb2yMjI3Xp0iWdO3fOYXYnNTVVkZGR9j7fffedw/7yrtbK63M5Pz8/+fn5uXgUAADAE7l1ZscYo2HDhmnp0qVav369ateu7bC9RYsW8vHx0bp16+xtBw4cUFJSkmJiYiRJMTEx+vHHH3Xy5El7nzVr1igoKEiNGzcunYEAAACP5daZnaFDh2r+/Pn67LPPFBgYaF9jExwcrAoVKig4OFiJiYkaMWKEQkNDFRQUpOHDhysmJkatW7eWJHXq1EmNGzdWv3799OqrryolJUVjxozR0KFDmb0BAADuDTszZsyQJHXo0MGhfdasWRo4cKAkacqUKfLy8lJCQoIyMzMVFxend955x963XLlyWrZsmR5//HHFxMSoYsWKGjBggMaPH19awwAAAB7Mo+6z4y7cZwfuwH12PAv32QHKnjJ5nx0AAABXcyrs/Pe//3V1HQAAACXCqbBTr1493XnnnfrXv/6lixcvuromAAAAl3Eq7Pzwww9q2rSpRowYocjISA0ZMiTfvW4AAAA8gVNhp3nz5po2bZpOnDihDz/8UMnJyWrbtq1uuukmvfHGGzp16pSr6wQAAHBKsRYoe3t7q2fPnlq8eLEmTZqkQ4cOadSoUapRo4b69++v5ORkV9UJAADglGKFnW3btun//u//VLVqVb3xxhsaNWqUDh8+rDVr1ujEiRPq3r27q+oEAABwilM3FXzjjTc0a9YsHThwQF27dtXcuXPVtWtXeXn9kZ1q166t2bNnq1atWq6sFQAAoMicCjszZszQww8/rIEDB6pq1aoF9gkPD9cHH3xQrOIAAACKy6mwc/DgwWv28fX11YABA5zZPQAAgMs4tWZn1qxZWrx4cb72xYsXa86cOcUuCgAAwFWcCjsTJ05UlSpV8rWHh4drwoQJxS4KAADAVZwKO0lJSapdu3a+9ujoaCUlJRW7KAAAAFdxas1OeHi4du/ene9qq127dqly5cquqAvwWIX5tHI+QRsAPIdTMzu9e/fWE088oQ0bNignJ0c5OTlav369nnzySfXq1cvVNQIAADjNqZmdl156SUePHlXHjh3l7f3HLnJzc9W/f3/W7AAAAI/iVNjx9fXVwoUL9dJLL2nXrl2qUKGCmjRpoujoaFfXBwClgtOTgHU5FXbyNGjQQA0aNHBVLYBlFOYXJwCgdDgVdnJycjR79mytW7dOJ0+eVG5ursP29evXu6Q4AACA4nIq7Dz55JOaPXu24uPjddNNN8lms7m6LgAAAJdwKuwsWLBAixYtUteuXV1dDwAAgEs5dem5r6+v6tWr5+paAAAAXM6psDNy5EhNmzZNxhhX1wMAAOBSTp3G+vrrr7VhwwatWLFCN954o3x8fBy2f/LJJy4pDgAAoLicCjshISG67777XF0LAACAyzkVdmbNmuXqOgAAAEqEU2t2JCk7O1tr167Vu+++q/Pnz0uSTpw4oYyMDJcVBwAAUFxOzez88ssv6ty5s5KSkpSZmam7775bgYGBmjRpkjIzMzVz5kxX1wkAAOAUp2Z2nnzySbVs2VK//fabKlSoYG+/7777tG7dOpcVBwAAUFxOzex89dVX+uabb+Tr6+vQXqtWLf36668uKQwAAMAVnJrZyc3NVU5OTr7248ePKzAwsNhFAQAAuIpTYadTp06aOnWq/bnNZlNGRobGjh3LR0gAAACP4tRprNdff11xcXFq3LixLl68qIceekgHDx5UlSpV9PHHH7u6RgAAAKc5FXaqV6+uXbt2acGCBdq9e7cyMjKUmJioPn36OCxYBgAAcDenwo4keXt7q2/fvq6sBQAAwOWcCjtz58696vb+/fs7VQwAAICrORV2nnzySYfnWVlZ+v333+Xr6yt/f3/CDgAA8BhOXY3122+/OTwyMjJ04MABtW3blgXKAADAozj92ViXq1+/vl555ZV8sz4AAADu5PQC5QJ35u2tEydOuHKXQKmq9dxyd5cAAHAxp8LOf/7zH4fnxhglJyfrrbfeUps2bVxSGAAAgCs4FXZ69Ojh8NxmsyksLEx33XWXXn/9dVfUBQAA4BJOhZ3c3FxX1wEAAFAiXLZAGQAAwBM5NbMzYsSIQvd94403nDkEAACASzgVdnbs2KEdO3YoKytLN9xwgyTp559/Vrly5XTLLbfY+9lstqvuZ9OmTZo8ebK2b9+u5ORkLV261GE90MCBAzVnzhyH18TFxWnlypX252fPntXw4cP1+eefy8vLSwkJCZo2bZoCAgKcGRoAALAYp8JOt27dFBgYqDlz5qhSpUqS/rjR4KBBg9SuXTuNHDmyUPu5cOGCmjVrpocfflg9e/YssE/nzp01a9Ys+3M/Pz+H7X369FFycrLWrFmjrKwsDRo0SIMHD9b8+fOdGRoAALAYp8LO66+/rtWrV9uDjiRVqlRJ//jHP9SpU6dCh50uXbqoS5cuV+3j5+enyMjIArft379fK1eu1Pfff6+WLVtKkqZPn66uXbvqtddeU1RUVCFHBAAArMqpBcrp6ek6depUvvZTp07p/PnzxS7qz7788kuFh4frhhtu0OOPP64zZ87Yt23ZskUhISH2oCNJsbGx8vLy0tatW6+4z8zMTKWnpzs8AACANTkVdu677z4NGjRIn3zyiY4fP67jx4/r3//+txITE694OsoZnTt31ty5c7Vu3TpNmjRJGzduVJcuXZSTkyNJSklJUXh4uMNrvL29FRoaqpSUlCvud+LEiQoODrY/atSo4bKaAQCAZ3HqNNbMmTM1atQoPfTQQ8rKyvpjR97eSkxM1OTJk11WXK9evez/btKkiZo2baq6devqyy+/VMeOHZ3e7+jRox2uKEtPTyfwAABgUU6FHX9/f73zzjuaPHmyDh8+LEmqW7euKlas6NLiLlenTh1VqVJFhw4dUseOHRUZGamTJ0869MnOztbZs2evuM5H+mMd0OULnQEAgDUV66aCycnJSk5OVv369VWxYkUZY1xVV4GOHz+uM2fOqGrVqpKkmJgYnTt3Ttu3b7f3Wb9+vXJzc9WqVasSrQUAAJQNToWdM2fOqGPHjmrQoIG6du2q5ORkSVJiYmKhr8SSpIyMDO3cuVM7d+6UJB05ckQ7d+5UUlKSMjIy9Mwzz+jbb7/V0aNHtW7dOnXv3l316tVTXFycJKlRo0bq3LmzHn30UX333XfavHmzhg0bpl69enElFgAAkORk2Hn66afl4+OjpKQk+fv729sffPBBhxv+Xcu2bdt088036+abb5b0x52Zb775Zr3wwgsqV66cdu/erXvvvVcNGjRQYmKiWrRooa+++srhFNRHH32khg0bqmPHjuratavatm2r9957z5lhAQAAC3Jqzc7q1au1atUqVa9e3aG9fv36+uWXXwq9nw4dOlz11NeqVauuuY/Q0FBuIAgAAK7IqZmdCxcuOMzo5Dl79iwLfwEAgEdxKuy0a9dOc+fOtT+32WzKzc3Vq6++qjvvvNNlxQEAABSXU6exXn31VXXs2FHbtm3TpUuX9Ne//lV79+7V2bNntXnzZlfXCAAA4DSnZnZuuukm/fzzz2rbtq26d++uCxcuqGfPntqxY4fq1q3r6hoBAACcVuSZnaysLHXu3FkzZ87U888/XxI1AQAAuEyRZ3Z8fHy0e/fukqgFAADA5Zw6jdW3b1998MEHrq4FAADA5ZxaoJydna0PP/xQa9euVYsWLfJ9JtYbb7zhkuIAAACKq0hh57///a9q1aqlPXv26JZbbpEk/fzzzw59bDab66oDAA9S67nl1+xz9JX4UqgEQFEUKezUr19fycnJ2rBhg6Q/Ph7izTffVERERIkUBwAAUFxFCjuXf7TDihUrdOHCBZcWBABlGbM/gOdxaoFynqt9rhUAAIAnKFLYsdls+dbksEYHAAB4siKfxho4cKD9wz4vXryoxx57LN/VWJ988onrKgQAACiGIoWdAQMGODzv27evS4sBAABwtSKFnVmzZpVUHQAAACWiWAuUAQAAPB1hBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWFqRPggUAFB8tZ5bfs0+R1+JL4VKgOsDMzsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDS3Bp2Nm3apG7duikqKko2m02ffvqpw3ZjjF544QVVrVpVFSpUUGxsrA4ePOjQ5+zZs+rTp4+CgoIUEhKixMREZWRklOIoAACAJ3Nr2Llw4YKaNWumt99+u8Dtr776qt58803NnDlTW7duVcWKFRUXF6eLFy/a+/Tp00d79+7VmjVrtGzZMm3atEmDBw8urSEAAAAP5+3Og3fp0kVdunQpcJsxRlOnTtWYMWPUvXt3SdLcuXMVERGhTz/9VL169dL+/fu1cuVKff/992rZsqUkafr06eratatee+01RUVFldpYAACAZ3Jr2LmaI0eOKCUlRbGxsfa24OBgtWrVSlu2bFGvXr20ZcsWhYSE2IOOJMXGxsrLy0tbt27VfffdV+C+MzMzlZmZaX+enp5ecgOBx6j13HJ3lwAAcAOPDTspKSmSpIiICIf2iIgI+7aUlBSFh4c7bPf29lZoaKi9T0EmTpyoF1980cUVA4DrFCacH30lvhQqAcq+6/JqrNGjRystLc3+OHbsmLtLAgAAJcRjw05kZKQkKTU11aE9NTXVvi0yMlInT5502J6dna2zZ8/a+xTEz89PQUFBDg8AAGBNHht2ateurcjISK1bt87elp6erq1btyomJkaSFBMTo3Pnzmn79u32PuvXr1dubq5atWpV6jUDAADP49Y1OxkZGTp06JD9+ZEjR7Rz506FhoaqZs2aeuqpp/SPf/xD9evXV+3atfX3v/9dUVFR6tGjhySpUaNG6ty5sx599FHNnDlTWVlZGjZsmHr16sWVWAAAQJKbw862bdt055132p+PGDFCkjRgwADNnj1bf/3rX3XhwgUNHjxY586dU9u2bbVy5UqVL1/e/pqPPvpIw4YNU8eOHeXl5aWEhAS9+eabpT4WAADgmWzGGOPuItwtPT1dwcHBSktLY/2OhXHpOayGq7FwvSvs72+PvfQcAHB1XJ4OFI7HLlAGAABwBcIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwND4IFJbAJ5oDAK6EmR0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBp3u4uALiWWs8td3cJAIAyjLADABZWmD8Wjr4SXwqVAO7DaSwAAGBphB0AAGBphB0AAGBprNmBW7H4GABQ0pjZAQAAlkbYAQAAlsZpLJQYTlEBADwBMzsAAMDSmNmBU5i1AQCUFczsAAAASyPsAAAASyPsAAAASyPsAAAAS/PosDNu3DjZbDaHR8OGDe3bL168qKFDh6py5coKCAhQQkKCUlNT3VgxAADwNB4ddiTpxhtvVHJysv3x9ddf27c9/fTT+vzzz7V48WJt3LhRJ06cUM+ePd1YLQAA8DQef+m5t7e3IiMj87WnpaXpgw8+0Pz583XXXXdJkmbNmqVGjRrp22+/VevWrUu7VAAA4IE8fmbn4MGDioqKUp06ddSnTx8lJSVJkrZv366srCzFxsba+zZs2FA1a9bUli1brrrPzMxMpaenOzwAAIA1eXTYadWqlWbPnq2VK1dqxowZOnLkiNq1a6fz588rJSVFvr6+CgkJcXhNRESEUlJSrrrfiRMnKjg42P6oUaNGCY4CAAC4k0efxurSpYv9302bNlWrVq0UHR2tRYsWqUKFCk7vd/To0RoxYoT9eXp6OoEHwHWrMHdEP/pKfClUApQMj57ZuVxISIgaNGigQ4cOKTIyUpcuXdK5c+cc+qSmpha4xufP/Pz8FBQU5PAAAADWVKbCTkZGhg4fPqyqVauqRYsW8vHx0bp16+zbDxw4oKSkJMXExLixSgAA4Ek8+jTWqFGj1K1bN0VHR+vEiRMaO3asypUrp969eys4OFiJiYkaMWKEQkNDFRQUpOHDhysmJoYrsQAAgJ1Hh53jx4+rd+/eOnPmjMLCwtS2bVt9++23CgsLkyRNmTJFXl5eSkhIUGZmpuLi4vTOO++4uWoAAOBJbMYY4+4i3C09PV3BwcFKS0tj/U4hFWZBIwDrYIEyPFFhf3+XqTU7AAAAReXRp7HgHszaAACshJkdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaXxcBADgmgrzMTJ8WCg8FTM7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0rj0HADgElyeDk/FzA4AALA0wg4AALA0TmNdZwozzQwAgJUQdgAApYZ1PXAHTmMBAABLI+wAAABLI+wAAABLY80OAMCjuGpdD+uDkIeZHQAAYGnM7FgIl5UDAJAfMzsAAMDSCDsAAMDSOI0FAChzSvO0PQudyz5mdgAAgKURdgAAgKURdgAAgKWxZqeEca4XAAD3IuwAAK5brlrozB+2no2wU0Zww0AAAJzDmh0AAGBphB0AAGBpnMbyAJyiAgCg5BB2AAAoBSxidh9OYwEAAEsj7AAAAEuzzGmst99+W5MnT1ZKSoqaNWum6dOn67bbbnN3WQAAuJSrToddT6fVLBF2Fi5cqBEjRmjmzJlq1aqVpk6dqri4OB04cEDh4eHuLg8AgFLFhS+ObMYY4+4iiqtVq1a69dZb9dZbb0mScnNzVaNGDQ0fPlzPPffcNV+fnp6u4OBgpaWlKSgoyKW18YYDAFzvSmqGqLC/v8v8mp1Lly5p+/btio2Ntbd5eXkpNjZWW7ZscWNlAADAE5T501inT59WTk6OIiIiHNojIiL0008/FfiazMxMZWZm2p+npaVJ+iMhulpu5u8u3ycAAGVJSfx+/fN+r3WSqsyHHWdMnDhRL774Yr72GjVquKEaAACsLXhqye7//PnzCg4OvuL2Mh92qlSponLlyik1NdWhPTU1VZGRkQW+ZvTo0RoxYoT9eW5urs6ePavKlSvLZrOVaL1FlZ6erho1aujYsWMuX0/kqa63MV9v45UY8/Uw5uttvBJjdseYjTE6f/68oqKirtqvzIcdX19ftWjRQuvWrVOPHj0k/RFe1q1bp2HDhhX4Gj8/P/n5+Tm0hYSElHClxRMUFHTd/PDkud7GfL2NV2LM14PrbbwSYy5tV5vRyVPmw44kjRgxQgMGDFDLli112223aerUqbpw4YIGDRrk7tIAAICbWSLsPPjggzp16pReeOEFpaSkqHnz5lq5cmW+RcsAAOD6Y4mwI0nDhg274mmrsszPz09jx47Nd9rNyq63MV9v45UY8/XgehuvxJg9mSVuKggAAHAlZf6mggAAAFdD2AEAAJZG2AEAAJZG2AEAAJZG2PFAZ8+eVZ8+fRQUFKSQkBAlJiYqIyPjqq8ZMmSI6tatqwoVKigsLEzdu3e/4meDeZqijvfs2bMaPny4brjhBlWoUEE1a9bUE088Yf+Ms7LAme/xe++9pw4dOigoKEg2m03nzp0rnWKd9Pbbb6tWrVoqX768WrVqpe++++6q/RcvXqyGDRuqfPnyatKkib744otSqtR1ijLmvXv3KiEhQbVq1ZLNZtPUqVNLr1AXKcp433//fbVr106VKlVSpUqVFBsbe833hCcqypg/+eQTtWzZUiEhIapYsaKaN2+uefPmlWK1rlHUn+U8CxYskM1ms9/w160MPE7nzp1Ns2bNzLfffmu++uorU69ePdO7d++rvubdd981GzduNEeOHDHbt2833bp1MzVq1DDZ2dmlVLXzijreH3/80fTs2dP85z//MYcOHTLr1q0z9evXNwkJCaVYdfE48z2eMmWKmThxopk4caKRZH777bfSKdYJCxYsML6+vubDDz80e/fuNY8++qgJCQkxqampBfbfvHmzKVeunHn11VfNvn37zJgxY4yPj4/58ccfS7ly5xV1zN99950ZNWqU+fjjj01kZKSZMmVK6RZcTEUd70MPPWTefvtts2PHDrN//34zcOBAExwcbI4fP17KlTuvqGPesGGD+eSTT8y+ffvMoUOHzNSpU025cuXMypUrS7ly5xV1zHmOHDliqlWrZtq1a2e6d+9eOsVeBWHHw+zbt89IMt9//729bcWKFcZms5lff/210PvZtWuXkWQOHTpUEmW6jKvGu2jRIuPr62uysrJKokyXKu6YN2zY4PFh57bbbjNDhw61P8/JyTFRUVFm4sSJBfZ/4IEHTHx8vENbq1atzJAhQ0q0Tlcq6pj/LDo6usyFneKM1xhjsrOzTWBgoJkzZ05JlehyxR2zMcbcfPPNZsyYMSVRXolwZszZ2dnm9ttvN//85z/NgAEDPCLscBrLw2zZskUhISFq2bKlvS02NlZeXl7aunVrofZx4cIFzZo1S7Vr1/b4T3J3xXglKS0tTUFBQfL29vz7ZLpqzJ7q0qVL2r59u2JjY+1tXl5eio2N1ZYtWwp8zZYtWxz6S1JcXNwV+3saZ8ZclrlivL///ruysrIUGhpaUmW6VHHHbIzRunXrdODAAbVv374kS3UZZ8c8fvx4hYeHKzExsTTKLBTCjodJSUlReHi4Q5u3t7dCQ0OVkpJy1de+8847CggIUEBAgFasWKE1a9bI19e3JMsttuKMN8/p06f10ksvafDgwSVRosu5Ysye7PTp08rJycn3cS0RERFXHF9KSkqR+nsaZ8ZclrlivM8++6yioqLyhVxP5eyY09LSFBAQIF9fX8XHx2v69Om6++67S7pcl3BmzF9//bU++OADvf/++6VRYqERdkrJc889J5vNdtVHcRcU9+nTRzt27NDGjRvVoEEDPfDAA7p48aKLRlA0pTFeSUpPT1d8fLwaN26scePGFb/wYiitMQNl3SuvvKIFCxZo6dKlKl++vLvLKVGBgYHauXOnvv/+e7388ssaMWKEvvzyS3eXVSLOnz+vfv366f3331eVKlXcXY4Dz5/zt4iRI0dq4MCBV+1Tp04dRUZG6uTJkw7t2dnZOnv2rCIjI6/6+uDgYAUHB6t+/fpq3bq1KlWqpKVLl6p3797FLb/ISmO858+fV+fOnRUYGKilS5fKx8enuGUXS2mMuSyoUqWKypUrp9TUVIf21NTUK44vMjKySP09jTNjLsuKM97XXntNr7zyitauXaumTZuWZJku5eyYvby8VK9ePUlS8+bNtX//fk2cOFEdOnQoyXJdoqhjPnz4sI4ePapu3brZ23JzcyX9MXt94MAB1a1bt2SLvgLCTikJCwtTWFjYNfvFxMTo3Llz2r59u1q0aCFJWr9+vXJzc9WqVatCH8/8sfhcmZmZTtdcHCU93vT0dMXFxcnPz0//+c9/POKvw9L+HnsqX19ftWjRQuvWrbNfcpqbm6t169Zd8cN6Y2JitG7dOj311FP2tjVr1igmJqYUKi4+Z8Zcljk73ldffVUvv/yyVq1a5bBmrSxw1fc4NzfXbf8vF1VRx9ywYUP9+OOPDm1jxozR+fPnNW3aNPeuIXXzAmkUoHPnzubmm282W7duNV9//bWpX7++w2XJx48fNzfccIPZunWrMcaYw4cPmwkTJpht27aZX375xWzevNl069bNhIaGXvPyQE9Q1PGmpaWZVq1amSZNmphDhw6Z5ORk+6MsXGpvTNHHbIwxycnJZseOHeb99983ksymTZvMjh07zJkzZ9wxhKtasGCB8fPzM7Nnzzb79u0zgwcPNiEhISYlJcUYY0y/fv3Mc889Z++/efNm4+3tbV577TWzf/9+M3bs2DJ56XlRxpyZmWl27NhhduzYYapWrWpGjRplduzYYQ4ePOiuIRRJUcf7yiuvGF9fX7NkyRKHn9nz58+7awhFVtQxT5gwwaxevdocPnzY7Nu3z7z22mvG29vbvP/+++4aQpEVdcyX85SrsQg7HujMmTOmd+/eJiAgwAQFBZlBgwY5/Idw5MgRI8ls2LDBGGPMr7/+arp06WLCw8ONj4+PqV69unnooYfMTz/95KYRFE1Rx5t36XVBjyNHjrhnEEVU1DEbY8zYsWMLHPOsWbNKfwCFMH36dFOzZk3j6+trbrvtNvPtt9/at91xxx1mwIABDv0XLVpkGjRoYHx9fc2NN95oli9fXsoVF19Rxpz3Pb78cccdd5R+4U4qynijo6MLHO/YsWNLv/BiKMqYn3/+eVOvXj1Tvnx5U6lSJRMTE2MWLFjghqqLp6g/y3/mKWHHZowxpTaNBAAAUMq4GgsAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQeAZXXo0MHhIygAXJ8IOwA8Urdu3dS5c+cCt3311Vey2WzavXt3KVcFoCwi7ADwSImJiVqzZo2OHz+eb9usWbPUsmXLMvWp2QDch7ADwCPdc889CgsL0+zZsx3aMzIytHjxYvXo0UO9e/dWtWrV5O/vryZNmujjjz++6j5tNps+/fRTh7aQkBCHYxw7dkwPPPCAQkJCFBoaqu7du+vo0aOuGRQAtyDsAPBI3t7e6t+/v2bPnq0/f4Tf4sWLlZOTo759+6pFixZavny59uzZo8GDB6tfv3767rvvnD5mVlaW4uLiFBgYqK+++kqbN29WQECAOnfurEuXLrliWADcgLADwGM9/PDDOnz4sDZu3GhvmzVrlhISEhQdHa1Ro0apefPmqlOnjoYPH67OnTtr0aJFTh9v4cKFys3N1T//+U81adJEjRo10qxZs5SUlKQvv/zSBSMC4A6EHQAeq2HDhrr99tv14YcfSpIOHTqkr776SomJicrJydFLL72kJk2aKDQ0VAEBAVq1apWSkpKcPt6uXbt06NAhBQYGKiAgQAEBAQoNDdXFixd1+PBhVw0LQCnzdncBAHA1iYmJGj58uN5++23NmjVLdevW1R133KFJkyZp2rRpmjp1qpo0aaKKFSvqqaeeuurpJpvN5nBKTPrj1FWejIwMtWjRQh999FG+14aFhbluUABKFWEHgEd74IEH9OSTT2r+/PmaO3euHn/8cdlsNm3evFndu3dX3759JUm5ubn6+eef1bhx4yvuKywsTMnJyfbnBw8e1O+//25/fsstt2jhwoUKDw9XUFBQyQ0KQKniNBYAjxYQEKAHH3xQo0ePVnJysgYOHChJql+/vtasWaNvvvlG+/fv15AhQ5SamnrVfd1111166623tGPHDm3btk2PPfaYfHx87Nv79OmjKlWqqHv37vrqq6905MgRffnll3riiScKvAQeQNlA2AHg8RITE/Xbb78pLi5OUVFRkqQxY8bolltuUVxcnDp06KDIyEj16NHjqvt5/fXXVaNGDbVr104PPfSQRo0aJX9/f/t2f39/bdq0STVr1lTPnj3VqFEjJSYm6uLFi8z0AGWYzVx+AhsAAMBCmNkBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACW9v8A45Dvye9MUHAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Base Encoder Definition\n",
    "# ---------------------------------------------------------------\n",
    "class BaseEncoder(nn.Module):\n",
    "    def __init__(self, num_channels=62, spatial_filters=16, temporal_filters=16, temporal_kernel_size=48):\n",
    "        super(BaseEncoder, self).__init__()\n",
    "\n",
    "        # Spatial Convolution\n",
    "        self.spatial_conv = nn.Conv1d(\n",
    "            in_channels=num_channels,\n",
    "            out_channels=spatial_filters,\n",
    "            kernel_size=1\n",
    "        )\n",
    "\n",
    "        # Temporal Convolution\n",
    "        self.temporal_kernel_size = temporal_kernel_size\n",
    "        self.temporal_conv = nn.Conv1d(\n",
    "            in_channels=spatial_filters,\n",
    "            out_channels=temporal_filters,\n",
    "            kernel_size=temporal_kernel_size\n",
    "        )\n",
    "\n",
    "        # Batch Normalization\n",
    "        self.batch_norm = nn.BatchNorm1d(temporal_filters)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Activation Function\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "        # Additional Temporal Convolution\n",
    "        self.extra_temporal_conv = nn.Conv1d(\n",
    "            in_channels=temporal_filters,\n",
    "            out_channels=temporal_filters,\n",
    "            kernel_size=3,\n",
    "            padding=1  # To maintain the length\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, num_timepoints]\n",
    "\n",
    "        # Spatial Convolution\n",
    "        x = self.spatial_conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Apply asymmetric padding manually before temporal convolution\n",
    "        left_pad = (self.temporal_kernel_size - 1) // 2\n",
    "        right_pad = self.temporal_kernel_size // 2\n",
    "        x = F.pad(x, (left_pad, right_pad))\n",
    "\n",
    "        # Temporal Convolution\n",
    "        x = self.temporal_conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Batch Normalization\n",
    "        x = self.batch_norm(x)\n",
    "\n",
    "        # Dropout\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Additional Temporal Convolution\n",
    "        x = self.extra_temporal_conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Projector Definition\n",
    "# ---------------------------------------------------------------\n",
    "class Projector(nn.Module):\n",
    "    def __init__(self, spatial_filters=16, temporal_filters=32, avg_pool_kernel=10, temporal_kernel_size=3):\n",
    "        super(Projector, self).__init__()\n",
    "\n",
    "        # Average Pooling\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size=avg_pool_kernel, stride=avg_pool_kernel)\n",
    "\n",
    "        # Spatial Convolution\n",
    "        self.spatial_conv = nn.Conv1d(\n",
    "            in_channels=spatial_filters,\n",
    "            out_channels=temporal_filters,\n",
    "            kernel_size=1\n",
    "        )\n",
    "\n",
    "        # Temporal Convolution\n",
    "        self.temporal_conv = nn.Conv1d(\n",
    "            in_channels=temporal_filters,\n",
    "            out_channels=temporal_filters,\n",
    "            kernel_size=temporal_kernel_size,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "        # Activation Function\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Average Pooling\n",
    "        x = self.avg_pool(x)  # Reduces time dimension\n",
    "\n",
    "        # Spatial Convolution\n",
    "        x = self.spatial_conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Temporal Convolution\n",
    "        x = self.temporal_conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Reshape Function for DE Features\n",
    "# ---------------------------------------------------------------\n",
    "def reshape_for_encoder(segment, num_channels=62):\n",
    "    batch_size = segment.shape[0]\n",
    "    num_timepoints = segment.shape[1] // num_channels\n",
    "    return segment.view(batch_size, num_channels, num_timepoints)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Main Function to Test Integration\n",
    "# ---------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example input tensors\n",
    "    batch_size = 8\n",
    "    num_channels = 62\n",
    "    num_timepoints = 200  # Adjust based on DE feature length\n",
    "\n",
    "    # Create dummy DE features\n",
    "    segments_a = torch.rand((batch_size, num_channels * num_timepoints))\n",
    "    segments_b = torch.rand((batch_size, num_channels * num_timepoints))\n",
    "\n",
    "    # Reshape DE features\n",
    "    segments_a_reshaped = reshape_for_encoder(segments_a, num_channels)\n",
    "    segments_b_reshaped = reshape_for_encoder(segments_b, num_channels)\n",
    "\n",
    "    # Initialize models\n",
    "    base_encoder = BaseEncoder(num_channels=num_channels)\n",
    "    projector = Projector()\n",
    "\n",
    "    # Forward pass through Base Encoder\n",
    "    encoded_a = base_encoder(segments_a_reshaped)\n",
    "    encoded_b = base_encoder(segments_b_reshaped)\n",
    "\n",
    "    print(f\"Encoded A Shape: {encoded_a.shape}\")  # Expected: [batch_size, 16, num_timepoints]\n",
    "    print(f\"Encoded B Shape: {encoded_b.shape}\")  # Expected: [batch_size, 16, num_timepoints]\n",
    "\n",
    "    # Forward pass through Projector\n",
    "    projected_a = projector(encoded_a)\n",
    "    projected_b = projector(encoded_b)\n",
    "\n",
    "    print(f\"Projected A Shape: {projected_a.shape}\")  # Expected: [batch_size, 640]\n",
    "    print(f\"Projected B Shape: {projected_b.shape}\")  # Expected: [batch_size, 640]\n",
    "\n",
    "    # Compute gradient flow\n",
    "    loss = (projected_a - projected_b).pow(2).mean()\n",
    "    loss.backward()\n",
    "\n",
    "    print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Check gradient flow for Base Encoder and Projector\n",
    "    print(\"Gradients for Base Encoder:\")\n",
    "    for name, param in base_encoder.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            print(f\"{name}: grad norm = {param.grad.norm().item():.4f}\")\n",
    "\n",
    "    print(\"\\nGradients for Projector:\")\n",
    "    for name, param in projector.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            print(f\"{name}: grad norm = {param.grad.norm().item():.4f}\")\n",
    "\n",
    "    # Plot distribution of Projector output values\n",
    "    plt.hist(projected_a.detach().cpu().numpy().flatten(), bins=50)\n",
    "    plt.title(\"Distribution of Projector Output Values\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrastive Loss: 2.5627\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def contrastive_loss(embeddings_a, embeddings_b, temperature=0.5):\n",
    "    # Normalize the embeddings\n",
    "    embeddings_a = F.normalize(embeddings_a, dim=1)\n",
    "    embeddings_b = F.normalize(embeddings_b, dim=1)\n",
    "    \n",
    "    # Concatenate embeddings\n",
    "    embeddings = torch.cat([embeddings_a, embeddings_b], dim=0)\n",
    "    \n",
    "    # Compute cosine similarity matrix\n",
    "    similarities = torch.matmul(embeddings, embeddings.T) / temperature\n",
    "    \n",
    "    # Clamp similarities to avoid extreme values\n",
    "    similarities = torch.clamp(similarities, min=-5.0, max=5.0)\n",
    "    \n",
    "    # Create labels for positive pairs\n",
    "    batch_size = embeddings_a.shape[0]\n",
    "    labels = torch.cat([torch.arange(batch_size), torch.arange(batch_size)], dim=0)\n",
    "    labels = labels.to(embeddings.device)\n",
    "    \n",
    "    # Compute contrastive loss\n",
    "    loss = F.cross_entropy(similarities, labels)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Example usage\n",
    "loss = contrastive_loss(embeddings_a, embeddings_b, temperature=0.5)\n",
    "print(f\"Contrastive Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 3.4321\n",
      "Checkpoint saved at epoch 1\n",
      "Epoch [2/100], Loss: 3.4253\n",
      "Checkpoint saved at epoch 2\n",
      "Epoch [3/100], Loss: 3.4246\n",
      "Checkpoint saved at epoch 3\n",
      "Epoch [4/100], Loss: 3.4219\n",
      "Checkpoint saved at epoch 4\n",
      "Epoch [5/100], Loss: 3.4243\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 182\u001b[0m\n\u001b[0;32m    179\u001b[0m criterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m a, b: contrastive_loss(a, b, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 135\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(base_encoder, projector, dataloader, criterion, optimizer, num_epochs, patience, device, checkpoint_path)\u001b[0m\n\u001b[0;32m    132\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    134\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mlist\u001b[39m(base_encoder\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(projector\u001b[38;5;241m.\u001b[39mparameters()), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m--> 135\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    139\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "File \u001b[1;32mc:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    214\u001b[0m         group,\n\u001b[0;32m    215\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m         state_steps,\n\u001b[0;32m    221\u001b[0m     )\n\u001b[1;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:543\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    540\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_lerp_(device_exp_avgs, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m    542\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(device_exp_avg_sqs, beta2)\n\u001b[1;32m--> 543\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_addcmul_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;66;03m# Delete the local intermediate since it won't be used anymore to save on peak memory\u001b[39;00m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m device_grads\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import copy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Base Encoder Definition\n",
    "# ---------------------------------------------------------------\n",
    "class BaseEncoder(nn.Module):\n",
    "    def __init__(self, num_channels=62, spatial_filters=16, temporal_filters=16, temporal_kernel_size=48):\n",
    "        super(BaseEncoder, self).__init__()\n",
    "\n",
    "        self.spatial_conv = nn.Conv1d(num_channels, spatial_filters, kernel_size=1)\n",
    "        self.temporal_kernel_size = temporal_kernel_size\n",
    "        self.temporal_conv = nn.Conv1d(spatial_filters, temporal_filters, kernel_size=temporal_kernel_size)\n",
    "        self.batch_norm = nn.BatchNorm1d(temporal_filters)\n",
    "        self.dropout = nn.Dropout(p=0.3)  # Reduced dropout rate\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spatial_conv(x)\n",
    "        x = self.activation(x)\n",
    "        left_pad = (self.temporal_kernel_size - 1) // 2\n",
    "        right_pad = self.temporal_kernel_size // 2\n",
    "        x = F.pad(x, (left_pad, right_pad))\n",
    "        x = self.temporal_conv(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Projector Definition\n",
    "# ---------------------------------------------------------------\n",
    "class Projector(nn.Module):\n",
    "    def __init__(self, spatial_filters=16, temporal_filters=32, avg_pool_kernel=2, temporal_kernel_size=3):\n",
    "        super(Projector, self).__init__()\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size=avg_pool_kernel, stride=avg_pool_kernel)\n",
    "        self.spatial_conv = nn.Conv1d(spatial_filters, temporal_filters, kernel_size=1)\n",
    "        self.temporal_conv = nn.Conv1d(temporal_filters, temporal_filters, kernel_size=temporal_kernel_size, padding=1)\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.spatial_conv(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.temporal_conv(x)\n",
    "        x = self.activation(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Contrastive Loss Function\n",
    "# ---------------------------------------------------------------\n",
    "def contrastive_loss(embeddings_a, embeddings_b, temperature=0.1):\n",
    "    embeddings_a = F.normalize(embeddings_a, dim=1)\n",
    "    embeddings_b = F.normalize(embeddings_b, dim=1)\n",
    "\n",
    "    batch_size = embeddings_a.size(0)\n",
    "    labels = torch.arange(batch_size).to(embeddings_a.device)\n",
    "    \n",
    "    logits = torch.matmul(embeddings_a, embeddings_b.T) / temperature\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Dataset Class for Contrastive Pairs from Files\n",
    "# ---------------------------------------------------------------\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, data_dir, num_channels=62, num_timepoints=200):\n",
    "        self.filepaths = [os.path.join(data_dir, f\"batch_{i}_pairs.pkl.gz\") for i in range(1000)]\n",
    "        self.num_channels = num_channels\n",
    "        self.num_timepoints = num_timepoints\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.filepaths[idx]\n",
    "        with gzip.open(filepath, 'rb') as f:\n",
    "            pairs = pickle.load(f)\n",
    "\n",
    "        # Randomly select a pair from the batch\n",
    "        segment_a, segment_b, _ = pairs[torch.randint(0, len(pairs), (1,)).item()]\n",
    "\n",
    "        # Ensure each segment is reshaped to [num_channels, num_timepoints]\n",
    "        segment_a = torch.tensor(segment_a, dtype=torch.float32)\n",
    "        segment_b = torch.tensor(segment_b, dtype=torch.float32)\n",
    "\n",
    "        # Reshape to [num_channels, num_timepoints]\n",
    "        segment_a = segment_a.view(self.num_channels, -1)\n",
    "        segment_b = segment_b.view(self.num_channels, -1)\n",
    "\n",
    "        # Pad or truncate to ensure the time dimension is consistent\n",
    "        segment_a = F.pad(segment_a, (0, max(0, self.num_timepoints - segment_a.shape[1])))\n",
    "        segment_b = F.pad(segment_b, (0, max(0, self.num_timepoints - segment_b.shape[1])))\n",
    "\n",
    "        segment_a = segment_a[:, :self.num_timepoints]\n",
    "        segment_b = segment_b[:, :self.num_timepoints]\n",
    "\n",
    "        return segment_a, segment_b\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Training Loop with Checkpoints and Early Stopping\n",
    "# ---------------------------------------------------------------\n",
    "def train_model(base_encoder, projector, dataloader, criterion, optimizer, num_epochs=100, patience=30, device='cpu', checkpoint_path='best_model.pth'):\n",
    "    writer = SummaryWriter(log_dir='runs/contrastive_training')\n",
    "\n",
    "    base_encoder.to(device)\n",
    "    projector.to(device)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for segments_a, segments_b in dataloader:\n",
    "            segments_a, segments_b = segments_a.to(device), segments_b.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            embeddings_a = projector(base_encoder(segments_a))\n",
    "            embeddings_b = projector(base_encoder(segments_b))\n",
    "\n",
    "            loss = criterion(embeddings_a, embeddings_b)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(list(base_encoder.parameters()) + list(projector.parameters()), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "        writer.add_scalar('Loss/train', avg_loss, epoch + 1)\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_model_state = copy.deepcopy({'base_encoder': base_encoder.state_dict(), 'projector': projector.state_dict()})\n",
    "            torch.save(best_model_state, checkpoint_path)\n",
    "            print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "        # Log embeddings to TensorBoard\n",
    "        writer.add_histogram('Embeddings/embeddings_a', embeddings_a, epoch)\n",
    "        writer.add_histogram('Embeddings/embeddings_b', embeddings_b, epoch)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Main Function to Run Training\n",
    "# ---------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the contrastive pairs directory\n",
    "    data_dir = r\"C:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\contrastive_pairs\"\n",
    "\n",
    "    # Create Dataset and DataLoader\n",
    "    dataset = ContrastiveDataset(data_dir)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Initialize Models\n",
    "    base_encoder = BaseEncoder(num_channels=62)\n",
    "    projector = Projector()\n",
    "\n",
    "    # Define Optimizer and Criterion\n",
    "    optimizer = optim.Adam(list(base_encoder.parameters()) + list(projector.parameters()), lr=0.001)\n",
    "    criterion = lambda a, b: contrastive_loss(a, b, temperature=0.1)\n",
    "\n",
    "    # Train the Model\n",
    "    train_model(base_encoder, projector, dataloader, criterion, optimizer, num_epochs=100, patience=30, device='cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
